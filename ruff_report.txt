PLR0913 Too many arguments in function definition (7 > 5)
   --> src\core\adaptive_retry_strategy.py:167:9
    |
165 |         }
166 |
167 |     def record_failure(
    |         ^^^^^^^^^^^^^^
168 |         self,
169 |         failure_type: FailureType,
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> src\core\adaptive_retry_strategy.py:356:41
    |
355 |         # Increase max retries for frequently failing sites
356 |         if pattern.recent_occurrences > 10:
    |                                         ^^
357 |             adapted_config.max_retries = min(config.max_retries + 2, 10)
    |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> src\core\adaptive_retry_strategy.py:360:35
    |
359 |         # Adjust delays based on success rate
360 |         if pattern.success_rate < 0.3:  # Low success rate
    |                                   ^^^
361 |             adapted_config.base_delay *= 1.5
362 |             adapted_config.max_delay *= 2.0
    |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
   --> src\core\adaptive_retry_strategy.py:364:37
    |
362 |             adapted_config.max_delay *= 2.0
363 |             adapted_config.backoff_multiplier *= 1.2
364 |         elif pattern.success_rate > 0.8:  # High success rate
    |                                     ^^^
365 |             adapted_config.base_delay *= 0.8
366 |             adapted_config.max_delay *= 0.9
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> src\core\adaptive_retry_strategy.py:373:97
    |
372 |         # Lower session rotation threshold for access denied failures
373 |         if pattern.failure_type == FailureType.ACCESS_DENIED and pattern.consecutive_failures > 2:
    |                                                                                                 ^
374 |             adapted_config.session_rotation_threshold = max(
375 |                 config.session_rotation_threshold - 1, 1
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> src\core\adaptive_retry_strategy.py:382:66
    |
380 |         if (
381 |             pattern.peak_failure_hour is not None
382 |             and abs(current_hour - pattern.peak_failure_hour) <= 2
    |                                                                  ^
383 |         ):
384 |             adapted_config.base_delay *= 1.3  # Increase delay during peak hours
    |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
   --> src\core\adaptive_retry_strategy.py:411:39
    |
409 |             )
410 |
411 |         if analysis["success_rate"] < 0.5:
    |                                       ^^^
412 |             insights.append(
413 |                 f"Low success rate for {pattern.failure_type.value} on {pattern.site_name}: "
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> src\core\adaptive_retry_strategy.py:417:47
    |
415 |             )
416 |
417 |         if analysis["consecutive_failures"] > 3:
    |                                               ^
418 |             insights.append(
419 |                 f"Consecutive failures for {pattern.failure_type.value} on {pattern.site_name}: "
    |

PLR2004 Magic value used in comparison, consider replacing `2.0` with a constant variable
   --> src\core\adaptive_retry_strategy.py:423:46
    |
421 |             )
422 |
423 |         if analysis["average_retry_count"] > 2.0:
    |                                              ^^^
424 |             insights.append(
425 |                 f"High retry count needed for {pattern.failure_type.value} on {pattern.site_name}: "
    |

PLR0911 Too many return statements (7 > 6)
   --> src\core\adaptive_retry_strategy.py:495:9
    |
493 |             logger.warning(f"Failed to save failure history: {e}")
494 |
495 |     def calculate_delay(self, config: AdaptiveRetryConfig, retry_count: int) -> float:
    |         ^^^^^^^^^^^^^^^
496 |         """
497 |         Calculate delay for a specific retry attempt.
    |

PLR0913 Too many arguments in function definition (15 > 5)
  --> src\core\anti_detection_manager.py:26:9
   |
24 |     """Configuration for anti-detection modules."""
25 |
26 |     def __init__(
   |         ^^^^^^^^
27 |         self,
28 |         enable_captcha_detection: bool = True,
   |

PLC0415 `import` should be at the top-level of a file
   --> src\core\anti_detection_manager.py:140:13
    |
138 |         rate_limit_adaptive_config = None
139 |         if hasattr(self, "adaptive_retry_strategy"):
140 |             from src.core.failure_classifier import FailureType
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
141 |
142 |             rate_limit_adaptive_config = self.adaptive_retry_strategy.get_adaptive_config(
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\anti_detection_manager.py:211:9
    |
209 |             True if action should proceed, False if blocked
210 |         """
211 |         import os
    |         ^^^^^^^^^
212 |
213 |         is_ci = os.getenv("CI") == "true"
    |

PLR2004 Magic value used in comparison, consider replacing `0.1` with a constant variable
   --> src\core\anti_detection_manager.py:223:37
    |
221 |                 self.rate_limiter.apply_delay(self.browser.driver)
222 |                 delay_duration = time.time() - start_time
223 |                 if delay_duration > 0.1:  # Only log significant delays
    |                                     ^^^
224 |                     logger.debug(f"Rate limiter applied {delay_duration:.2f}s delay")
    |

PLR0911 Too many return statements (7 > 6)
   --> src\core\anti_detection_manager.py:275:9
    |
273 |             logger.error(f"Post-action hook failed: {e}")
274 |
275 |     def handle_error(self, error: Exception, action: str, retry_count: int = 0) -> bool:
    |         ^^^^^^^^^^^^
276 |         """
277 |         Handle errors with adaptive anti-detection recovery strategies.
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\anti_detection_manager.py:289:13
    |
287 |         try:
288 |             # Classify the error to determine failure type
289 |             from src.core.failure_classifier import FailureClassifier
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
290 |
291 |             failure_classifier = FailureClassifier()
    |

E501 Line too long (106 > 100)
   --> src\core\anti_detection_manager.py:302:101
    |
300 |             if retry_count >= adaptive_config.max_retries:
301 |                 logger.warning(
302 |                     f"Adaptive max retries ({adaptive_config.max_retries}) exceeded for action: {action} "
    |                                                                                                     ^^^^^^
303 |                     f"(failure: {failure_context.failure_type.value})"
304 |                 )
    |

E501 Line too long (108 > 100)
   --> src\core\anti_detection_manager.py:311:101
    |
309 |             if delay > 0:
310 |                 logger.info(
311 |                     f"Adaptive retry delay for '{action}' - failure: {failure_context.failure_type.value}, "
    |                                                                                                     ^^^^^^^^
312 |                     f"retry {retry_count + 1}/{adaptive_config.max_retries}, delay: {delay:.1f}s"
313 |                 )
    |

E722 Do not use bare `except`
   --> src\core\anti_detection_manager.py:485:17
    |
483 |                         logger.info(f"CAPTCHA detected using selector: {selector}")
484 |                         return True
485 |                 except:
    |                 ^^^^^^
486 |                     continue
487 |             return False
    |

E501 Line too long (121 > 100)
   --> src\core\anti_detection_manager.py:502:101
    |
500 |                     current_url = driver.current_url
501 |                     logger.info(
502 |                         f"Attempting CAPTCHA resolution using external service (attempt {attempt + 1}/{max_retries + 1})"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^
503 |                     )
504 |                     if self.captcha_solver.solve_captcha(driver, current_url):
    |

E501 Line too long (103 > 100)
   --> src\core\anti_detection_manager.py:509:101
    |
507 |                     else:
508 |                         logger.warning(
509 |                             f"External CAPTCHA solving failed (attempt {attempt + 1}), trying fallback"
    |                                                                                                     ^^^
510 |                         )
    |

E501 Line too long (112 > 100)
   --> src\core\anti_detection_manager.py:514:101
    |
512 |                 # Fallback: just wait and retry
513 |                 logger.info(
514 |                     f"Attempting CAPTCHA resolution (waiting strategy, attempt {attempt + 1}/{max_retries + 1})"
    |                                                                                                     ^^^^^^^^^^^^
515 |                 )
516 |                 wait_time = random.uniform(5, 10) * (
    |

E722 Do not use bare `except`
   --> src\core\anti_detection_manager.py:561:17
    |
559 |                         logger.info(f"Rate limiting detected using selector: {selector}")
560 |                         return True
561 |                 except:
    |                 ^^^^^^
562 |                     continue
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\anti_detection_manager.py:582:9
    |
580 |     def apply_delay(self, driver=None) -> None:
581 |         """Apply appropriate delay before next request using adaptive strategies."""
582 |         import os
    |         ^^^^^^^^^
583 |
584 |         is_ci = os.getenv("CI") == "true"
    |

E501 Line too long (194 > 100)
   --> src\core\anti_detection_manager.py:623:101
    |
621 | â€¦
622 | â€¦
623 | â€¦2f}s, required_delay: {required_delay:.2f}s, applying delay: {delay:.2f}s, failures: {self.consecutive_failures}"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
624 | â€¦
625 | â€¦
    |

E501 Line too long (145 > 100)
   --> src\core\anti_detection_manager.py:628:101
    |
626 | â€¦
627 | â€¦
628 | â€¦eded (time_since_last: {time_since_last:.2f}s >= required_delay: {required_delay:.2f}s)"
    |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
629 | â€¦
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\anti_detection_manager.py:698:13
    |
697 |             # Create new browser instance
698 |             from src.utils.scraping.browser import create_browser
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
699 |
700 |             manager.browser = create_browser(
    |

E722 Do not use bare `except`
   --> src\core\anti_detection_manager.py:734:17
    |
732 |                         logger.info(f"Blocking page detected using selector: {selector}")
733 |                         return True
734 |                 except:
    |                 ^^^^^^
735 |                     continue
    |

PLR0913 Too many arguments in function definition (6 > 5)
  --> src\core\captcha_solver.py:37:9
   |
35 |     """Configuration for CAPTCHA solving services."""
36 |
37 |     def __init__(
   |         ^^^^^^^^
38 |         self,
39 |         enabled: bool = False,
   |

E501 Line too long (101 > 100)
   --> src\core\captcha_solver.py:143:101
    |
141 |                     if elements:
142 |                         element = elements[0]
143 |                         site_key = element.get_attribute("data-sitekey") or driver.execute_script("""
    |                                                                                                     ^
144 |                                 var recaptcha = document.querySelector('.g-recaptcha');
145 |                                 if (recaptcha) {
    |

E722 Do not use bare `except`
   --> src\core\captcha_solver.py:155:17
    |
153 |                                 "element": element,
154 |                             }
155 |                 except:
    |                 ^^^^^^
156 |                     continue
    |

E722 Do not use bare `except`
   --> src\core\captcha_solver.py:179:13
    |
177 |                             "site_key": site_key,
178 |                         }
179 |             except:
    |             ^^^^^^
180 |                 pass
    |

E722 Do not use bare `except`
   --> src\core\captcha_solver.py:200:17
    |
198 |                                 "element": element,
199 |                             }
200 |                 except:
    |                 ^^^^^^
201 |                     continue
    |

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\llm_classifier.py:48:27
   |
46 |     def __init__(
47 |         self,
48 |         product_taxonomy: dict[str, list[str]] = None,
   |                           ^^^^^^^^^^^^^^^^^^^^
49 |         product_pages: list[str] = None,
50 |     ):
   |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\llm_classifier.py:49:24
   |
47 |         self,
48 |         product_taxonomy: dict[str, list[str]] = None,
49 |         product_pages: list[str] = None,
   |                        ^^^^^^^^^
50 |     ):
51 |         if not OPENROUTER_API_KEY:
   |
help: Convert to `T | None`

E501 Line too long (115 > 100)
  --> src\core\classification\llm_classifier.py:53:101
   |
51 |         if not OPENROUTER_API_KEY:
52 |             raise ValueError(
53 |                 "OpenRouter API key not found. Set OPENROUTER_API_KEY environment variable or add to settings.json"
   |                                                                                                     ^^^^^^^^^^^^^^^
54 |             )
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\classification\llm_classifier.py:59:17
   |
57 |         if product_taxonomy is None:
58 |             try:
59 |                 from .manager import GENERAL_PRODUCT_TAXONOMY
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
60 |
61 |                 self.product_taxonomy = GENERAL_PRODUCT_TAXONOMY
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\classification\llm_classifier.py:64:21
   |
62 |             except ImportError:
63 |                 try:
64 |                     from src.core.classification.manager import GENERAL_PRODUCT_TAXONOMY
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
65 |
66 |                     self.product_taxonomy = GENERAL_PRODUCT_TAXONOMY
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\classification\llm_classifier.py:88:17
   |
86 |         if product_pages is None:
87 |             try:
88 |                 from .manager import PRODUCT_PAGES
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
89 |
90 |                 self.product_pages = PRODUCT_PAGES
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\classification\llm_classifier.py:93:21
   |
91 |             except ImportError:
92 |                 try:
93 |                     from src.core.classification.manager import PRODUCT_PAGES
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
94 |
95 |                     self.product_pages = PRODUCT_PAGES
   |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\llm_classifier.py:118:13
    |
116 |           """Initialize conversation with taxonomy and instructions."""
117 |           try:
118 | /             from src.core.classification.manager import (
119 | |                 UNIFIED_SINGLE_PRODUCT_JSON_FORMAT,
120 | |                 UNIFIED_SYSTEM_PROMPT,
121 | |             )
    | |_____________^
122 |           except ImportError:
123 |               from .manager import UNIFIED_SINGLE_PRODUCT_JSON_FORMAT, UNIFIED_SYSTEM_PROMPT
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\llm_classifier.py:123:13
    |
121 |             )
122 |         except ImportError:
123 |             from .manager import UNIFIED_SINGLE_PRODUCT_JSON_FORMAT, UNIFIED_SYSTEM_PROMPT
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
124 |
125 |         # Create comprehensive system prompt
    |

PLR2004 Magic value used in comparison, consider replacing `200` with a constant variable
   --> src\core\classification\llm_classifier.py:162:44
    |
160 |                 )
161 |
162 |                 if response.status_code == 200:
    |                                            ^^^
163 |                     result = response.json()
164 |                     return result["choices"][0]["message"]["content"]
    |

E501 Line too long (113 > 100)
   --> src\core\classification\llm_classifier.py:167:101
    |
165 |                 else:
166 |                     print(
167 |                         f"OpenRouter API error (attempt {attempt + 1}): {response.status_code} - {response.text}"
    |                                                                                                     ^^^^^^^^^^^^^
168 |                     )
    |

B905 `zip()` without an explicit `strict=` parameter
   --> src\core\classification\llm_classifier.py:253:28
    |
251 |         # Reconstruct full results list with empty results for invalid products
252 |         results = [{"category": "", "product_type": "", "product_on_pages": ""} for _ in products]
253 |         for idx, result in zip(valid_indices, valid_results):
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
254 |             results[idx] = result
    |
help: Add explicit value for parameter `strict=`

PLR0912 Too many branches (14 > 12)
   --> src\core\classification\llm_classifier.py:285:9
    |
283 |         return results
284 |
285 |     def _classify_batch_api_call(self, products: list[dict[str, Any]]) -> list[dict[str, str]]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
286 |         """Make a single API call for multiple products."""
287 |         if not products:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\llm_classifier.py:291:13
    |
290 |         try:
291 |             from src.core.classification.manager import UNIFIED_BATCH_JSON_FORMAT
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
292 |         except ImportError:
293 |             from .manager import UNIFIED_BATCH_JSON_FORMAT
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\llm_classifier.py:293:13
    |
291 |             from src.core.classification.manager import UNIFIED_BATCH_JSON_FORMAT
292 |         except ImportError:
293 |             from .manager import UNIFIED_BATCH_JSON_FORMAT
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
294 |
295 |         # Create batch prompt with essential product information
    |

E501 Line too long (130 > 100)
   --> src\core\classification\llm_classifier.py:296:101
    |
295 |         # Create batch prompt with essential product information
296 |         batch_prompt = "Classify these products. For each product, use the name and brand to determine the category and type.\n\n"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
297 |
298 |         for i, product in enumerate(products, 1):
    |

B007 Loop control variable `product` not used within loop body
   --> src\core\classification\llm_classifier.py:339:24
    |
337 |                 # Convert to expected format
338 |                 batch_results = []
339 |                 for i, product in enumerate(products):
    |                        ^^^^^^^
340 |                     # Find classification for this product index
341 |                     product_classification = None
    |
help: Rename unused `product` to `_product`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\classification\llm_classifier.py:460:23
    |
459 | def get_llm_classifier(
460 |     product_taxonomy: dict[str, list[str]] = None, product_pages: list[str] = None
    |                       ^^^^^^^^^^^^^^^^^^^^
461 | ) -> LLMProductClassifier:
462 |     """Get or create LLM classifier instance."""
    |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\classification\llm_classifier.py:460:67
    |
459 | def get_llm_classifier(
460 |     product_taxonomy: dict[str, list[str]] = None, product_pages: list[str] = None
    |                                                                   ^^^^^^^^^
461 | ) -> LLMProductClassifier:
462 |     """Get or create LLM classifier instance."""
    |
help: Convert to `T | None`

PLW0603 Using the global statement to update `_llm_classifier` is discouraged
   --> src\core\classification\llm_classifier.py:463:12
    |
461 | ) -> LLMProductClassifier:
462 |     """Get or create LLM classifier instance."""
463 |     global _llm_classifier
    |            ^^^^^^^^^^^^^^^
464 |     if _llm_classifier is None:
465 |         try:
    |

B905 `zip()` without an explicit `strict=` parameter
   --> src\core\classification\llm_classifier.py:544:47
    |
542 |         results = classifier.classify_products_batch(test_products)
543 |
544 |         for i, (product, result) in enumerate(zip(test_products, results), 1):
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
545 |             print(f"\nðŸ“¦ Product {i}: {product['Name'][:50]}")
546 |             print(f"   Category: {result.get('category', 'N/A')}")
    |
help: Add explicit value for parameter `strict=`

E501 Line too long (102 > 100)
  --> src\core\classification\local_llm_classifier.py:42:101
   |
41 | class LocalLLMProductClassifier:
42 |     """Local LLM-based product classifier using Ollama for running models locally without API keys."""
   |                                                                                                     ^^
43 |
44 |     def __init__(
   |

PLR0912 Too many branches (13 > 12)
  --> src\core\classification\local_llm_classifier.py:44:9
   |
42 |     """Local LLM-based product classifier using Ollama for running models locally without API keys."""
43 |
44 |     def __init__(
   |         ^^^^^^^^
45 |         self,
46 |         model_name: str = None,
   |

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\local_llm_classifier.py:46:21
   |
44 |     def __init__(
45 |         self,
46 |         model_name: str = None,
   |                     ^^^
47 |         cache_file: Path = None,
48 |         product_taxonomy: dict[str, list[str]] = None,
   |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\local_llm_classifier.py:47:21
   |
45 |         self,
46 |         model_name: str = None,
47 |         cache_file: Path = None,
   |                     ^^^^
48 |         product_taxonomy: dict[str, list[str]] = None,
49 |         product_pages: list[str] = None,
   |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\local_llm_classifier.py:48:27
   |
46 |         model_name: str = None,
47 |         cache_file: Path = None,
48 |         product_taxonomy: dict[str, list[str]] = None,
   |                           ^^^^^^^^^^^^^^^^^^^^
49 |         product_pages: list[str] = None,
50 |     ):
   |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\local_llm_classifier.py:49:24
   |
47 |         cache_file: Path = None,
48 |         product_taxonomy: dict[str, list[str]] = None,
49 |         product_pages: list[str] = None,
   |                        ^^^^^^^^^
50 |     ):
51 |         # Try to get model name from settings first, then parameter, then environment, then default
   |
help: Convert to `T | None`

PLC0415 `import` should be at the top-level of a file
  --> src\core\classification\local_llm_classifier.py:70:17
   |
68 |         if product_taxonomy is None:
69 |             try:
70 |                 from .taxonomy_manager import get_product_taxonomy
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
71 |
72 |                 self.product_taxonomy = get_product_taxonomy()
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\classification\local_llm_classifier.py:75:21
   |
73 |             except ImportError:
74 |                 try:
75 |                     from src.core.classification.taxonomy_manager import get_product_taxonomy
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
76 |
77 |                     self.product_taxonomy = get_product_taxonomy()
   |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\local_llm_classifier.py:99:17
    |
 97 |         if product_pages is None:
 98 |             try:
 99 |                 from .manager import PRODUCT_PAGES
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
100 |
101 |                 self.product_pages = PRODUCT_PAGES
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\local_llm_classifier.py:104:21
    |
102 |             except ImportError:
103 |                 try:
104 |                     from src.core.classification.manager import PRODUCT_PAGES
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
105 |
106 |                     self.product_pages = PRODUCT_PAGES
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\core\classification\local_llm_classifier.py:125:13
    |
123 |               print(f"âœ… Ollama connection successful, using model: {self.model_name}")
124 |           except Exception as e:
125 | /             raise ValueError(
126 | |                 f"Ollama not available. Please install Ollama and ensure it's running: {e}"
127 | |             )
    | |_____________^
128 |
129 |       def _initialize_conversation(self):
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\local_llm_classifier.py:132:13
    |
130 |           """Initialize conversation with taxonomy and instructions."""
131 |           try:
132 | /             from src.core.classification.manager import (
133 | |                 UNIFIED_SINGLE_PRODUCT_JSON_FORMAT,
134 | |                 UNIFIED_SYSTEM_PROMPT,
135 | |             )
    | |_____________^
136 |           except ImportError:
137 |               from .manager import UNIFIED_SINGLE_PRODUCT_JSON_FORMAT, UNIFIED_SYSTEM_PROMPT
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\local_llm_classifier.py:137:13
    |
135 |             )
136 |         except ImportError:
137 |             from .manager import UNIFIED_SINGLE_PRODUCT_JSON_FORMAT, UNIFIED_SYSTEM_PROMPT
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
138 |
139 |         # Create comprehensive system prompt
    |

B905 `zip()` without an explicit `strict=` parameter
   --> src\core\classification\local_llm_classifier.py:260:28
    |
258 |         # Reconstruct full results list with empty results for invalid products
259 |         results = [{"category": "", "product_type": "", "product_on_pages": ""} for _ in products]
260 |         for idx, result in zip(valid_indices, valid_results):
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
261 |             results[idx] = result
    |
help: Add explicit value for parameter `strict=`

PLR0912 Too many branches (14 > 12)
   --> src\core\classification\local_llm_classifier.py:292:9
    |
290 |         return results
291 |
292 |     def _classify_batch_ollama_call(self, products: list[dict[str, Any]]) -> list[dict[str, str]]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
293 |         """Make a single API call for multiple products."""
294 |         if not products:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\local_llm_classifier.py:298:13
    |
297 |         try:
298 |             from src.core.classification.manager import UNIFIED_BATCH_JSON_FORMAT
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
299 |         except ImportError:
300 |             from .manager import UNIFIED_BATCH_JSON_FORMAT
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\local_llm_classifier.py:300:13
    |
298 |             from src.core.classification.manager import UNIFIED_BATCH_JSON_FORMAT
299 |         except ImportError:
300 |             from .manager import UNIFIED_BATCH_JSON_FORMAT
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
301 |
302 |         # Create batch prompt with essential product information
    |

E501 Line too long (130 > 100)
   --> src\core\classification\local_llm_classifier.py:303:101
    |
302 |         # Create batch prompt with essential product information
303 |         batch_prompt = "Classify these products. For each product, use the name and brand to determine the category and type.\n\n"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
304 |
305 |         for i, product in enumerate(products, 1):
    |

B007 Loop control variable `product` not used within loop body
   --> src\core\classification\local_llm_classifier.py:346:24
    |
344 |                 # Convert to expected format
345 |                 batch_results = []
346 |                 for i, product in enumerate(products):
    |                        ^^^^^^^
347 |                     # Find classification for this product index
348 |                     product_classification = None
    |
help: Rename unused `product` to `_product`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\classification\local_llm_classifier.py:467:17
    |
466 | def get_local_llm_classifier(
467 |     model_name: str = None,
    |                 ^^^
468 |     product_taxonomy: dict[str, list[str]] = None,
469 |     product_pages: list[str] = None,
    |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\classification\local_llm_classifier.py:468:23
    |
466 | def get_local_llm_classifier(
467 |     model_name: str = None,
468 |     product_taxonomy: dict[str, list[str]] = None,
    |                       ^^^^^^^^^^^^^^^^^^^^
469 |     product_pages: list[str] = None,
470 | ) -> LocalLLMProductClassifier:
    |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\classification\local_llm_classifier.py:469:20
    |
467 |     model_name: str = None,
468 |     product_taxonomy: dict[str, list[str]] = None,
469 |     product_pages: list[str] = None,
    |                    ^^^^^^^^^
470 | ) -> LocalLLMProductClassifier:
471 |     """Get or create local LLM classifier instance."""
    |
help: Convert to `T | None`

PLW0603 Using the global statement to update `_local_llm_classifier` is discouraged
   --> src\core\classification\local_llm_classifier.py:472:12
    |
470 | ) -> LocalLLMProductClassifier:
471 |     """Get or create local LLM classifier instance."""
472 |     global _local_llm_classifier
    |            ^^^^^^^^^^^^^^^^^^^^^
473 |     if _local_llm_classifier is None:
474 |         try:
    |

PLW0603 Using the global statement to update `_local_llm_classifier` is discouraged
   --> src\core\classification\local_llm_classifier.py:489:12
    |
487 | def reset_local_llm_classifier():
488 |     """Reset the global classifier instance and clear cache (for testing)."""
489 |     global _local_llm_classifier
    |            ^^^^^^^^^^^^^^^^^^^^^
490 |     if _local_llm_classifier:
491 |         # Clear the cache file
    |

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\classification\local_llm_classifier.py:502:23
    |
500 | def classify_product_local_llm(
501 |     product_info: dict[str, Any],
502 |     product_taxonomy: dict[str, list[str]] = None,
    |                       ^^^^^^^^^^^^^^^^^^^^
503 |     product_pages: list[str] = None,
504 | ) -> dict[str, str]:
    |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\classification\local_llm_classifier.py:503:20
    |
501 |     product_info: dict[str, Any],
502 |     product_taxonomy: dict[str, list[str]] = None,
503 |     product_pages: list[str] = None,
    |                    ^^^^^^^^^
504 | ) -> dict[str, str]:
505 |     """
    |
help: Convert to `T | None`

B905 `zip()` without an explicit `strict=` parameter
   --> src\core\classification\local_llm_classifier.py:578:47
    |
576 |         results = classifier.classify_products_batch(test_products)
577 |
578 |         for i, (product, result) in enumerate(zip(test_products, results), 1):
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
579 |             print(f"\nðŸ“¦ Product {i}: {product['Name'][:50]}")
580 |             print(f"   Category: {result.get('category', 'N/A')}")
    |
help: Add explicit value for parameter `strict=`

E501 Line too long (123 > 100)
  --> src\core\classification\manager.py:74:101
   |
73 | CLASSIFICATION RULES:
74 | 1. **Prioritize the existing taxonomy.** If a product fits well into an existing category or product type, you must use it.
   |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^
75 | 2. If no suitable option exists, you may suggest a new one.
76 | 3. If you are uncertain, it is better to choose the closest existing match rather than creating a new one.
   |

E501 Line too long (106 > 100)
  --> src\core\classification\manager.py:76:101
   |
74 | 1. **Prioritize the existing taxonomy.** If a product fits well into an existing category or product type, you must use it.
75 | 2. If no suitable option exists, you may suggest a new one.
76 | 3. If you are uncertain, it is better to choose the closest existing match rather than creating a new one.
   |                                                                                                     ^^^^^^
77 |
78 | CRITICAL: You must respond with valid JSON only. No explanations, no markdown, no additional text.
   |

E501 Line too long (154 > 100)
  --> src\core\classification\manager.py:89:101
   |
87 | â€¦
88 | â€¦
89 | â€¦pe": "Dry Dog Food|Adult Dog Food", "product_on_pages": "Dog Food|All Pets|Pet Supplies"}}"""
   |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
90 | â€¦
91 | â€¦ exact JSON format:
   |

PLR0912 Too many branches (22 > 12)
   --> src\core\classification\manager.py:143:5
    |
143 | def classify_products_batch(products_list, method=None):
    |     ^^^^^^^^^^^^^^^^^^^^^^^
144 |     """
145 |     Classify multiple products using specified method.
    |

PLR0915 Too many statements (69 > 50)
   --> src\core\classification\manager.py:143:5
    |
143 | def classify_products_batch(products_list, method=None):
    |     ^^^^^^^^^^^^^^^^^^^^^^^
144 |     """
145 |     Classify multiple products using specified method.
    |

E501 Line too long (131 > 100)
   --> src\core\classification\manager.py:149:101
    |
147 |     Args:
148 |         products_list: List of product_info dictionaries to classify
149 |         method: Classification method - "llm" (OpenRouter API), "local_llm" (Ollama), "mock" (for testing). If None, uses settings.
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
150 |
151 |     Returns:
    |

E501 Line too long (104 > 100)
   --> src\core\classification\manager.py:162:101
    |
161 |     print(
162 |         f"[CLASSIFY] Batch Classification: Using {method} approach for {len(products_list)} products..."
    |                                                                                                     ^^^^
163 |     )
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:168:13
    |
166 |     if method == "llm":
167 |         try:
168 |             from src.core.classification.llm_classifier import get_llm_classifier
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
169 |         except ImportError:
170 |             try:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:171:17
    |
169 |         except ImportError:
170 |             try:
171 |                 from llm_classifier import get_llm_classifier
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
172 |             except ImportError:
173 |                 print("[WARNING] Could not import LLM classifier")
    |

E501 Line too long (115 > 100)
   --> src\core\classification\manager.py:199:101
    |
198 |                 print(
199 |                     f"[SUCCESS] LLM batch classification complete! Processed {len(classified_products)} products\n"
    |                                                                                                     ^^^^^^^^^^^^^^^
200 |                 )
201 |                 return classified_products
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:210:13
    |
208 |     if method == "local_llm":
209 |         try:
210 |             from src.core.classification.local_llm_classifier import get_local_llm_classifier
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
211 |         except ImportError:
212 |             try:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:213:17
    |
211 |         except ImportError:
212 |             try:
213 |                 from local_llm_classifier import get_local_llm_classifier
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
214 |             except ImportError:
215 |                 print("[WARNING] Could not import local LLM classifier")
    |

B905 `zip()` without an explicit `strict=` parameter
   --> src\core\classification\manager.py:251:49
    |
250 |                     # Convert results back to expected format
251 |                     for product_info, result in zip(batch, batch_results):
    |                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
252 |                         product_copy = product_info.copy()
253 |                         product_copy["Category"] = result.get("category", "")
    |
help: Add explicit value for parameter `strict=`

E501 Line too long (121 > 100)
   --> src\core\classification\manager.py:259:101
    |
258 |                 print(
259 |                     f"[SUCCESS] Local_Llm batch classification complete! Processed {len(classified_products)} products\n"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^
260 |                 )
261 |                 return classified_products
    |

E501 Line too long (102 > 100)
   --> src\core\classification\manager.py:266:101
    |
264 |         except Exception as e:
265 |             print(
266 |                 f"[WARNING] Local LLM batch classification failed: {e}, leaving products unclassified"
    |                                                                                                     ^^
267 |             )
    |

E501 Line too long (116 > 100)
   --> src\core\classification\manager.py:281:101
    |
280 |     print(
281 |         f"[SUCCESS] {method.title()} batch classification complete! Processed {len(classified_products)} products\n"
    |                                                                                                     ^^^^^^^^^^^^^^^^
282 |     )
283 |     return classified_products
    |

PLR0912 Too many branches (15 > 12)
   --> src\core\classification\manager.py:286:5
    |
286 | def classify_single_product(product_info, method=None):
    |     ^^^^^^^^^^^^^^^^^^^^^^^
287 |     """
288 |     Classify a single product using LLM classification.
    |

E501 Line too long (131 > 100)
   --> src\core\classification\manager.py:292:101
    |
290 |     Args:
291 |         product_info: Dict with product details
292 |         method: Classification method - "llm" (OpenRouter API), "local_llm" (Ollama), "mock" (for testing). If None, uses settings.
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
293 |
294 |     Returns:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:309:13
    |
307 |     if method == "llm":
308 |         try:
309 |             from src.core.classification.llm_classifier import classify_product_llm
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
310 |         except ImportError:
311 |             try:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:312:17
    |
310 |         except ImportError:
311 |             try:
312 |                 from llm_classifier import classify_product_llm
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
313 |             except ImportError:
314 |                 print("[WARNING] Could not import LLM classifier")
    |

E501 Line too long (108 > 100)
   --> src\core\classification\manager.py:328:101
    |
327 |             print(
328 |                 f"[LLM] LLM classification: {product_name[:40]}... -> {product_info.get('Category', 'N/A')}"
    |                                                                                                     ^^^^^^^^
329 |             )
330 |             return product_info
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:338:13
    |
336 |     elif method == "local_llm":
337 |         try:
338 |             from src.core.classification.local_llm_classifier import classify_product_local_llm
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
339 |         except ImportError:
340 |             try:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\manager.py:341:17
    |
339 |         except ImportError:
340 |             try:
341 |                 from local_llm_classifier import classify_product_local_llm
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
342 |             except ImportError:
343 |                 print("[WARNING] Could not import local LLM classifier")
    |

E501 Line too long (116 > 100)
   --> src\core\classification\manager.py:359:101
    |
358 |             print(
359 |                 f"[LOCAL] Local LLM classification: {product_name[:40]}... -> {product_info.get('Category', 'N/A')}"
    |                                                                                                     ^^^^^^^^^^^^^^^^
360 |             )
361 |             return product_info
    |

E501 Line too long (106 > 100)
   --> src\core\classification\manager.py:374:101
    |
373 |         print(
374 |             f"[MOCK] Mock classification: {product_name[:40]}... -> {product_info.get('Category', 'N/A')}"
    |                                                                                                     ^^^^^^
375 |         )
376 |         return product_info
    |

E501 Line too long (108 > 100)
   --> src\core\classification\manager.py:489:101
    |
487 |         else:
488 |             print(
489 |                 f"FAIL: Batch processing failed: expected {len(test_products)}, got {len(classified_batch)}"
    |                                                                                                     ^^^^^^^^
490 |             )
    |

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\taxonomy_manager.py:14:39
   |
12 |     """Manages product taxonomy with database integration"""
13 |
14 |     def __init__(self, taxonomy_file: str = None, db_path: str = None):
   |                                       ^^^
15 |         """
16 |         Initialize taxonomy manager
   |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\classification\taxonomy_manager.py:14:60
   |
12 |     """Manages product taxonomy with database integration"""
13 |
14 |     def __init__(self, taxonomy_file: str = None, db_path: str = None):
   |                                                            ^^^
15 |         """
16 |         Initialize taxonomy manager
   |
help: Convert to `T | None`

E501 Line too long (103 > 100)
   --> src\core\classification\taxonomy_manager.py:176:101
    |
175 |                 if category and product_type:
176 |                     # Split combined categories on "|" and add product type to each individual category
    |                                                                                                     ^^^
177 |                     individual_categories = [
178 |                         cat.strip() for cat in category.split("|") if cat.strip()
    |

RUF001 String contains ambiguous `âž•` (HEAVY PLUS SIGN). Did you mean `+` (PLUS SIGN)?
   --> src\core\classification\taxonomy_manager.py:226:25
    |
224 |             if category not in updated_taxonomy:
225 |                 updated_taxonomy[category] = []
226 |                 print(f"âž• Added new category: {category}")
    |                         ^^
227 |
228 |         # Add new product types to existing categories
    |

RUF001 String contains ambiguous `âž•` (HEAVY PLUS SIGN). Did you mean `+` (PLUS SIGN)?
   --> src\core\classification\taxonomy_manager.py:239:23
    |
237 |                 updated_taxonomy[category].extend(sorted(new_types))
238 |                 print(
239 |                     f"âž• Added {len(new_types)} new product types to {category}: {sorted(new_types)}"
    |                       ^^
240 |                 )
    |

E501 Line too long (101 > 100)
   --> src\core\classification\taxonomy_manager.py:239:100
    |
237 |                 updated_taxonomy[category].extend(sorted(new_types))
238 |                 print(
239 |                     f"âž• Added {len(new_types)} new product types to {category}: {sorted(new_types)}"
    |                                                                                                     ^
240 |                 )
    |

PLW0603 Using the global statement to update `_taxonomy_manager` is discouraged
   --> src\core\classification\taxonomy_manager.py:510:12
    |
508 | def get_taxonomy_manager() -> TaxonomyManager:
509 |     """Get global taxonomy manager instance"""
510 |     global _taxonomy_manager
    |            ^^^^^^^^^^^^^^^^^
511 |     if _taxonomy_manager is None:
512 |         _taxonomy_manager = TaxonomyManager()
    |

B007 Loop control variable `i` not used within loop body
   --> src\core\classification\taxonomy_manager.py:546:9
    |
544 |     # Show sample
545 |     print("\nðŸ“‹ Sample categories:")
546 |     for i, (category, types) in enumerate(list(updated_taxonomy.items())[:3]):
    |         ^
547 |         print(f"   {category}: {len(types)} types")
548 |         if types:
    |
help: Rename unused `i` to `_i`

E402 Module level import not at top of file
  --> src\core\classification\ui.py:22:1
   |
21 | # Check if we're running under pytest by inspecting the call stack
22 | import inspect
   | ^^^^^^^^^^^^^^
23 |
24 | is_pytest = any("pytest" in str(frame) for frame in inspect.stack())
   |

E501 Line too long (133 > 100)
  --> src\core\classification\ui.py:82:101
   |
80 |         print(f"âš ï¸ PyQt6 GUI not available (headless environment): {e}")
81 |
82 | # Import product pages from manager (which loads from JSON) - moved inside function to avoid relative import issues when run directly
   |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
83 | # from .manager import PRODUCT_PAGES
   |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\ui.py:98:9
    |
 96 |     try:
 97 |         # Load taxonomy from JSON via taxonomy manager
 98 |         from .taxonomy_manager import get_product_taxonomy
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 99 |
100 |         category_product_types = get_product_taxonomy()
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\classification\ui.py:103:9
    |
102 |         # Load product pages from JSON via manager
103 |         from .manager import get_product_pages
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
104 |
105 |         product_on_pages_options = get_product_pages()
    |

E501 Line too long (121 > 100)
   --> src\core\classification\ui.py:248:101
    |
246 | def assign_classification_batch(products_list):
247 |     """
248 |     Assign classification (Category, Product Type, Product On Pages) to multiple products using the interactive batch UI.
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^
249 |     Always uses the UI, even for a single product.
250 |     Args:
    |

E501 Line too long (105 > 100)
   --> src\core\classification\ui.py:259:100
    |
257 |     results = edit_classification_in_batch(products_list)
258 |     print(
259 |         f"\033[92mâœ… Classification assignment (UI) complete! Processed {len(results)} products\033[0m\n"
    |                                                                                                     ^^^^^
260 |     )
261 |     return results
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> src\core\classification\ui.py:386:25
    |
385 |         def on_available_changed(self, option, state):
386 |             if state == 2:  # Checked
    |                         ^
387 |                 self.selected_items.add(option)
388 |                 self.selection_changed.emit()
    |

E501 Line too long (112 > 100)
   --> src\core\classification\ui.py:825:101
    |
823 |         if image_url:
824 |             try:
825 |                 # For now, just show the URL since we can't easily load images in PyQt6 without additional setup
    |                                                                                                     ^^^^^^^^^^^^
826 |                 # In a real implementation, you'd use QNetworkAccessManager or similar
827 |                 self.image_display.setText(f"Image URL:\n{image_url}")
    |

E501 Line too long (111 > 100)
   --> src\core\classification\ui.py:909:100
    |
907 |         print(f"ðŸ’¾ Products reviewed: {self.current_index + 1}")
908 |         print(
909 |             f"ðŸ¤– Products with auto-classifications only: {len(self.products_list) - (self.current_index + 1)}"
    |                                                                                                     ^^^^^^^^^^^
910 |         )
911 |         self.close()
    |

PLR0912 Too many branches (18 > 12)
   --> src\core\classification\ui.py:931:5
    |
931 | def edit_classification_in_batch(products_list):
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
932 |     """
933 |     Interactive batch editor for product classification fields (Category, Product Type, Product On Pages).
    |

E501 Line too long (106 > 100)
   --> src\core\classification\ui.py:933:101
    |
931 | def edit_classification_in_batch(products_list):
932 |     """
933 |     Interactive batch editor for product classification fields (Category, Product Type, Product On Pages).
    |                                                                                                     ^^^^^^
934 |     Focused on classification selection.
935 |     Returns updated products_list with selected classifications.
    |

N806 Variable `CATEGORY_PRODUCT_TYPES` in function should be lowercase
   --> src\core\classification\ui.py:943:5
    |
942 |     # Import facet options only
943 |     CATEGORY_PRODUCT_TYPES, PRODUCT_ON_PAGES_OPTIONS = get_facet_options_from_db()
    |     ^^^^^^^^^^^^^^^^^^^^^^
944 |
945 |     # For consolidated products, augment available options with any categories/types/pages found in scraped data
    |

N806 Variable `PRODUCT_ON_PAGES_OPTIONS` in function should be lowercase
   --> src\core\classification\ui.py:943:29
    |
942 |     # Import facet options only
943 |     CATEGORY_PRODUCT_TYPES, PRODUCT_ON_PAGES_OPTIONS = get_facet_options_from_db()
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^
944 |
945 |     # For consolidated products, augment available options with any categories/types/pages found in scraped data
    |

E501 Line too long (112 > 100)
   --> src\core\classification\ui.py:945:101
    |
943 |     CATEGORY_PRODUCT_TYPES, PRODUCT_ON_PAGES_OPTIONS = get_facet_options_from_db()
944 |
945 |     # For consolidated products, augment available options with any categories/types/pages found in scraped data
    |                                                                                                     ^^^^^^^^^^^^
946 |     # that aren't already in the database
947 |     if products_list and any("_consolidated_data" in p for p in products_list):
    |

E501 Line too long (102 > 100)
   --> src\core\classification\ui.py:949:101
    |
947 |     if products_list and any("_consolidated_data" in p for p in products_list):
948 |         print(
949 |             "EDITOR DEBUG: Found consolidated products, augmenting facet options with scraped data..."
    |                                                                                                     ^^
950 |         )
    |

N806 Variable `CATEGORY_OPTIONS` in function should be lowercase
    --> src\core\classification\ui.py:1004:5
     |
1003 |     # Extract categories and all product types
1004 |     CATEGORY_OPTIONS = sorted(CATEGORY_PRODUCT_TYPES.keys(), key=str.lower)
     |     ^^^^^^^^^^^^^^^^
1005 |     ALL_PRODUCT_TYPES = sorted(
1006 |         set(ptype for types in CATEGORY_PRODUCT_TYPES.values() for ptype in types),
     |

N806 Variable `ALL_PRODUCT_TYPES` in function should be lowercase
    --> src\core\classification\ui.py:1005:5
     |
1003 |     # Extract categories and all product types
1004 |     CATEGORY_OPTIONS = sorted(CATEGORY_PRODUCT_TYPES.keys(), key=str.lower)
1005 |     ALL_PRODUCT_TYPES = sorted(
     |     ^^^^^^^^^^^^^^^^^
1006 |         set(ptype for types in CATEGORY_PRODUCT_TYPES.values() for ptype in types),
1007 |         key=str.lower,
     |

E501 Line too long (150 > 100)
    --> src\core\classification\ui.py:1102:101
     |
1100 | â€¦
1101 | â€¦
1102 | â€¦ '')}', Type='{prod.get('Product Type', '')}', Pages='{prod.get('Product On Pages', '')}'"
     |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1103 | â€¦
     |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> src\core\data_quality_scorer.py:18:23
   |
16 |       """
17 |
18 |       REQUIRED_FIELDS = [
   |  _______________________^
19 | |         "SKU",
20 | |         "Name",
21 | |         "Price",
22 | |         "Images",
23 | |         "Weight",
24 | |         "Product_Field_16",  # Brand
25 | |         "Product_Field_24",  # Category
26 | |         "Product_Field_25",  # Product Type
27 | |     ]
   | |_____^
28 |
29 |       INVALID_VALUES = {"", "N/A", "null", "NULL", None}
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> src\core\data_quality_scorer.py:29:22
   |
27 |     ]
28 |
29 |     INVALID_VALUES = {"", "N/A", "null", "NULL", None}
   |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 |
31 |     # Weight conversion factors to LB
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> src\core\data_quality_scorer.py:32:20
   |
31 |       # Weight conversion factors to LB
32 |       WEIGHT_UNITS = {
   |  ____________________^
33 | |         "lb": 1.0,
34 | |         "lbs": 1.0,
35 | |         "oz": 1 / 16.0,
36 | |         "kg": 2.20462,
37 | |         "g": 0.00220462,
38 | |         "gram": 0.00220462,
39 | |         "grams": 0.00220462,
40 | |     }
   | |_____^
41 |
42 |       def __init__(self):
   |

E722 Do not use bare `except`
   --> src\core\data_quality_scorer.py:220:9
    |
218 |             else:
219 |                 return 0, {"normalized": None, "valid": False}
220 |         except:
    |         ^^^^^^
221 |             return 0, {"normalized": None, "valid": False}
    |

E722 Do not use bare `except`
   --> src\core\data_quality_scorer.py:262:9
    |
260 |             parsed = urlparse(url)
261 |             return parsed.scheme in ("http", "https") and bool(parsed.netloc)
262 |         except:
    |         ^^^^^^
263 |             return False
    |

E722 Do not use bare `except`
   --> src\core\data_quality_scorer.py:278:9
    |
276 |                 "value": price_value,
277 |             }
278 |         except:
    |         ^^^^^^
279 |             return 0, {"numeric": False, "value": None}
    |

PLR2004 Magic value used in comparison, consider replacing `200` with a constant variable
   --> src\core\data_quality_scorer.py:295:34
    |
293 |         if re.match(r"^\d+$", name):
294 |             return False
295 |         return 1 <= len(name) <= 200
    |                                  ^^^
296 |
297 |     def _is_text_field_consistent(self, value: str) -> bool:
    |

PLR2004 Magic value used in comparison, consider replacing `100` with a constant variable
   --> src\core\data_quality_scorer.py:301:43
    |
299 |         if not value or value in self.INVALID_VALUES:
300 |             return False
301 |         return 1 <= len(value.strip()) <= 100
    |                                           ^^^
    |

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\database\queries.py:12:33
   |
11 | class ProductDatabase:
12 |     def __init__(self, db_path: str = None):
   |                                 ^^^
13 |         if db_path is None:
14 |             script_dir = os.path.dirname(os.path.abspath(__file__))
   |
help: Convert to `T | None`

B905 `zip()` without an explicit `strict=` parameter
  --> src\core\database\queries.py:64:32
   |
63 |             for row in cursor.fetchall():
64 |                 product = dict(zip(columns, row))
   |                                ^^^^^^^^^^^^^^^^^
65 |
66 |                 # No extra_data JSON parsing needed for current schema
   |
help: Add explicit value for parameter `strict=`

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
  --> src\core\database\queries.py:72:13
   |
71 |         except sqlite3.Error as e:
72 |             raise Exception(f"SQL Error: {e}")
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
73 |
74 |     def search_products(self, field: str, value: str, limit: int = 20) -> list[dict[str, Any]]:
   |

B905 `zip()` without an explicit `strict=` parameter
   --> src\core\database\queries.py:105:28
    |
104 |         for row in cursor.fetchall():
105 |             product = dict(zip(columns, row))
    |                            ^^^^^^^^^^^^^^^^^
106 |             results.append(product)
    |
help: Add explicit value for parameter `strict=`

PLR0912 Too many branches (17 > 12)
   --> src\core\database\queries.py:111:5
    |
111 | def main():
    |     ^^^^
112 |     db = ProductDatabase()
    |

PLR0915 Too many statements (63 > 50)
   --> src\core\database\queries.py:111:5
    |
111 | def main():
    |     ^^^^
112 |     db = ProductDatabase()
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> src\core\database\queries.py:123:26
    |
121 |         print(f"ðŸ“‹ Available fields: {len(fields)} total")
122 |         print("Common fields:", ", ".join(fields[:10]))
123 |         if len(fields) > 10:
    |                          ^^
124 |             print(f"... and {len(fields) - 10} more")
    |

E501 Line too long (120 > 100)
   --> src\core\database\queries.py:131:101
    |
129 |         print("2. Custom SQL: SELECT * FROM products WHERE SKU LIKE '2028%'")
130 |         print(
131 |             "3. Count by category: SELECT Category, COUNT(*) FROM products WHERE Category IS NOT NULL GROUP BY Category"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^
132 |         )
133 |         print("=" * 50)
    |

PLR2004 Magic value used in comparison, consider replacing `5` with a constant variable
   --> src\core\database\queries.py:154:39
    |
152 |                         name = product.get("extra_data", {}).get("Name", "No Name")
153 |                         print(f"  {i}. {sku}: {name}")
154 |                     if len(results) > 5:
    |                                       ^
155 |                         print(f"     ... and {len(results) - 5} more")
156 |                 except Exception as e:
    |

E501 Line too long (191 > 100)
   --> src\core\database\queries.py:161:101
    |
159 | â€¦
160 | â€¦
161 | â€¦Images, Weight, Brand, Special_Order, Category, Product_Type, Product_On_Pages, ProductDisabled, last_updated)"
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
162 | â€¦
163 | â€¦
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> src\core\database\queries.py:170:43
    |
168 |                         for i, product in enumerate(results[:10], 1):  # Show first 10
169 |                             print(f"  {i}. {product}")
170 |                         if len(results) > 10:
    |                                           ^^
171 |                             print(f"     ... and {len(results) - 10} more")
172 |                     except Exception as e:
    |

RUF013 PEP 484 prohibits implicit `Optional`
  --> src\core\database\refresh.py:17:33
   |
15 |     """SQLite database manager for ShopSite products."""
16 |
17 |     def __init__(self, db_path: str = None):
   |                                 ^^^
18 |         if db_path is None:
19 |             script_dir = os.path.dirname(os.path.abspath(__file__))
   |
help: Convert to `T | None`

E501 Line too long (102 > 100)
  --> src\core\database\refresh.py:34:101
   |
33 |             if table_exists:
34 |                 # Check current schema - look for old column names to determine if migration is needed
   |                                                                                                     ^^
35 |                 cursor.execute("PRAGMA table_info(products)")
36 |                 columns_info = cursor.fetchall()
   |

E501 Line too long (102 > 100)
  --> src\core\database\refresh.py:49:101
   |
47 |                 has_old_schema = any(col in columns for col in old_schema_indicators)
48 |
49 |                 # Check if we have new schema columns (raw ShopSite columns with single Images column)
   |                                                                                                     ^^
50 |                 new_schema_columns = [
51 |                     "SKU",
   |

E501 Line too long (114 > 100)
  --> src\core\database\refresh.py:94:101
   |
92 |                         SELECT id, sku, name, '', '[]', weight,
93 |                                Product_Field_16, Product_Field_11,
94 |                                Product_Field_24, Product_Field_25, Product_On_Pages, ProductDisabled, last_updated
   |                                                                                                     ^^^^^^^^^^^^^^
95 |                         FROM products
96 |                     """
   |

E501 Line too long (103 > 100)
   --> src\core\database\refresh.py:108:101
    |
106 |                     conn.execute("CREATE INDEX IF NOT EXISTS idx_brand ON products(Brand)")
107 |                     conn.execute(
108 |                         "CREATE INDEX IF NOT EXISTS idx_product_on_pages ON products(Product_On_Pages)"
    |                                                                                                     ^^^
109 |                     )
    |

PLR0912 Too many branches (23 > 12)
   --> src\core\database\refresh.py:394:5
    |
394 | def parse_xml_file_to_dataframe(xml_file_path: str) -> pd.DataFrame | None:
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
395 |     """Parse a local ShopSite XML file to pandas DataFrame."""
396 |     try:
    |

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\database\refresh.py:485:34
    |
484 | def process_xml_to_database(
485 |     xml_file_path: str, db_path: str = None, clear_existing: bool = True
    |                                  ^^^
486 | ) -> bool:
487 |     """
    |
help: Convert to `T | None`

E501 Line too long (106 > 100)
   --> src\core\database\refresh.py:516:100
    |
514 |         duration = (end_time - start_time).total_seconds()
515 |         logging.info(
516 |             f"âš¡ Batch insert completed in {duration:.2f} seconds ({len(df) / duration:.0f} products/sec)"
    |                                                                                                     ^^^^^^
517 |         )
    |

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\database\refresh.py:529:60
    |
529 | def refresh_database_from_xml(xml_file_path: str, db_path: str = None) -> tuple[bool, str]:
    |                                                            ^^^
530 |     """
531 |     Refresh the local database with new XML data.
    |
help: Convert to `T | None`

F401 `..field_mapping.REQUIRED_FIELDS` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src\core\database\xml_import.py:17:33
   |
15 | # Import field mapping configuration
16 | try:
17 |     from ..field_mapping import REQUIRED_FIELDS, map_shopsite_fields
   |                                 ^^^^^^^^^^^^^^^
18 | except ImportError:
19 |     # Fallback for standalone execution
   |
help: Remove unused import: `..field_mapping.REQUIRED_FIELDS`

PLR0912 Too many branches (17 > 12)
   --> src\core\database\xml_import.py:218:9
    |
216 |         return True
217 |
218 |     def download_products_xml(self) -> str | None:
    |         ^^^^^^^^^^^^^^^^^^^^^
219 |         """Download products database as XML from ShopSite with progress tracking."""
220 |         try:
    |

PLR0915 Too many statements (73 > 50)
   --> src\core\database\xml_import.py:218:9
    |
216 |         return True
217 |
218 |     def download_products_xml(self) -> str | None:
    |         ^^^^^^^^^^^^^^^^^^^^^
219 |         """Download products database as XML from ShopSite with progress tracking."""
220 |         try:
    |

PLR2004 Magic value used in comparison, consider replacing `200` with a constant variable
   --> src\core\database\xml_import.py:237:40
    |
235 |             )
236 |
237 |             if response.status_code == 200:
    |                                        ^^^
238 |                 import time
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\database\xml_import.py:238:17
    |
237 |             if response.status_code == 200:
238 |                 import time
    |                 ^^^^^^^^^^^
239 |
240 |                 # Try to estimate total size based on previous downloads
    |

E501 Line too long (107 > 100)
   --> src\core\database\xml_import.py:246:100
    |
244 |                     estimated_mb = estimated_size / (1024 * 1024)
245 |                     self.log(
246 |                         f"ðŸ“Š Estimated download size: ~{estimated_mb:.1f} MB (based on previous downloads)"
    |                                                                                                     ^^^^^^^
247 |                     )
    |

PLR2004 Magic value used in comparison, consider replacing `3600` with a constant variable
   --> src\core\database\xml_import.py:274:46
    |
272 | â€¦                     eta_str = (
273 | â€¦                         f" ETA: {eta:.0f}s"
274 | â€¦                         if eta < 3600
    |                                    ^^^^
275 | â€¦                         else f" ETA: {eta / 3600:.1f}h"
276 | â€¦                     )
    |

PLR2004 Magic value used in comparison, consider replacing `8192` with a constant variable
   --> src\core\database\xml_import.py:283:67
    |
281 | â€¦                     current_time = time.time()
282 | â€¦                     if (
283 | â€¦                         downloaded_size % (1024 * 1024) < 8192  # Every ~1MB
    |                                                             ^^^^
284 | â€¦                         or current_time - (getattr(self, "last_progress_time", 0)) > 5
285 | â€¦                     ):  # Or every 5 seconds
    |

PLR2004 Magic value used in comparison, consider replacing `5` with a constant variable
   --> src\core\database\xml_import.py:284:94
    |
282 | â€¦                     if (
283 | â€¦                         downloaded_size % (1024 * 1024) < 8192  # Every ~1MB
284 | â€¦                         or current_time - (getattr(self, "last_progress_time", 0)) > 5
    |                                                                                        ^
285 | â€¦                     ):  # Or every 5 seconds
286 | â€¦                         downloaded_mb = downloaded_size / (1024 * 1024)
    |

E501 Line too long (127 > 100)
   --> src\core\database\xml_import.py:288:100
    |
286 | â€¦                     downloaded_mb = downloaded_size / (1024 * 1024)
287 | â€¦                     total_mb = total_size / (1024 * 1024)
288 | â€¦                     progress_msg = f"ðŸ“¥ Progress: {progress:.1f}% ({downloaded_mb:.1f}/{total_mb:.1f} MB){eta_str}"
    |                                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
289 | â€¦                     self.log(progress_msg)
290 | â€¦                     self.last_progress_time = current_time
    |

PLR2004 Magic value used in comparison, consider replacing `5` with a constant variable
   --> src\core\database\xml_import.py:303:88
    |
301 | â€¦                     # Send progress update to log callback (every 5 seconds)
302 | â€¦                     current_time = time.time()
303 | â€¦                     if current_time - getattr(self, "last_progress_time", 0) > 5:
    |                                                                                  ^
304 | â€¦                         downloaded_mb = downloaded_size / (1024 * 1024)
305 | â€¦                         progress_msg = f"ðŸ“¥ Downloaded: {downloaded_mb:.1f} MB{speed_str} ({elapsed:.1f}s elapsed)"
    |

E501 Line too long (123 > 100)
   --> src\core\database\xml_import.py:305:100
    |
303 | â€¦                     if current_time - getattr(self, "last_progress_time", 0) > 5:
304 | â€¦                         downloaded_mb = downloaded_size / (1024 * 1024)
305 | â€¦                         progress_msg = f"ðŸ“¥ Downloaded: {downloaded_mb:.1f} MB{speed_str} ({elapsed:.1f}s elapsed)"
    |                                                                                               ^^^^^^^^^^^^^^^^^^^^^^^
306 | â€¦                         self.log(progress_msg)
307 | â€¦                         self.last_progress_time = current_time
    |

E501 Line too long (134 > 100)
   --> src\core\database\xml_import.py:312:100
    |
310 | â€¦     downloaded_mb = downloaded_size / (1024 * 1024)
311 | â€¦     speed_mbps = (downloaded_size / (time.time() - start_time)) / (1024 * 1024)
312 | â€¦     final_msg = f"ðŸ“¥ Downloaded: {downloaded_mb:.1f} MB @ {speed_mbps:.2f} MB/s ({time.time() - start_time:.1f}s elapsed)"
    |                                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
313 | â€¦     self.log(final_msg)
    |

RUF013 PEP 484 prohibits implicit `Optional`
   --> src\core\database\xml_import.py:345:32
    |
344 | def save_dataframe_to_database(
345 |     df: pd.DataFrame, db_path: str = None, clear_existing: bool = True
    |                                ^^^
346 | ) -> tuple[bool, str]:
347 |     """Save DataFrame directly to SQLite database."""
    |
help: Convert to `T | None`

PLR0912 Too many branches (22 > 12)
   --> src\core\database\xml_import.py:479:5
    |
479 | def parse_xml_to_dataframe(xml_content: str) -> pd.DataFrame | None:
    |     ^^^^^^^^^^^^^^^^^^^^^^
480 |     """Parse ShopSite XML content to pandas DataFrame."""
481 |     try:
    |

PLR0915 Too many statements (74 > 50)
   --> src\core\database\xml_import.py:479:5
    |
479 | def parse_xml_to_dataframe(xml_content: str) -> pd.DataFrame | None:
    |     ^^^^^^^^^^^^^^^^^^^^^^
480 |     """Parse ShopSite XML content to pandas DataFrame."""
481 |     try:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\database\xml_import.py:483:9
    |
481 |     try:
482 |         # Preprocess XML to handle HTML entities that aren't valid in XML
483 |         import re
    |         ^^^^^^^^^
484 |
485 |         # Replace common HTML entities with XML-safe equivalents
    |

E501 Line too long (101 > 100)
   --> src\core\database\xml_import.py:559:101
    |
557 |         # Use regex to only replace ampersands that are NOT already part of XML entities
558 |
559 |         # Replace & that is not followed by a valid entity pattern (letters, numbers, #, or ; at end)
    |                                                                                                     ^
560 |         xml_content = re.sub(r"&(?![a-zA-Z0-9#]+;)", "&amp;", xml_content)
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\database\xml_import.py:571:21
    |
569 |                 # Try to get the numeric value using html.entities if available
570 |                 try:
571 |                     import html.entities
    |                     ^^^^^^^^^^^^^^^^^^^^
572 |
573 |                     if entity in html.entities.name2codepoint:
    |

E501 Line too long (108 > 100)
   --> src\core\database\xml_import.py:622:101
    |
620 |                 for child in product_elem:
621 |                     if child.tag == "ProductOnPages":
622 |                         # Special handling for ProductOnPages - it's a container with PageLink/Name elements
    |                                                                                                     ^^^^^^^^
623 |                         page_names = []
624 |                         # Look for Name elements under PageLink elements
    |

E501 Line too long (112 > 100)
   --> src\core\database\xml_import.py:655:101
    |
653 |                 for subchild in list(child)[:3]:
654 |                     logging.info(
655 |                         f"  Subchild: {subchild.tag}, text length: {len(subchild.text) if subchild.text else 0}"
    |                                                                                                     ^^^^^^^^^^^^
656 |                     )
    |

PLR2004 Magic value used in comparison, consider replacing `200` with a constant variable
   --> src\core\database\xml_import.py:674:91
    |
672 |                 marker = ">>> " if i == error_line else "    "
673 |                 logging.error(
674 |                     f"{marker}Line {i}: {lines[i - 1][:200]}{'...' if len(lines[i - 1]) > 200 else ''}"
    |                                                                                           ^^^
675 |                 )
    |

E501 Line too long (103 > 100)
   --> src\core\database\xml_import.py:674:101
    |
672 |                 marker = ">>> " if i == error_line else "    "
673 |                 logging.error(
674 |                     f"{marker}Line {i}: {lines[i - 1][:200]}{'...' if len(lines[i - 1]) > 200 else ''}"
    |                                                                                                     ^^^
675 |                 )
    |

PLR0911 Too many return statements (7 > 6)
   --> src\core\database\xml_import.py:692:5
    |
692 | def import_from_shopsite_xml(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^
693 |     save_excel: bool = True,
694 |     save_to_db: bool = False,
    |

PLR0912 Too many branches (14 > 12)
   --> src\core\database\xml_import.py:692:5
    |
692 | def import_from_shopsite_xml(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^
693 |     save_excel: bool = True,
694 |     save_to_db: bool = False,
    |

E501 Line too long (101 > 100)
   --> src\core\database\xml_import.py:715:100
    |
713 |         return (
714 |             False,
715 |             "âŒ Failed to authenticate with ShopSite XML interface. Check credentials in .env file.",
    |                                                                                                     ^
716 |         )
    |

PLR0913 Too many arguments in function definition (6 > 5)
   --> src\core\database\xml_import.py:780:5
    |
779 | # For backwards compatibility
780 | def publish_shopsite_changes(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^
781 |     html_pages: bool = True,
782 |     custom_pages: bool = True,
    |

PLR0912 Too many branches (14 > 12)
   --> src\core\database\xml_import.py:780:5
    |
779 | # For backwards compatibility
780 | def publish_shopsite_changes(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^
781 |     html_pages: bool = True,
782 |     custom_pages: bool = True,
    |

PLR2004 Magic value used in comparison, consider replacing `200` with a constant variable
   --> src\core\database\xml_import.py:849:36
    |
847 |         response = session.get(publish_url, params=params, timeout=600)  # 10 minute timeout
848 |
849 |         if response.status_code == 200:
    |                                    ^^^
850 |             success_msg = "âœ… ShopSite publish completed successfully"
851 |             log(success_msg)
    |

E501 Line too long (126 > 100)
   --> src\core\database\xml_import.py:855:100
    |
853 |             # Check response content for any messages
854 |             if response.text.strip():
855 |                 content_msg = f"ðŸ“„ Response: {response.text.strip()[:200]}{'...' if len(response.text.strip()) > 200 else ''}"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
856 |                 log(content_msg)
    |

PLR2004 Magic value used in comparison, consider replacing `200` with a constant variable
   --> src\core\database\xml_import.py:855:113
    |
853 |             # Check response content for any messages
854 |             if response.text.strip():
855 |                 content_msg = f"ðŸ“„ Response: {response.text.strip()[:200]}{'...' if len(response.text.strip()) > 200 else ''}"
    |                                                                                                                  ^^^
856 |                 log(content_msg)
    |

PLC0415 `import` should be at the top-level of a file
   --> src\core\database\xml_import.py:938:5
    |
937 | def main() -> None:
938 |     import sys
    |     ^^^^^^^^^^
939 |
940 |     # Check for command line arguments
    |

E501 Line too long (107 > 100)
   --> src\core\failure_analytics.py:111:101
    |
110 |         logger.info(
111 |             f"FailureAnalytics initialized with max_records={max_records}, retention={retention_days} days"
    |                                                                                                     ^^^^^^^
112 |         )
    |

PLR0913 Too many arguments in function definition (11 > 5)
   --> src\core\failure_analytics.py:114:9
    |
112 |         )
113 |
114 |     def record_failure(
    |         ^^^^^^^^^^^^^^
115 |         self,
116 |         site_name: str,
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> src\core\failure_analytics.py:170:27
    |
169 |         # Lightweight logging - only log significant failures
170 |         if retry_count >= 3 or failure_type in [
    |                           ^
171 |             FailureType.ACCESS_DENIED,
172 |             FailureType.RATE_LIMITED,
    |

F841 Local variable `cutoff_time` is assigned to but never used
   --> src\core\failure_analytics.py:240:9
    |
238 |             Nested dictionary of failure patterns
239 |         """
240 |         cutoff_time = time.time() - (hours * 3600)
    |         ^^^^^^^^^^^
241 |
242 |         with self._lock:
    |
help: Remove assignment to unused variable `cutoff_time`

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> src\core\failure_analytics.py:443:35
    |
441 |         if failure_counts.get("rate_limited", 0) > 0:
442 |             rate_limited_pct = failure_counts["rate_limited"] / sum(failure_counts.values())
443 |             if rate_limited_pct > 0.3:
    |                                   ^^^
444 |                 recommendations.append(
445 |                     "High rate limiting detected. Consider increasing delays between requests "
    |

PLR2004 Magic value used in comparison, consider replacing `0.2` with a constant variable
   --> src\core\failure_analytics.py:452:30
    |
450 |         if failure_counts.get("captcha_detected", 0) > 0:
451 |             captcha_pct = failure_counts["captcha_detected"] / sum(failure_counts.values())
452 |             if captcha_pct > 0.2:
    |                              ^^^
453 |                 recommendations.append(
454 |                     "Frequent CAPTCHA detection. Consider implementing automated CAPTCHA solving "
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> src\core\failure_analytics.py:467:27
    |
465 |         # Site-specific recommendations
466 |         for site, failures in site_failures.items():
467 |             if failures > 10:  # Arbitrary threshold
    |                           ^^
468 |                 recommendations.append(
469 |                     f"High failure rate for {site}. Consider reviewing site-specific configuration "
    |

PLR2004 Magic value used in comparison, consider replacing `5` with a constant variable
   --> src\core\failure_analytics.py:474:46
    |
473 |         # Action-specific recommendations
474 |         if action_failures.get("login", 0) > 5:
    |                                              ^
475 |             recommendations.append(
476 |                 "Login failures detected. Verify credentials and consider implementing "
    |

PLR2004 Magic value used in comparison, consider replacing `7200` with a constant variable
   --> src\core\failure_analytics.py:520:93
    |
518 |                 # Reset recent failures counter every few hours
519 |                 if (
520 |                     metrics.last_failure_time and time.time() - metrics.last_failure_time > 7200
    |                                                                                             ^^^^
521 |                 ):  # 2 hours
522 |                     metrics.recent_failures = max(0, metrics.recent_failures - 1)
    |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
   --> src\core\failure_classifier.py:261:29
    |
259 |                 exception_str, patterns["text_patterns"]
260 |             )
261 |             if confidence > 0.5:
    |                             ^^^
262 |                 return FailureContext(
263 |                     failure_type=failure_type,
    |

PLR0912 Too many branches (14 > 12)
   --> src\core\failure_classifier.py:285:9
    |
283 |         )
284 |
285 |     def classify_page_content(self, driver, context: dict[str, Any]) -> FailureContext:
    |         ^^^^^^^^^^^^^^^^^^^^^
286 |         """
287 |         Classify a failure based on page content analysis.
    |

E501 Line too long (121 > 100)
   --> src\core\failure_classifier.py:362:101
    |
360 |                         details["triggered_by_wait_for_timeout"] = True
361 |                     elif best_match is None:  # If no other failure type matched yet
362 |                         # If it was a wait_for timeout and no patterns matched, still give a decent NO_RESULTS confidence
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^
363 |                         confidence = max(confidence, 0.6)
364 |                         details["triggered_by_wait_for_timeout"] = True
    |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> src\core\failure_classifier.py:379:50
    |
378 |             if (
379 |                 best_match and best_confidence > 0.3
    |                                                  ^^^
380 |             ):  # Lower threshold to catch more potential failures
381 |                 return FailureContext(
    |

E501 Line too long (101 > 100)
   --> src\core\failure_classifier.py:393:101
    |
391 |                 return FailureContext(
392 |                     failure_type=FailureType.NO_RESULTS,
393 |                     confidence=0.5,  # Moderate confidence since it timed out but no explicit pattern
    |                                                                                                     ^
394 |                     details={
395 |                         "no_explicit_failure_detected": True,
    |

E722 Do not use bare `except`
   --> src\core\failure_classifier.py:428:17
    |
426 |                     if elements:
427 |                         return 0.8  # High confidence for *any* selector match (adjusted from 0.9)
428 |                 except:
    |                 ^^^^^^
429 |                     continue
430 |             return 0.0
    |

PLR0912 Too many branches (15 > 12)
  --> src\core\field_mapping.py:50:5
   |
50 | def map_shopsite_fields(product_data):
   |     ^^^^^^^^^^^^^^^^^^^
51 |     """
52 |     Map ShopSite XML fields to editor format, keeping only relevant fields.
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\local_storage\dataset.py:55:13
   |
53 |         for item in data:
54 |             # Generate unique filename
55 |             import uuid
   |             ^^^^^^^^^^^
56 |
57 |             filename = f"{uuid.uuid4()}.json"
   |

PLC0415 `import` should be at the top-level of a file
   --> src\core\scraper_testing_client.py:101:9
    |
 99 |         """
100 |         # Import the integration tester for local runs
101 |         from tests.integration.test_scraper_integration import ScraperIntegrationTester
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
102 |
103 |         tester = ScraperIntegrationTester()
    |

PLC0415 `import` should be at the top-level of a file
  --> src\core\scraper_testing_integration.py:43:9
   |
41 |         # Initialize testing client
42 |         # In CI environments, always use headless mode
43 |         import os
   |         ^^^^^^^^^
44 |
45 |         is_ci = os.getenv("CI") == "true"
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\scraper_testing_integration.py:51:9
   |
49 |     def get_test_skus(self, scraper_name: str) -> list[str]:
50 |         """Get test SKUs for a scraper from its YAML config."""
51 |         from src.scrapers.parser.yaml_parser import ScraperConfigParser
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
52 |
53 |         config_path = self.project_root / "src" / "scrapers" / "configs" / f"{scraper_name}.yaml"
   |

PLR0912 Too many branches (14 > 12)
   --> src\core\scraper_testing_integration.py:206:9
    |
204 |         return results
205 |
206 |     def _print_test_summary(self, test_results: dict[str, Any]) -> None:
    |         ^^^^^^^^^^^^^^^^^^^
207 |         """Print a summary of test results for a single scraper."""
208 |         scraper = test_results["scraper"]
    |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
   --> src\core\scraper_testing_integration.py:242:52
    |
240 |                 print("   Field Coverage:")
241 |                 for field, coverage in field_coverage.items():
242 |                     status = "PASS" if coverage == 100.0 else "WARN" if coverage > 0 else "FAIL"
    |                                                    ^^^^^
243 |                     print(f"     {status} {field}: {coverage:.1f}%")
    |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> src\core\settings_manager.py:16:16
   |
15 |       # Default settings
16 |       DEFAULTS = {
   |  ________________^
17 | |         # Scraper Credentials
18 | |         "petfood_username": "",
19 | |         "petfood_password": "",
20 | |         "phillips_username": "",
21 | |         "phillips_password": "",
22 | |         "orgill_username": "",
23 | |         "orgill_password": "",
24 | |         "petfoodex_username": "",
25 | |         "petfoodex_password": "",
26 | |         "headless_scraping": True,
27 | |         # ShopSite API Credentials
28 | |         "shopsite_client_id": "",
29 | |         "shopsite_secret_key": "",
30 | |         "shopsite_authorization_code": "",
31 | |         "shopsite_auth_url": "https://yourstore.shopsite.com/xml/",
32 | |         "shopsite_username": "",
33 | |         "shopsite_password": "",
34 | |         "shopsite_base_url": "",
35 | |         "shopsite_store_id": "",
36 | |         # Cloud Settings
37 | |         "google_cloud_project_id": "",
38 | |         # AI/ML Settings
39 | |         "openrouter_api_key": "",
40 | |         "ollama_model": "llama3.2",
41 | |         "classification_method": "llm",  # 'llm' (OpenRouter), 'local_llm' (Ollama), 'fuzzy' (legacy)
42 | |         # Application Settings
43 | |         "debug_mode": False,
44 | |         "database_path": "data/databases/products.db",
45 | |         "selenium_headless": True,
46 | |         "selenium_timeout": 30,
47 | |         "scraper_system": "new",  # 'new' (modular YAML), 'legacy' (archived)
48 | |         # UI Settings
49 | |         "auto_scroll_logs": True,
50 | |         "theme": "dark",  # 'dark' or 'light'
51 | |     }
   | |_____^
52 |
53 |       def __init__(self):
   |

E501 Line too long (101 > 100)
  --> src\core\settings_manager.py:41:101
   |
39 |         "openrouter_api_key": "",
40 |         "ollama_model": "llama3.2",
41 |         "classification_method": "llm",  # 'llm' (OpenRouter), 'local_llm' (Ollama), 'fuzzy' (legacy)
   |                                                                                                     ^
42 |         # Application Settings
43 |         "debug_mode": False,
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\settings_manager.py:67:13
   |
65 |         """Load settings from settings.json file for initial setup."""
66 |         try:
67 |             import json
   |             ^^^^^^^^^^^
68 |             from pathlib import Path
   |

PLC0415 `import` should be at the top-level of a file
  --> src\core\settings_manager.py:68:13
   |
66 |         try:
67 |             import json
68 |             from pathlib import Path
   |             ^^^^^^^^^^^^^^^^^^^^^^^^
69 |
70 |             settings_file = Path(__file__).parent.parent.parent / "settings.json"
   |

PLC0415 `import` should be at the top-level of a file
  --> src\main.py:36:9
   |
35 |     if args.run == "gui":
36 |         from src.ui.main_window import MainWindow
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 |
38 |         app = QApplication(sys.argv)
   |

PLC0415 `import` should be at the top-level of a file
  --> src\main.py:43:9
   |
41 |         sys.exit(app.exec())
42 |     elif args.run == "scraper":
43 |         from src.core.settings_manager import settings
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
44 |
45 |         # Check which scraper system to use
   |

PLC0415 `import` should be at the top-level of a file
  --> src\main.py:50:13
   |
48 |         if scraper_system == "legacy":
49 |             print("ðŸ”„ Using legacy archived scraper system...")
50 |             from src.scrapers.main import run_scraping
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
51 |         else:
52 |             print("ðŸš€ Using new modular scraper system...")
   |

PLC0415 `import` should be at the top-level of a file
  --> src\main.py:53:13
   |
51 |         else:
52 |             print("ðŸš€ Using new modular scraper system...")
53 |             from src.scrapers.main import run_scraping
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
54 |
55 |         if args.file:
   |

PLC0415 `import` should be at the top-level of a file
  --> src\main.py:61:9
   |
59 |     else:
60 |         # Default to GUI if no argument is provided
61 |         from src.ui.main_window import MainWindow
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
62 |
63 |         app = QApplication(sys.argv)
   |

F401 `src.scrapers.actions.handlers.browser` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
 --> src\scrapers\actions\__init__.py:5:5
  |
3 | # Import handlers to ensure they are registered
4 | from src.scrapers.actions.handlers import (
5 |     browser,
  |     ^^^^^^^
6 |     click,
7 |     combine,
  |
help: Add unused import `browser` to __all__

F401 `src.scrapers.actions.handlers.click` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
 --> src\scrapers\actions\__init__.py:6:5
  |
4 | from src.scrapers.actions.handlers import (
5 |     browser,
6 |     click,
  |     ^^^^^
7 |     combine,
8 |     conditional,
  |
help: Add unused import `click` to __all__

F401 `src.scrapers.actions.handlers.combine` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
 --> src\scrapers\actions\__init__.py:7:5
  |
5 |     browser,
6 |     click,
7 |     combine,
  |     ^^^^^^^
8 |     conditional,
9 |     extract,
  |
help: Add unused import `combine` to __all__

F401 `src.scrapers.actions.handlers.conditional` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:8:5
   |
 6 |     click,
 7 |     combine,
 8 |     conditional,
   |     ^^^^^^^^^^^
 9 |     extract,
10 |     image,
   |
help: Add unused import `conditional` to __all__

F401 `src.scrapers.actions.handlers.extract` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:9:5
   |
 7 |     combine,
 8 |     conditional,
 9 |     extract,
   |     ^^^^^^^
10 |     image,
11 |     input,
   |
help: Add unused import `extract` to __all__

F401 `src.scrapers.actions.handlers.image` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:10:5
   |
 8 |     conditional,
 9 |     extract,
10 |     image,
   |     ^^^^^
11 |     input,
12 |     json,
   |
help: Add unused import `image` to __all__

F401 `src.scrapers.actions.handlers.input` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:11:5
   |
 9 |     extract,
10 |     image,
11 |     input,
   |     ^^^^^
12 |     json,
13 |     login,
   |
help: Add unused import `input` to __all__

F401 `src.scrapers.actions.handlers.json` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:12:5
   |
10 |     image,
11 |     input,
12 |     json,
   |     ^^^^
13 |     login,
14 |     navigate,
   |
help: Add unused import `json` to __all__

F401 `src.scrapers.actions.handlers.login` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:13:5
   |
11 |     input,
12 |     json,
13 |     login,
   |     ^^^^^
14 |     navigate,
15 |     sponsored,
   |
help: Add unused import `login` to __all__

F401 `src.scrapers.actions.handlers.navigate` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:14:5
   |
12 |     json,
13 |     login,
14 |     navigate,
   |     ^^^^^^^^
15 |     sponsored,
16 |     table,
   |
help: Add unused import `navigate` to __all__

F401 `src.scrapers.actions.handlers.sponsored` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:15:5
   |
13 |     login,
14 |     navigate,
15 |     sponsored,
   |     ^^^^^^^^^
16 |     table,
17 |     transform,
   |
help: Add unused import `sponsored` to __all__

F401 `src.scrapers.actions.handlers.table` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:16:5
   |
14 |     navigate,
15 |     sponsored,
16 |     table,
   |     ^^^^^
17 |     transform,
18 |     verify,
   |
help: Add unused import `table` to __all__

F401 `src.scrapers.actions.handlers.transform` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:17:5
   |
15 |     sponsored,
16 |     table,
17 |     transform,
   |     ^^^^^^^^^
18 |     verify,
19 |     wait,
   |
help: Add unused import `transform` to __all__

F401 `src.scrapers.actions.handlers.verify` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:18:5
   |
16 |     table,
17 |     transform,
18 |     verify,
   |     ^^^^^^
19 |     wait,
20 |     wait_for,
   |
help: Add unused import `verify` to __all__

F401 `src.scrapers.actions.handlers.wait` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:19:5
   |
17 |     transform,
18 |     verify,
19 |     wait,
   |     ^^^^
20 |     wait_for,
21 |     weight,
   |
help: Add unused import `wait` to __all__

F401 `src.scrapers.actions.handlers.wait_for` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:20:5
   |
18 |     verify,
19 |     wait,
20 |     wait_for,
   |     ^^^^^^^^
21 |     weight,
22 | )
   |
help: Add unused import `wait_for` to __all__

F401 `src.scrapers.actions.handlers.weight` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> src\scrapers\actions\__init__.py:21:5
   |
19 |     wait,
20 |     wait_for,
21 |     weight,
   |     ^^^^^^
22 | )
23 | from src.scrapers.actions.registry import ActionRegistry
   |
help: Add unused import `weight` to __all__

N812 Lowercase `expected_conditions` imported as non-lowercase `EC`
 --> src\scrapers\actions\handlers\click.py:7:40
  |
6 | from selenium.common.exceptions import NoSuchElementException, TimeoutException
7 | from selenium.webdriver.support import expected_conditions as EC
  |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^
8 | from selenium.webdriver.support.ui import WebDriverWait
  |

E501 Line too long (135 > 100)
  --> src\scrapers\actions\handlers\click.py:34:101
   |
33 |         logger.debug(
34 |             f"Attempting to click element: {selector} (locator: {locator_type}, CI: {self.executor.is_ci}, max_retries: {max_retries})"
   |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
35 |         )
   |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
  --> src\scrapers\actions\handlers\click.py:45:13
   |
43 |         except TimeoutException:
44 |             logger.warning(f"No elements found for selector '{selector}' within timeout period.")
45 |             raise WorkflowExecutionError(f"No elements found for selector: {selector}")
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
46 |
47 |         # Now find elements and perform filtering and click
   |

E501 Line too long (131 > 100)
  --> src\scrapers\actions\handlers\click.py:74:101
   |
72 |             if index >= len(filtered_elements):
73 |                 raise WorkflowExecutionError(
74 |                     f"Index {index} out of bounds for filtered elements (count: {len(filtered_elements)}) for selector: {selector}"
   |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
75 |                 )
   |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\actions\handlers\click.py:100:13
    |
 99 |         except Exception as e:
100 |             raise WorkflowExecutionError(f"Failed to click element after waiting: {e}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

PLC0415 `import` should be at the top-level of a file
  --> src\scrapers\actions\handlers\conditional.py:37:13
   |
35 |             selector = params.get("selector")
36 |             # We need to check if element exists without throwing error
37 |             from selenium.webdriver.common.by import By
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
38 |
39 |             try:
   |

E722 Do not use bare `except`
  --> src\scrapers\actions\handlers\conditional.py:42:13
   |
40 |                 self.executor.browser.driver.find_element(By.CSS_SELECTOR, selector)
41 |                 condition_met = True
42 |             except:
   |             ^^^^^^
43 |                 condition_met = False
   |

PLR0912 Too many branches (18 > 12)
  --> src\scrapers\actions\handlers\image.py:16:9
   |
14 |     """Action to process, filter, and upgrade image URLs."""
15 |
16 |     def execute(self, params: dict[str, Any]) -> None:
   |         ^^^^^^^
17 |         field = params.get("field")
18 |         if not field:
   |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
  --> src\scrapers\actions\handlers\input.py:33:13
   |
31 |             logger.debug(f"Input text into {selector}: {text}")
32 |         except NoSuchElementException:
33 |             raise WorkflowExecutionError(f"Input element not found: {selector}")
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

E501 Line too long (103 > 100)
  --> src\scrapers\actions\handlers\login.py:40:101
   |
38 |         # Use the executor's internal login method logic, but adapted
39 |         # Since the original method was complex and called other actions,
40 |         # we might want to keep the logic here or call the executor's method if we keep it temporarily.
   |                                                                                                     ^^^
41 |         # For now, let's call the executor's method to ensure backward compatibility during migration
42 |         # But ideally this should be fully refactored.
   |

E501 Line too long (101 > 100)
  --> src\scrapers\actions\handlers\login.py:41:101
   |
39 |         # Since the original method was complex and called other actions,
40 |         # we might want to keep the logic here or call the executor's method if we keep it temporarily.
41 |         # For now, let's call the executor's method to ensure backward compatibility during migration
   |                                                                                                     ^
42 |         # But ideally this should be fully refactored.
   |

E501 Line too long (104 > 100)
  --> src\scrapers\actions\handlers\verify.py:35:101
   |
33 |         actual_str = str(actual_value)
34 |
35 |         # If expected is not provided, we might be verifying against a context value (like searched SKU)
   |                                                                                                     ^^^^
36 |         # But for now let's assume expected is passed explicitly or we check for non-empty
37 |         if expected is None:
   |

E501 Line too long (110 > 100)
  --> src\scrapers\actions\handlers\verify.py:52:101
   |
51 |         if not matched:
52 |             msg = f"Verification failed for {field}: expected '{expected}' ({match_mode}), got '{actual_str}'"
   |                                                                                                     ^^^^^^^^^^
53 |             logger.warning(msg)
54 |             if params.get("strict", True):
   |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
  --> src\scrapers\actions\handlers\verify.py:85:28
   |
83 |             new_name = new_name[: -(len(brand))].strip().rstrip(":-")
84 |
85 |         if len(new_name) < 3:  # Don't make it too short
   |                            ^
86 |             new_name = name
   |

N812 Lowercase `expected_conditions` imported as non-lowercase `EC`
 --> src\scrapers\actions\handlers\wait_for.py:6:40
  |
5 | from selenium.common.exceptions import TimeoutException
6 | from selenium.webdriver.support import expected_conditions as EC
  |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^
7 | from selenium.webdriver.support.ui import WebDriverWait
  |

E501 Line too long (104 > 100)
  --> src\scrapers\actions\handlers\wait_for.py:30:101
   |
29 |         logger.debug(
30 |             f"Waiting for any of elements: {selectors} (timeout: {timeout}s, CI: {self.executor.is_ci})"
   |                                                                                                     ^^^^
31 |         )
   |

E501 Line too long (109 > 100)
  --> src\scrapers\actions\handlers\wait_for.py:45:100
   |
43 |             wait_duration = time.time() - start_time
44 |             logger.warning(
45 |                 f"â° TIMEOUT: Element not found within {timeout}s (waited {wait_duration:.2f}s): {selectors}"
   |                                                                                                     ^^^^^^^^^
46 |             )
   |

E722 Do not use bare `except`
  --> src\scrapers\actions\handlers\wait_for.py:52:13
   |
50 |                 logger.debug(f"Current page URL: {self.executor.browser.driver.current_url}")
51 |                 logger.debug(f"Page title: {self.executor.browser.driver.title}")
52 |             except:
   |             ^^^^^^
53 |                 pass
   |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
  --> src\scrapers\actions\handlers\wait_for.py:55:13
   |
53 |                 pass
54 |
55 |             raise WorkflowExecutionError(f"Element not found within {timeout}s: {selectors}")
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLR0912 Too many branches (18 > 12)
  --> src\scrapers\actions\handlers\weight.py:16:9
   |
14 |     """Action to parse and normalize weight strings."""
15 |
16 |     def execute(self, params: dict[str, Any]) -> None:
   |         ^^^^^^^
17 |         field = params.get("field")
18 |         target_unit = params.get("target_unit", "lb")  # lb, kg, oz, g
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
 --> src\scrapers\actions\registry.py:7:45
  |
5 |     """Registry for managing available workflow actions."""
6 |
7 |     _actions: dict[str, type[BaseAction]] = {}
  |                                             ^^
8 |
9 |     @classmethod
  |

N812 Lowercase `expected_conditions` imported as non-lowercase `EC`
  --> src\scrapers\executor\workflow_executor.py:13:40
   |
11 | from selenium.common.exceptions import NoSuchElementException, TimeoutException
12 | from selenium.webdriver.common.by import By
13 | from selenium.webdriver.support import expected_conditions as EC
   |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^
14 | from selenium.webdriver.support.ui import WebDriverWait
   |

PLC0415 `import` should be at the top-level of a file
  --> src\scrapers\executor\workflow_executor.py:65:9
   |
64 |         # Log environment details for debugging
65 |         import os
   |         ^^^^^^^^^
66 |
67 |         self.is_ci = os.getenv("CI") == "true"
   |

PLR2004 Magic value used in comparison, consider replacing `60` with a constant variable
  --> src\scrapers\executor\workflow_executor.py:70:42
   |
69 |         # Adjust timeout for CI environment (headless browsers need more time)
70 |         if self.is_ci and self.timeout < 60:
   |                                          ^^
71 |             self.timeout = 60
72 |             logger.info(f"Adjusted timeout for CI environment: {self.timeout}s")
   |

F821 Undefined name `logger`
  --> src\scrapers\executor\workflow_executor.py:72:13
   |
70 |         if self.is_ci and self.timeout < 60:
71 |             self.timeout = 60
72 |             logger.info(f"Adjusted timeout for CI environment: {self.timeout}s")
   |             ^^^^^^
73 |
74 |         logger.info(
   |

F821 Undefined name `logger`
  --> src\scrapers\executor\workflow_executor.py:74:9
   |
72 |             logger.info(f"Adjusted timeout for CI environment: {self.timeout}s")
73 |
74 |         logger.info(
   |         ^^^^^^
75 |             f"Initializing workflow executor - CI: {self.is_ci}, Headless: {headless}, Timeout: {self.timeout}"
76 |         )
   |

E501 Line too long (111 > 100)
  --> src\scrapers\executor\workflow_executor.py:75:101
   |
74 |         logger.info(
75 |             f"Initializing workflow executor - CI: {self.is_ci}, Headless: {headless}, Timeout: {self.timeout}"
   |                                                                                                     ^^^^^^^^^^^
76 |         )
   |

F821 Undefined name `logger`
  --> src\scrapers\executor\workflow_executor.py:85:13
   |
83 |                 profile_suffix=f"workflow_{int(time.time())}",
84 |             )
85 |             logger.info(f"Browser initialized for scraper: {self.config.name}")
   |             ^^^^^^
86 |
87 |             # Log browser capabilities for debugging
   |

F821 Undefined name `logger`
  --> src\scrapers\executor\workflow_executor.py:94:17
   |
92 |                     "chromedriverVersion", "unknown"
93 |                 )
94 |                 logger.info(
   |                 ^^^^^^
95 |                     f"Browser capabilities - Chrome: {browser_version}, ChromeDriver: {chrome_version}"
96 |                 )
   |

E501 Line too long (103 > 100)
  --> src\scrapers\executor\workflow_executor.py:95:101
   |
93 |                 )
94 |                 logger.info(
95 |                     f"Browser capabilities - Chrome: {browser_version}, ChromeDriver: {chrome_version}"
   |                                                                                                     ^^^
96 |                 )
97 |             except Exception as cap_e:
   |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:98:17
    |
 96 |                 )
 97 |             except Exception as cap_e:
 98 |                 logger.debug(f"Could not get browser capabilities: {cap_e}")
    |                 ^^^^^^
 99 |
100 |         except Exception as e:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:101:13
    |
100 |         except Exception as e:
101 |             logger.error(f"Failed to initialize browser: {e}")
    |             ^^^^^^
102 |             raise WorkflowExecutionError(f"Failed to initialize browser: {e}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:102:13
    |
100 |         except Exception as e:
101 |             logger.error(f"Failed to initialize browser: {e}")
102 |             raise WorkflowExecutionError(f"Failed to initialize browser: {e}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
103 |
104 |         # Initialize anti-detection manager if configured
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:102:19
    |
100 |         except Exception as e:
101 |             logger.error(f"Failed to initialize browser: {e}")
102 |             raise WorkflowExecutionError(f"Failed to initialize browser: {e}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
103 |
104 |         # Initialize anti-detection manager if configured
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:110:17
    |
108 |                     self.browser, config.anti_detection, config.name
109 |                 )
110 |                 logger.info(f"Anti-detection manager initialized for scraper: {self.config.name}")
    |                 ^^^^^^
111 |             except Exception as e:
112 |                 logger.warning(f"Failed to initialize anti-detection manager: {e}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:112:17
    |
110 |                 logger.info(f"Anti-detection manager initialized for scraper: {self.config.name}")
111 |             except Exception as e:
112 |                 logger.warning(f"Failed to initialize anti-detection manager: {e}")
    |                 ^^^^^^
113 |                 self.anti_detection_manager = None
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:136:13
    |
134 |         """
135 |         try:
136 |             logger.info(f"Starting workflow execution for: {self.config.name}")
    |             ^^^^^^
137 |
138 |             for i, step in enumerate(self.config.workflows, 1):
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:140:21
    |
138 |             for i, step in enumerate(self.config.workflows, 1):
139 |                 if self.workflow_stopped:
140 |                     logger.info("Workflow stopped due to condition, skipping remaining steps.")
    |                     ^^^^^^
141 |                     break
142 |                 logger.info(f"Step {i}/{len(self.config.workflows)}: Executing {step.action}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:142:17
    |
140 |                     logger.info("Workflow stopped due to condition, skipping remaining steps.")
141 |                     break
142 |                 logger.info(f"Step {i}/{len(self.config.workflows)}: Executing {step.action}")
    |                 ^^^^^^
143 |                 self._execute_step(step)
144 |                 logger.info(f"Step {i}/{len(self.config.workflows)}: Completed {step.action}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:144:17
    |
142 |                 logger.info(f"Step {i}/{len(self.config.workflows)}: Executing {step.action}")
143 |                 self._execute_step(step)
144 |                 logger.info(f"Step {i}/{len(self.config.workflows)}: Completed {step.action}")
    |                 ^^^^^^
145 |
146 |             logger.info(f"Workflow execution completed for: {self.config.name}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:146:13
    |
144 |                 logger.info(f"Step {i}/{len(self.config.workflows)}: Completed {step.action}")
145 |
146 |             logger.info(f"Workflow execution completed for: {self.config.name}")
    |             ^^^^^^
147 |             return {
148 |                 "success": True,
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:155:13
    |
154 |         except Exception as e:
155 |             logger.error(f"Workflow execution failed: {e}")
    |             ^^^^^^
156 |             raise WorkflowExecutionError(f"Workflow execution failed: {e}")
157 |         finally:
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:156:13
    |
154 |         except Exception as e:
155 |             logger.error(f"Workflow execution failed: {e}")
156 |             raise WorkflowExecutionError(f"Workflow execution failed: {e}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
157 |         finally:
158 |             if quit_browser and self.browser:
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:156:19
    |
154 |         except Exception as e:
155 |             logger.error(f"Workflow execution failed: {e}")
156 |             raise WorkflowExecutionError(f"Workflow execution failed: {e}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
157 |         finally:
158 |             if quit_browser and self.browser:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:175:13
    |
173 |         """
174 |         try:
175 |             logger.info(f"Starting step execution for: {self.config.name}")
    |             ^^^^^^
176 |
177 |             for step in steps:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:179:21
    |
177 |             for step in steps:
178 |                 if self.workflow_stopped:
179 |                     logger.info("Workflow stopped due to condition, skipping remaining steps.")
    |                     ^^^^^^
180 |                     break
181 |                 self._execute_step(step)
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:183:13
    |
181 |                 self._execute_step(step)
182 |
183 |             logger.info(f"Step execution completed for: {self.config.name}")
    |             ^^^^^^
184 |             return {
185 |                 "success": True,
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:192:13
    |
191 |         except Exception as e:
192 |             logger.error(f"Step execution failed: {e}")
    |             ^^^^^^
193 |             raise WorkflowExecutionError(f"Step execution failed: {e}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:193:13
    |
191 |         except Exception as e:
192 |             logger.error(f"Step execution failed: {e}")
193 |             raise WorkflowExecutionError(f"Step execution failed: {e}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
194 |
195 |     def _execute_step(self, step: WorkflowStep):
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:193:19
    |
191 |         except Exception as e:
192 |             logger.error(f"Step execution failed: {e}")
193 |             raise WorkflowExecutionError(f"Step execution failed: {e}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
194 |
195 |     def _execute_step(self, step: WorkflowStep):
    |

PLR0912 Too many branches (29 > 12)
   --> src\scrapers\executor\workflow_executor.py:195:9
    |
193 |             raise WorkflowExecutionError(f"Step execution failed: {e}")
194 |
195 |     def _execute_step(self, step: WorkflowStep):
    |         ^^^^^^^^^^^^^
196 |         """
197 |         Execute a single workflow step.
    |

PLR0915 Too many statements (92 > 50)
   --> src\scrapers\executor\workflow_executor.py:195:9
    |
193 |             raise WorkflowExecutionError(f"Step execution failed: {e}")
194 |
195 |     def _execute_step(self, step: WorkflowStep):
    |         ^^^^^^^^^^^^^
196 |         """
197 |         Execute a single workflow step.
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:210:9
    |
208 |         params["start_time"] = start_time  # Track for analytics
209 |
210 |         logger.debug(f"Executing step: {action} with params: {params}")
    |         ^^^^^^
211 |
212 |         # Pre-action anti-detection hook
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:219:23
    |
217 |                 action, params, skip_rate_limit_check=skip_rate_limit_check
218 |             ):
219 |                 raise WorkflowExecutionError(
    |                       ^^^^^^^^^^^^^^^^^^^^^^
220 |                     f"Pre-action anti-detection check failed for '{action}'"
221 |                 )
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:256:23
    |
254 |                 self._action_verify(params)
255 |             else:
256 |                 raise WorkflowExecutionError(f"Unknown action: {action}")
    |                       ^^^^^^^^^^^^^^^^^^^^^^
257 |
258 |             success = True
    |

E501 Line too long (104 > 100)
   --> src\scrapers\executor\workflow_executor.py:275:101
    |
273 |                 # This was a successful retry
274 |                 self.adaptive_retry_strategy.record_failure(
275 |                     failure_type=FailureType.NETWORK_ERROR,  # Default, will be updated with actual type
    |                                                                                                     ^^^^
276 |                     site_name=self.config.name,
277 |                     action=action,
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:288:17
    |
286 |             try:
287 |                 failure_context = self.failure_classifier.classify_exception(e, {"action": action})
288 |                 logger.debug(
    |                 ^^^^^^
289 |                     f"Failure classified: {failure_context.failure_type.value} "
290 |                     f"(confidence: {failure_context.confidence})"
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:306:29
    |
304 |                             and page_failure_context.confidence > failure_context.confidence
305 |                         ):
306 |                             logger.debug(
    |                             ^^^^^^
307 |                                 f"Reclassified failure from {failure_context.failure_type.value} "
308 |                                 f"to {page_failure_context.failure_type.value} based on page content"
    |

E501 Line too long (101 > 100)
   --> src\scrapers\executor\workflow_executor.py:308:101
    |
306 | â€¦                     logger.debug(
307 | â€¦                         f"Reclassified failure from {failure_context.failure_type.value} "
308 | â€¦                         f"to {page_failure_context.failure_type.value} based on page content"
    |                                                                                               ^
309 | â€¦                     )
310 | â€¦                     failure_context = page_failure_context
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:312:25
    |
310 |                             failure_context = page_failure_context
311 |                     except Exception as page_classify_e:
312 |                         logger.debug(f"Could not classify page content: {page_classify_e}")
    |                         ^^^^^^
313 |
314 |             except Exception as classify_e:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:315:17
    |
314 |             except Exception as classify_e:
315 |                 logger.debug(f"Could not classify failure: {classify_e}")
    |                 ^^^^^^
316 |                 # Default to network error
317 |                 failure_context = FailureContext(
    |

PLR1714 Consider merging multiple comparisons. Use a `set` if the elements are hashable.
   --> src\scrapers\executor\workflow_executor.py:332:17
    |
330 |               # Check if we should retry
331 |               should_retry = (
332 | /                 retry_count < adaptive_config.max_retries
333 | |                 and failure_context.failure_type != FailureType.PAGE_NOT_FOUND
334 | |                 and failure_context.failure_type != FailureType.NO_RESULTS
    | |__________________________________________________________________________^
335 |               )
    |
help: Merge multiple comparisons

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:340:17
    |
338 |                 # Calculate delay using adaptive strategy
339 |                 delay = self.adaptive_retry_strategy.calculate_delay(adaptive_config, retry_count)
340 |                 logger.info(
    |                 ^^^^^^
341 |                     f"Adaptive retry for '{action}' - failure: {failure_context.failure_type.value}, "
342 |                     f"retry {retry_count + 1}/{adaptive_config.max_retries}, delay: {delay:.1f}s"
    |

E501 Line too long (102 > 100)
   --> src\scrapers\executor\workflow_executor.py:341:101
    |
339 |                 delay = self.adaptive_retry_strategy.calculate_delay(adaptive_config, retry_count)
340 |                 logger.info(
341 |                     f"Adaptive retry for '{action}' - failure: {failure_context.failure_type.value}, "
    |                                                                                                     ^^
342 |                     f"retry {retry_count + 1}/{adaptive_config.max_retries}, delay: {delay:.1f}s"
343 |                 )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:351:25
    |
349 |                 if self.anti_detection_manager:
350 |                     if self.anti_detection_manager.handle_error(e, action, retry_count):
351 |                         logger.info(
    |                         ^^^^^^
352 |                             f"Anti-detection error handling succeeded for '{action}', retrying..."
353 |                         )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:355:25
    |
353 |                         )
354 |                     else:
355 |                         logger.debug(f"Anti-detection error handling failed for '{action}'")
    |                         ^^^^^^
356 |
357 |                 # Record the failure for analytics
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:441:13
    |
439 |             }
440 |
441 |             raise WorkflowExecutionError(f"Failed to execute step '{action}': {e}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
442 |         finally:
443 |             # Post-action anti-detection hook
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:441:19
    |
439 |             }
440 |
441 |             raise WorkflowExecutionError(f"Failed to execute step '{action}': {e}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
442 |         finally:
443 |             # Post-action anti-detection hook
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:451:19
    |
449 |         url = params.get("url")
450 |         if not url:
451 |             raise WorkflowExecutionError("Navigate action requires 'url' parameter")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
452 |
453 |         logger.info(f"Navigating to: {url}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:453:9
    |
451 |             raise WorkflowExecutionError("Navigate action requires 'url' parameter")
452 |
453 |         logger.info(f"Navigating to: {url}")
    |         ^^^^^^
454 |         self.browser.get(url)
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:478:13
    |
476 |         status_code = self.browser.check_http_status()
477 |         if status_code is None:
478 |             logger.debug(f"Could not determine HTTP status for {url}")
    |             ^^^^^^
479 |             return
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:481:9
    |
479 |             return
480 |
481 |         logger.debug(f"HTTP status for {url}: {status_code}")
    |         ^^^^^^
482 |
483 |         # Store status in results for later use
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:491:17
    |
489 |             error_codes = self.config.http_status.error_status_codes
490 |             if status_code in error_codes:
491 |                 logger.error(f"HTTP error status {status_code} detected for {url}")
    |                 ^^^^^^
492 |                 raise WorkflowExecutionError(
493 |                     f"HTTP {status_code} error encountered while navigating to {url}"
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:492:23
    |
490 |             if status_code in error_codes:
491 |                 logger.error(f"HTTP error status {status_code} detected for {url}")
492 |                 raise WorkflowExecutionError(
    |                       ^^^^^^^^^^^^^^^^^^^^^^
493 |                     f"HTTP {status_code} error encountered while navigating to {url}"
494 |                 )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:499:13
    |
497 |         warning_codes = self.config.http_status.warning_status_codes
498 |         if status_code in warning_codes:
499 |             logger.warning(f"HTTP redirect status {status_code} detected for {url}")
    |             ^^^^^^
500 |
501 |     def _action_wait_for(self, params: dict[str, Any]):
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:507:19
    |
506 |         if not selector_param:
507 |             raise WorkflowExecutionError("Wait_for action requires 'selector' parameter")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
508 |
509 |         selectors = selector_param if isinstance(selector_param, list) else [selector_param]
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:511:9
    |
509 |         selectors = selector_param if isinstance(selector_param, list) else [selector_param]
510 |
511 |         logger.debug(
    |         ^^^^^^
512 |             f"Waiting for any of elements: {selectors} (timeout: {timeout}s, CI: {self.is_ci})"
513 |         )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:522:13
    |
520 |             WebDriverWait(self.browser.driver, timeout).until(EC.any_of(*conditions))
521 |             wait_duration = time.time() - start_time
522 |             logger.info(f"âœ… Element found after {wait_duration:.2f}s from selectors: {selectors}")
    |             ^^^^^^
523 |         except TimeoutException:
524 |             wait_duration = time.time() - start_time
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:525:13
    |
523 |         except TimeoutException:
524 |             wait_duration = time.time() - start_time
525 |             logger.warning(
    |             ^^^^^^
526 |                 f"â° TIMEOUT: Element not found within {timeout}s (waited {wait_duration:.2f}s): {selectors}"
527 |             )
    |

E501 Line too long (109 > 100)
   --> src\scrapers\executor\workflow_executor.py:526:100
    |
524 |             wait_duration = time.time() - start_time
525 |             logger.warning(
526 |                 f"â° TIMEOUT: Element not found within {timeout}s (waited {wait_duration:.2f}s): {selectors}"
    |                                                                                                     ^^^^^^^^^
527 |             )
528 |             logger.debug(f"Current page URL: {self.browser.driver.current_url}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:528:13
    |
526 |                 f"â° TIMEOUT: Element not found within {timeout}s (waited {wait_duration:.2f}s): {selectors}"
527 |             )
528 |             logger.debug(f"Current page URL: {self.browser.driver.current_url}")
    |             ^^^^^^
529 |             logger.debug(f"Page title: {self.browser.driver.title}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:529:13
    |
527 |             )
528 |             logger.debug(f"Current page URL: {self.browser.driver.current_url}")
529 |             logger.debug(f"Page title: {self.browser.driver.title}")
    |             ^^^^^^
530 |
531 |             # Log available elements for debugging
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:534:17
    |
532 |             try:
533 |                 all_elements = self.browser.driver.find_elements(By.CSS_SELECTOR, "*")
534 |                 logger.debug(f"Total elements on page: {len(all_elements)}")
    |                 ^^^^^^
535 |
536 |                 # Try to find similar selectors
    |

E722 Do not use bare `except`
   --> src\scrapers\executor\workflow_executor.py:548:29
    |
546 |                                 elif selector.startswith("#") and selector[1:] == el_id:
547 |                                     similar_selectors.append(selector)
548 |                             except:
    |                             ^^^^^^
549 |                                 pass
550 |                         if similar_selectors:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:551:29
    |
549 |                                 pass
550 |                         if similar_selectors:
551 |                             logger.debug(
    |                             ^^^^^^
552 |                                 f"Found similar elements for {selector}: {similar_selectors[:5]}"
553 |                             )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:555:17
    |
553 |                             )
554 |             except Exception as debug_e:
555 |                 logger.debug(f"Could not analyze page elements: {debug_e}")
    |                 ^^^^^^
556 |
557 |             raise WorkflowExecutionError(f"Element not found within {timeout}s: {selectors}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:557:13
    |
555 |                 logger.debug(f"Could not analyze page elements: {debug_e}")
556 |
557 |             raise WorkflowExecutionError(f"Element not found within {timeout}s: {selectors}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
558 |
559 |     def _action_wait(self, params: dict[str, Any]):
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:557:19
    |
555 |                 logger.debug(f"Could not analyze page elements: {debug_e}")
556 |
557 |             raise WorkflowExecutionError(f"Element not found within {timeout}s: {selectors}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
558 |
559 |     def _action_wait(self, params: dict[str, Any]):
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:562:9
    |
560 |         """Simple wait/delay."""
561 |         seconds = params.get("seconds", params.get("timeout", 1))
562 |         logger.debug(f"Waiting for {seconds} seconds")
    |         ^^^^^^
563 |         time.sleep(seconds)
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:571:19
    |
570 |         if not field_name or not selector_name:
571 |             raise WorkflowExecutionError(
    |                   ^^^^^^^^^^^^^^^^^^^^^^
572 |                 "Extract_single requires 'field' and 'selector' parameters"
573 |             )
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:577:19
    |
575 |         selector_config = self.selectors.get(selector_name)
576 |         if not selector_config:
577 |             raise WorkflowExecutionError(f"Selector '{selector_name}' not found in config")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
578 |
579 |         try:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:583:13
    |
581 |             value = self._extract_value_from_element(element, selector_config.attribute)
582 |             self.results[field_name] = value
583 |             logger.debug(f"Extracted {field_name}: {value}")
    |             ^^^^^^
584 |         except NoSuchElementException:
585 |             logger.warning(f"Element not found for field: {field_name}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:585:13
    |
583 |             logger.debug(f"Extracted {field_name}: {value}")
584 |         except NoSuchElementException:
585 |             logger.warning(f"Element not found for field: {field_name}")
    |             ^^^^^^
586 |             self.results[field_name] = None
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:594:19
    |
593 |         if not field_name or not selector_name:
594 |             raise WorkflowExecutionError(
    |                   ^^^^^^^^^^^^^^^^^^^^^^
595 |                 "Extract_multiple requires 'field' and 'selector' parameters"
596 |             )
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:600:19
    |
598 |         selector_config = self.selectors.get(selector_name)
599 |         if not selector_config:
600 |             raise WorkflowExecutionError(f"Selector '{selector_name}' not found in config")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
601 |
602 |         try:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:610:13
    |
608 |                     values.append(value)
609 |             self.results[field_name] = values
610 |             logger.debug(f"Extracted {len(values)} items for {field_name}")
    |             ^^^^^^
611 |         except Exception as e:
612 |             logger.warning(f"Failed to extract multiple values for {field_name}: {e}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:612:13
    |
610 |             logger.debug(f"Extracted {len(values)} items for {field_name}")
611 |         except Exception as e:
612 |             logger.warning(f"Failed to extract multiple values for {field_name}: {e}")
    |             ^^^^^^
613 |             self.results[field_name] = []
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:625:9
    |
623 |         """Extract multiple fields at once (legacy compatibility)."""
624 |         fields = params.get("fields", [])
625 |         logger.debug(f"Starting extract action for fields: {fields}")
    |         ^^^^^^
626 |         for field_name in fields:
627 |             selector_config = self.selectors.get(field_name)
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:629:17
    |
627 |             selector_config = self.selectors.get(field_name)
628 |             if not selector_config:
629 |                 logger.warning(f"Selector '{field_name}' not found in config")
    |                 ^^^^^^
630 |                 continue
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:657:17
    |
655 |                     value = self._extract_value_from_element(element, selector_config.attribute)
656 |                     self.results[field_name] = value
657 |                 logger.debug(f"Extracted {field_name}: {self.results[field_name]}")
    |                 ^^^^^^
658 |             except NoSuchElementException:
659 |                 logger.warning(f"Element not found for field: {field_name}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:659:17
    |
657 |                 logger.debug(f"Extracted {field_name}: {self.results[field_name]}")
658 |             except NoSuchElementException:
659 |                 logger.warning(f"Element not found for field: {field_name}")
    |                 ^^^^^^
660 |                 self.results[field_name] = [] if selector_config.multiple else None
661 |         logger.info(f"Extract action completed. Results: {self.results}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:661:9
    |
659 |                 logger.warning(f"Element not found for field: {field_name}")
660 |                 self.results[field_name] = [] if selector_config.multiple else None
661 |         logger.info(f"Extract action completed. Results: {self.results}")
    |         ^^^^^^
662 |
663 |     def _action_input_text(self, params: dict[str, Any]):
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:670:19
    |
669 |         if not selector or text is None:
670 |             raise WorkflowExecutionError("Input_text requires 'selector' and 'text' parameters")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
671 |
672 |         try:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:677:13
    |
675 |                 element.clear()
676 |             element.send_keys(str(text))
677 |             logger.debug(f"Input text into {selector}: {text}")
    |             ^^^^^^
678 |         except NoSuchElementException:
679 |             raise WorkflowExecutionError(f"Input element not found: {selector}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:679:13
    |
677 |             logger.debug(f"Input text into {selector}: {text}")
678 |         except NoSuchElementException:
679 |             raise WorkflowExecutionError(f"Input element not found: {selector}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
680 |
681 |     def _action_click(self, params: dict[str, Any]):
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:679:19
    |
677 |             logger.debug(f"Input text into {selector}: {text}")
678 |         except NoSuchElementException:
679 |             raise WorkflowExecutionError(f"Input element not found: {selector}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
680 |
681 |     def _action_click(self, params: dict[str, Any]):
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:689:19
    |
688 |         if not selector:
689 |             raise WorkflowExecutionError("Click action requires 'selector' parameter")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
690 |
691 |         locator_type = self._get_locator_type(selector)
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:694:9
    |
692 |         max_retries = params.get("max_retries", 3 if self.is_ci else 1)  # More retries in CI
693 |
694 |         logger.debug(
    |         ^^^^^^
695 |             f"Attempting to click element: {selector} (locator: {locator_type}, CI: {self.is_ci}, max_retries: {max_retries})"
696 |         )
    |

E501 Line too long (126 > 100)
   --> src\scrapers\executor\workflow_executor.py:695:101
    |
694 |         logger.debug(
695 |             f"Attempting to click element: {selector} (locator: {locator_type}, CI: {self.is_ci}, max_retries: {max_retries})"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
696 |         )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:703:13
    |
701 |                 EC.presence_of_element_located((locator_type, selector))
702 |             )
703 |             logger.info("At least one element is present, proceeding to filter and click")
    |             ^^^^^^
704 |         except TimeoutException:
705 |             logger.warning(f"No elements found for selector '{selector}' within timeout period.")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:705:13
    |
703 |             logger.info("At least one element is present, proceeding to filter and click")
704 |         except TimeoutException:
705 |             logger.warning(f"No elements found for selector '{selector}' within timeout period.")
    |             ^^^^^^
706 |             raise WorkflowExecutionError(f"No elements found for selector: {selector}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:706:13
    |
704 |         except TimeoutException:
705 |             logger.warning(f"No elements found for selector '{selector}' within timeout period.")
706 |             raise WorkflowExecutionError(f"No elements found for selector: {selector}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
707 |
708 |         # Now find elements and perform filtering and click
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:706:19
    |
704 |         except TimeoutException:
705 |             logger.warning(f"No elements found for selector '{selector}' within timeout period.")
706 |             raise WorkflowExecutionError(f"No elements found for selector: {selector}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
707 |
708 |         # Now find elements and perform filtering and click
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:734:23
    |
733 |             if index >= len(filtered_elements):
734 |                 raise WorkflowExecutionError(
    |                       ^^^^^^^^^^^^^^^^^^^^^^
735 |                     f"Index {index} out of bounds for filtered elements (count: {len(filtered_elements)}) for selector: {selector}"
736 |                 )
    |

E501 Line too long (131 > 100)
   --> src\scrapers\executor\workflow_executor.py:735:101
    |
733 |             if index >= len(filtered_elements):
734 |                 raise WorkflowExecutionError(
735 |                     f"Index {index} out of bounds for filtered elements (count: {len(filtered_elements)}) for selector: {selector}"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
736 |                 )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:748:17
    |
746 |                 time.sleep(0.5)  # Brief pause after scrolling
747 |             except Exception as scroll_e:
748 |                 logger.debug(f"Could not scroll element into view: {scroll_e}")
    |                 ^^^^^^
749 |
750 |             # Attempt click
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:752:13
    |
750 |             # Attempt click
751 |             element_to_click.click()
752 |             logger.info(f"Successfully clicked element: {selector} at index {index}")
    |             ^^^^^^
753 |
754 |             # Optional wait after click
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:757:17
    |
755 |             wait_time = params.get("wait_after", 0)
756 |             if wait_time > 0:
757 |                 logger.debug(f"Waiting {wait_time}s after click")
    |                 ^^^^^^
758 |                 time.sleep(wait_time)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:761:13
    |
760 |         except Exception as e:
761 |             raise WorkflowExecutionError(f"Failed to click element after waiting: {e}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
762 |
763 |     def _action_login(self, params: dict[str, Any]):
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:761:19
    |
760 |         except Exception as e:
761 |             raise WorkflowExecutionError(f"Failed to click element after waiting: {e}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
762 |
763 |     def _action_login(self, params: dict[str, Any]):
    |

PLR0912 Too many branches (15 > 12)
   --> src\scrapers\executor\workflow_executor.py:763:9
    |
761 |             raise WorkflowExecutionError(f"Failed to click element after waiting: {e}")
762 |
763 |     def _action_login(self, params: dict[str, Any]):
    |         ^^^^^^^^^^^^^
764 |         """Execute login workflow with credentials."""
765 |         # Merge login details from config into params
    |

PLR0915 Too many statements (72 > 50)
   --> src\scrapers\executor\workflow_executor.py:763:9
    |
761 |             raise WorkflowExecutionError(f"Failed to click element after waiting: {e}")
762 |
763 |     def _action_login(self, params: dict[str, Any]):
    |         ^^^^^^^^^^^^^
764 |         """Execute login workflow with credentials."""
765 |         # Merge login details from config into params
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:793:9
    |
792 | â€¦     # Debug logging for credentials
793 | â€¦     logger.debug(
    |       ^^^^^^
794 | â€¦         f"Login params for {scraper_name}: username={'***' if username else 'None'}, password={'***' if password else 'None'}, url=â€¦
795 | â€¦     )
    |

E501 Line too long (147 > 100)
   --> src\scrapers\executor\workflow_executor.py:794:101
    |
792 | â€¦
793 | â€¦
794 | â€¦***' if username else 'None'}, password={'***' if password else 'None'}, url={login_url}"
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
795 | â€¦
796 | â€¦
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:796:9
    |
794 | â€¦         f"Login params for {scraper_name}: username={'***' if username else 'None'}, password={'***' if password else 'None'}, url=â€¦
795 | â€¦     )
796 | â€¦     logger.debug(
    |       ^^^^^^
797 | â€¦         f"Login fields: username_field={username_field}, password_field={password_field}, submit_button={submit_button}"
798 | â€¦     )
    |

E501 Line too long (124 > 100)
   --> src\scrapers\executor\workflow_executor.py:797:101
    |
795 |         )
796 |         logger.debug(
797 |             f"Login fields: username_field={username_field}, password_field={password_field}, submit_button={submit_button}"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^
798 |         )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:810:13
    |
808 | â€¦         ]
809 | â€¦     ):
810 | â€¦         logger.error(
    |           ^^^^^^
811 | â€¦             f"Missing login parameters for {scraper_name}: username={bool(username)}, password={bool(password)}, url={bool(login_urâ€¦
812 | â€¦         )
    |

E501 Line too long (254 > 100)
   --> src\scrapers\executor\workflow_executor.py:811:101
    |
809 | â€¦
810 | â€¦
811 | â€¦ord={bool(password)}, url={bool(login_url)}, username_field={bool(username_field)}, password_field={bool(password_field)}, submit_button={bool(submit_button)}"
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
812 | â€¦
813 | â€¦
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:813:19
    |
811 | â€¦         f"Missing login parameters for {scraper_name}: username={bool(username)}, password={bool(password)}, url={bool(login_url)},â€¦
812 | â€¦     )
813 | â€¦     raise WorkflowExecutionError(
    |             ^^^^^^^^^^^^^^^^^^^^^^
814 | â€¦         "Login action requires username, password, url, username_field, password_field, and submit_button parameters"
815 | â€¦     )
    |

E501 Line too long (125 > 100)
   --> src\scrapers\executor\workflow_executor.py:814:101
    |
812 |             )
813 |             raise WorkflowExecutionError(
814 |                 "Login action requires username, password, url, username_field, password_field, and submit_button parameters"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
815 |             )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:817:9
    |
815 |             )
816 |
817 |         logger.info("Executing login workflow")
    |         ^^^^^^
818 |
819 |         # Navigate to login page
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:828:13
    |
826 |             username_element.clear()
827 |             username_element.send_keys(str(username))
828 |             logger.debug("Entered username")
    |             ^^^^^^
829 |         except NoSuchElementException:
830 |             raise WorkflowExecutionError(f"Username field not found: {username_field}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:830:13
    |
828 |             logger.debug("Entered username")
829 |         except NoSuchElementException:
830 |             raise WorkflowExecutionError(f"Username field not found: {username_field}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
831 |
832 |         # Input password
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:830:19
    |
828 |             logger.debug("Entered username")
829 |         except NoSuchElementException:
830 |             raise WorkflowExecutionError(f"Username field not found: {username_field}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
831 |
832 |         # Input password
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:837:13
    |
835 |             password_element.clear()
836 |             password_element.send_keys(str(password))
837 |             logger.debug("Entered password")
    |             ^^^^^^
838 |         except NoSuchElementException:
839 |             raise WorkflowExecutionError(f"Password field not found: {password_field}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:839:13
    |
837 |             logger.debug("Entered password")
838 |         except NoSuchElementException:
839 |             raise WorkflowExecutionError(f"Password field not found: {password_field}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
840 |
841 |         # Click submit button
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:839:19
    |
837 |             logger.debug("Entered password")
838 |         except NoSuchElementException:
839 |             raise WorkflowExecutionError(f"Password field not found: {password_field}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
840 |
841 |         # Click submit button
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:845:13
    |
843 |             submit_element = self.browser.driver.find_element(By.CSS_SELECTOR, submit_button)
844 |             submit_element.click()
845 |             logger.debug("Clicked submit button")
    |             ^^^^^^
846 |         except NoSuchElementException:
847 |             raise WorkflowExecutionError(f"Submit button not found: {submit_button}")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:847:13
    |
845 |             logger.debug("Clicked submit button")
846 |         except NoSuchElementException:
847 |             raise WorkflowExecutionError(f"Submit button not found: {submit_button}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
848 |
849 |         # Wait for success indicator if provided
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:847:19
    |
845 |             logger.debug("Clicked submit button")
846 |         except NoSuchElementException:
847 |             raise WorkflowExecutionError(f"Submit button not found: {submit_button}")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
848 |
849 |         # Wait for success indicator if provided
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:855:17
    |
853 |                     EC.presence_of_element_located((By.CSS_SELECTOR, success_indicator))
854 |                 )
855 |                 logger.info("Login successful - success indicator found")
    |                 ^^^^^^
856 |             except TimeoutException:
857 |                 raise WorkflowExecutionError(
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src\scrapers\executor\workflow_executor.py:857:17
    |
855 |                   logger.info("Login successful - success indicator found")
856 |               except TimeoutException:
857 | /                 raise WorkflowExecutionError(
858 | |                     f"Login failed - success indicator not found within {self.timeout}s: {success_indicator}"
859 | |                 )
    | |_________________^
860 |           else:
861 |               # If no success indicator, wait a bit for login to process
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:857:23
    |
855 |                 logger.info("Login successful - success indicator found")
856 |             except TimeoutException:
857 |                 raise WorkflowExecutionError(
    |                       ^^^^^^^^^^^^^^^^^^^^^^
858 |                     f"Login failed - success indicator not found within {self.timeout}s: {success_indicator}"
859 |                 )
    |

E501 Line too long (109 > 100)
   --> src\scrapers\executor\workflow_executor.py:858:101
    |
856 |             except TimeoutException:
857 |                 raise WorkflowExecutionError(
858 |                     f"Login failed - success indicator not found within {self.timeout}s: {success_indicator}"
    |                                                                                                     ^^^^^^^^^
859 |                 )
860 |         else:
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:863:13
    |
861 |             # If no success indicator, wait a bit for login to process
862 |             time.sleep(3)
863 |             logger.info("Login submitted (no success indicator configured)")
    |             ^^^^^^
864 |
865 |         # Check for login failure indicators if configured
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:868:13
    |
866 |         failure_indicators = params.get("failure_indicators")
867 |         if failure_indicators:
868 |             logger.debug("Checking for login failure indicators")
    |             ^^^^^^
869 |             # Include HTTP status if available
870 |             context = {"action": "login"}
    |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
   --> src\scrapers\executor\workflow_executor.py:880:50
    |
878 |             if (
879 |                 failure_context.failure_type.value == "login_failed"
880 |                 and failure_context.confidence > 0.5
    |                                                  ^^^
881 |             ):
882 |                 logger.error(f"Login failure detected: {failure_context.details}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:882:17
    |
880 |                 and failure_context.confidence > 0.5
881 |             ):
882 |                 logger.error(f"Login failure detected: {failure_context.details}")
    |                 ^^^^^^
883 |                 raise WorkflowExecutionError(
884 |                     f"Login failed - detected failure indicators: {failure_context.details}"
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:883:23
    |
881 |             ):
882 |                 logger.error(f"Login failure detected: {failure_context.details}")
883 |                 raise WorkflowExecutionError(
    |                       ^^^^^^^^^^^^^^^^^^^^^^
884 |                     f"Login failed - detected failure indicators: {failure_context.details}"
885 |                 )
    |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> src\scrapers\executor\workflow_executor.py:886:47
    |
884 |                     f"Login failed - detected failure indicators: {failure_context.details}"
885 |                 )
886 |             elif failure_context.confidence > 0.3:
    |                                               ^^^
887 |                 logger.warning(
888 |                     f"Potential login failure detected (confidence: {failure_context.confidence}): {failure_context.details}"
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:887:17
    |
885 |                 )
886 |             elif failure_context.confidence > 0.3:
887 |                 logger.warning(
    |                 ^^^^^^
888 |                     f"Potential login failure detected (confidence: {failure_context.confidence}): {failure_context.details}"
889 |                 )
    |

E501 Line too long (125 > 100)
   --> src\scrapers\executor\workflow_executor.py:888:101
    |
886 |             elif failure_context.confidence > 0.3:
887 |                 logger.warning(
888 |                     f"Potential login failure detected (confidence: {failure_context.confidence}): {failure_context.details}"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
889 |                 )
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:894:13
    |
892 |         """Detect CAPTCHA presence on current page."""
893 |         if not self.anti_detection_manager or not self.anti_detection_manager.captcha_detector:
894 |             logger.warning("CAPTCHA detection not enabled")
    |             ^^^^^^
895 |             return
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:901:13
    |
900 |         if detected:
901 |             logger.info("CAPTCHA detected on current page")
    |             ^^^^^^
902 |             # Store detection result
903 |             self.results["captcha_details"] = {
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:908:13
    |
906 |             }
907 |         else:
908 |             logger.debug("No CAPTCHA detected on current page")
    |             ^^^^^^
909 |
910 |     def _action_handle_blocking(self, params: dict[str, Any]):
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:913:13
    |
911 |         """Handle blocking pages."""
912 |         if not self.anti_detection_manager or not self.anti_detection_manager.blocking_handler:
913 |             logger.warning("Blocking handling not enabled")
    |             ^^^^^^
914 |             return
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:920:13
    |
919 |         if handled:
920 |             logger.info("Blocking page handled successfully")
    |             ^^^^^^
921 |         else:
922 |             logger.warning("Failed to handle blocking page")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:922:13
    |
920 |             logger.info("Blocking page handled successfully")
921 |         else:
922 |             logger.warning("Failed to handle blocking page")
    |             ^^^^^^
923 |
924 |     def _action_rate_limit(self, params: dict[str, Any]):
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:927:13
    |
925 |         """Apply rate limiting delay."""
926 |         if not self.anti_detection_manager or not self.anti_detection_manager.rate_limiter:
927 |             logger.warning("Rate limiting not enabled")
    |             ^^^^^^
928 |             return
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:934:13
    |
932 |             # Custom delay
933 |             time.sleep(delay)
934 |             logger.debug(f"Applied custom rate limit delay: {delay}s")
    |             ^^^^^^
935 |         else:
936 |             # Use rate limiter's intelligent delay
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:938:13
    |
936 |             # Use rate limiter's intelligent delay
937 |             self.anti_detection_manager.rate_limiter.apply_delay()
938 |             logger.debug("Applied intelligent rate limiting")
    |             ^^^^^^
939 |
940 |     def _action_simulate_human(self, params: dict[str, Any]):
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:943:13
    |
941 |         """Simulate human-like behavior."""
942 |         if not self.anti_detection_manager or not self.anti_detection_manager.human_simulator:
943 |             logger.warning("Human behavior simulation not enabled")
    |             ^^^^^^
944 |             return
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:951:13
    |
949 |         if behavior_type == "reading":
950 |             time.sleep(duration)
951 |             logger.debug(f"Simulated reading behavior for {duration}s")
    |             ^^^^^^
952 |         elif behavior_type == "typing":
953 |             # Simulate typing delay
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:955:13
    |
953 |             # Simulate typing delay
954 |             time.sleep(duration * 0.1)  # Shorter for typing
955 |             logger.debug(f"Simulated typing behavior for {duration * 0.1}s")
    |             ^^^^^^
956 |         elif behavior_type == "navigation":
957 |             time.sleep(duration)
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:958:13
    |
956 |         elif behavior_type == "navigation":
957 |             time.sleep(duration)
958 |             logger.debug(f"Simulated navigation pause for {duration}s")
    |             ^^^^^^
959 |         else:
960 |             # Random human-like pause
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:962:13
    |
960 |             # Random human-like pause
961 |             time.sleep(random.uniform(1, duration))
962 |             logger.debug(f"Simulated random human behavior for {random.uniform(1, duration):.2f}s")
    |             ^^^^^^
963 |
964 |     def _action_rotate_session(self, params: dict[str, Any]):
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:967:13
    |
965 |         """Force session rotation."""
966 |         if not self.anti_detection_manager or not self.anti_detection_manager.session_manager:
967 |             logger.warning("Session rotation not enabled")
    |             ^^^^^^
968 |             return
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:976:13
    |
975 |         if rotated:
976 |             logger.info("Session rotated successfully")
    |             ^^^^^^
977 |         else:
978 |             logger.warning("Failed to rotate session")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:978:13
    |
976 |             logger.info("Session rotated successfully")
977 |         else:
978 |             logger.warning("Failed to rotate session")
    |             ^^^^^^
979 |
980 |     def _action_validate_http_status(self, params: dict[str, Any]):
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:991:17
    |
989 |         if status_code is None:
990 |             if fail_on_error:
991 |                 logger.error(f"Could not determine HTTP status for {current_url}")
    |                 ^^^^^^
992 |                 raise WorkflowExecutionError(f"Failed to determine HTTP status for {current_url}")
993 |             else:
    |

F821 Undefined name `WorkflowExecutionError`
   --> src\scrapers\executor\workflow_executor.py:992:23
    |
990 |             if fail_on_error:
991 |                 logger.error(f"Could not determine HTTP status for {current_url}")
992 |                 raise WorkflowExecutionError(f"Failed to determine HTTP status for {current_url}")
    |                       ^^^^^^^^^^^^^^^^^^^^^^
993 |             else:
994 |                 logger.warning(f"Could not determine HTTP status for {current_url}")
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:994:17
    |
992 |                 raise WorkflowExecutionError(f"Failed to determine HTTP status for {current_url}")
993 |             else:
994 |                 logger.warning(f"Could not determine HTTP status for {current_url}")
    |                 ^^^^^^
995 |                 return
    |

F821 Undefined name `logger`
   --> src\scrapers\executor\workflow_executor.py:997:9
    |
995 |                 return
996 |
997 |         logger.debug(f"Validated HTTP status for {current_url}: {status_code}")
    |         ^^^^^^
998 |
999 |         # Store status in results
    |

E501 Line too long (116 > 100)
    --> src\scrapers\executor\workflow_executor.py:1006:101
     |
1004 |         if expected_status is not None:
1005 |             if status_code != expected_status:
1006 |                 error_msg = f"HTTP status mismatch: expected {expected_status}, got {status_code} for {current_url}"
     |                                                                                                     ^^^^^^^^^^^^^^^^
1007 |                 if fail_on_error:
1008 |                     logger.error(error_msg)
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1008:21
     |
1006 |                 error_msg = f"HTTP status mismatch: expected {expected_status}, got {status_code} for {current_url}"
1007 |                 if fail_on_error:
1008 |                     logger.error(error_msg)
     |                     ^^^^^^
1009 |                     raise WorkflowExecutionError(error_msg)
1010 |                 else:
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1009:27
     |
1007 |                 if fail_on_error:
1008 |                     logger.error(error_msg)
1009 |                     raise WorkflowExecutionError(error_msg)
     |                           ^^^^^^^^^^^^^^^^^^^^^^
1010 |                 else:
1011 |                     logger.warning(error_msg)
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1011:21
     |
1009 |                     raise WorkflowExecutionError(error_msg)
1010 |                 else:
1011 |                     logger.warning(error_msg)
     |                     ^^^^^^
1012 |
1013 |         # Check for error status codes
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1017:17
     |
1015 |             error_msg = f"HTTP error status {status_code} detected for {current_url}"
1016 |             if fail_on_error:
1017 |                 logger.error(error_msg)
     |                 ^^^^^^
1018 |                 raise WorkflowExecutionError(error_msg)
1019 |             else:
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1018:23
     |
1016 |             if fail_on_error:
1017 |                 logger.error(error_msg)
1018 |                 raise WorkflowExecutionError(error_msg)
     |                       ^^^^^^^^^^^^^^^^^^^^^^
1019 |             else:
1020 |                 logger.warning(error_msg)
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1020:17
     |
1018 |                 raise WorkflowExecutionError(error_msg)
1019 |             else:
1020 |                 logger.warning(error_msg)
     |                 ^^^^^^
1021 |
1022 |     def _action_check_no_results(self, params: dict[str, Any]):
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1028:9
     |
1026 |         Uses both config validation patterns and failure classifier.
1027 |         """
1028 |         logger.info("Performing explicit 'check_no_results' action.")
     |         ^^^^^^
1029 |         min_confidence = params.get("min_confidence", 0.5)  # Lower threshold for explicit check
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1048:25
     |
1046 |                     elements = self.browser.driver.find_elements(By.CSS_SELECTOR, selector)
1047 |                     if elements:
1048 |                         logger.info(f"âœ… No results detected via config selector: {selector}")
     |                         ^^^^^^
1049 |                         self.results["no_results_found"] = True
1050 |                         return
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1052:21
     |
1050 |                         return
1051 |                 except Exception as e:
1052 |                     logger.debug(f"Error checking selector {selector}: {e}")
     |                     ^^^^^^
1053 |
1054 |             # Check config text patterns
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1057:21
     |
1055 |             for pattern in config_text_patterns:
1056 |                 if pattern.lower() in page_source or pattern.lower() in page_title:
1057 |                     logger.info(f"âœ… No results detected via config text pattern: {pattern}")
     |                     ^^^^^^
1058 |                     self.results["no_results_found"] = True
1059 |                     return
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1062:13
     |
1061 |         except Exception as e:
1062 |             logger.debug(f"Error during config-based no-results check: {e}")
     |             ^^^^^^
1063 |
1064 |         # Fallback to failure classifier
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1078:13
     |
1076 |         ):
1077 |             self.results["no_results_found"] = True
1078 |             logger.info(
     |             ^^^^^^
1079 |                 f"âœ… 'No results' detected via classifier with confidence "
1080 |                 f"{failure_context.confidence:.2f}."
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1084:13
     |
1082 |         else:
1083 |             self.results["no_results_found"] = False
1084 |             logger.debug(
     |             ^^^^^^
1085 |                 f"No 'no results' detected (Type: {failure_context.failure_type.value}, "
1086 |                 f"Confidence: {failure_context.confidence:.2f})."
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1095:19
     |
1093 |         if_flag = params.get("if_flag")
1094 |         if not if_flag:
1095 |             raise WorkflowExecutionError("conditional_skip action requires 'if_flag' parameter")
     |                   ^^^^^^^^^^^^^^^^^^^^^^
1096 |
1097 |         if self.results.get(if_flag):
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1098:13
     |
1097 |         if self.results.get(if_flag):
1098 |             logger.info(f"Condition '{if_flag}' is true, stopping workflow execution.")
     |             ^^^^^^
1099 |             self.workflow_stopped = True
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1115:17
     |
1113 |                     "arguments[0].scrollIntoView({block: 'center'});", element
1114 |                 )
1115 |                 logger.debug(f"Scrolled to element: {selector}")
     |                 ^^^^^^
1116 |             except NoSuchElementException:
1117 |                 raise WorkflowExecutionError(f"Scroll target element not found: {selector}")
     |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    --> src\scrapers\executor\workflow_executor.py:1117:17
     |
1115 |                 logger.debug(f"Scrolled to element: {selector}")
1116 |             except NoSuchElementException:
1117 |                 raise WorkflowExecutionError(f"Scroll target element not found: {selector}")
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1118 |         elif direction == "to_bottom":
1119 |             self.browser.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1117:23
     |
1115 |                 logger.debug(f"Scrolled to element: {selector}")
1116 |             except NoSuchElementException:
1117 |                 raise WorkflowExecutionError(f"Scroll target element not found: {selector}")
     |                       ^^^^^^^^^^^^^^^^^^^^^^
1118 |         elif direction == "to_bottom":
1119 |             self.browser.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1120:13
     |
1118 |         elif direction == "to_bottom":
1119 |             self.browser.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
1120 |             logger.debug("Scrolled to bottom of page")
     |             ^^^^^^
1121 |         elif direction == "to_top":
1122 |             self.browser.driver.execute_script("window.scrollTo(0, 0);")
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1123:13
     |
1121 |         elif direction == "to_top":
1122 |             self.browser.driver.execute_script("window.scrollTo(0, 0);")
1123 |             logger.debug("Scrolled to top of page")
     |             ^^^^^^
1124 |         else:
1125 |             scroll_amount = amount if amount is not None else "window.innerHeight"
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1128:17
     |
1126 |             if direction == "down":
1127 |                 self.browser.driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
1128 |                 logger.debug(f"Scrolled down by {scroll_amount} pixels")
     |                 ^^^^^^
1129 |             elif direction == "up":
1130 |                 self.browser.driver.execute_script(f"window.scrollBy(0, -{scroll_amount});")
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1131:17
     |
1129 |             elif direction == "up":
1130 |                 self.browser.driver.execute_script(f"window.scrollBy(0, -{scroll_amount});")
1131 |                 logger.debug(f"Scrolled up by {scroll_amount} pixels")
     |                 ^^^^^^
1132 |
1133 |     def _action_extract_from_json(self, params: dict[str, Any]):
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1140:19
     |
1139 |         if not all([selector, json_path, field_name]):
1140 |             raise WorkflowExecutionError(
     |                   ^^^^^^^^^^^^^^^^^^^^^^
1141 |                 "extract_from_json requires 'selector', 'json_path', and 'field' parameters"
1142 |             )
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1170:13
     |
1169 |             self.results[field_name] = current_data
1170 |             logger.debug(f"Extracted from JSON for {field_name}: {current_data}")
     |             ^^^^^^
1171 |
1172 |         except NoSuchElementException:
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1173:13
     |
1172 |         except NoSuchElementException:
1173 |             logger.warning(f"Script element not found for JSON extraction: {selector}")
     |             ^^^^^^
1174 |             self.results[field_name] = None
1175 |         except (json.JSONDecodeError, KeyError) as e:
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1176:13
     |
1174 |             self.results[field_name] = None
1175 |         except (json.JSONDecodeError, KeyError) as e:
1176 |             logger.warning(f"Failed to extract from JSON: {e}")
     |             ^^^^^^
1177 |             self.results[field_name] = None
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1183:19
     |
1181 |         selector = params.get("selector")
1182 |         if not selector:
1183 |             raise WorkflowExecutionError("conditional_click requires 'selector' parameter")
     |                   ^^^^^^^^^^^^^^^^^^^^^^
1184 |
1185 |         locator_type = self._get_locator_type(selector)
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1194:13
     |
1193 |             # If present, attempt the click using the main click action
1194 |             logger.info(f"Conditional element '{selector}' found. Attempting to click.")
     |             ^^^^^^
1195 |             self._action_click(params)
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1198:13
     |
1197 |         except TimeoutException:
1198 |             logger.info(f"Conditional element '{selector}' not found. Skipping click.")
     |             ^^^^^^
1199 |         except Exception as e:
1200 |             # Catch other exceptions from _action_click but log as warning
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1201:13
     |
1199 |         except Exception as e:
1200 |             # Catch other exceptions from _action_click but log as warning
1201 |             logger.warning(
     |             ^^^^^^
1202 |                 f"Conditional click on '{selector}' failed with an unexpected error: {e}"
1203 |             )
     |

PLR0912 Too many branches (14 > 12)
    --> src\scrapers\executor\workflow_executor.py:1205:9
     |
1203 |             )
1204 |
1205 |     def _action_verify(self, params: dict[str, Any]):
     |         ^^^^^^^^^^^^^^
1206 |         """Verify a value on the page against an expected value."""
1207 |         selector = params.get("selector")
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1214:19
     |
1213 |         if not all([selector, expected_value]):
1214 |             raise WorkflowExecutionError(
     |                   ^^^^^^^^^^^^^^^^^^^^^^
1215 |                 "Verify action requires 'selector' and 'expected_value' parameters"
1216 |             )
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1237:23
     |
1235 |                     match = int(expected_digits) == int(actual_digits)
1236 |             else:
1237 |                 raise WorkflowExecutionError(f"Unknown match_mode: {match_mode}")
     |                       ^^^^^^^^^^^^^^^^^^^^^^
1238 |
1239 |             if match:
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1240:17
     |
1239 | â€¦     if match:
1240 | â€¦         logger.info(
     |           ^^^^^^
1241 | â€¦             f"âœ… Verification successful for selector '{selector}'. Found '{actual_value}', expected '{expected_value}' (mode: {matâ€¦
1242 | â€¦         )
     |

E501 Line too long (150 > 100)
    --> src\scrapers\executor\workflow_executor.py:1241:100
     |
1239 | â€¦
1240 | â€¦
1241 | â€¦ '{selector}'. Found '{actual_value}', expected '{expected_value}' (mode: {match_mode})."
     |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1242 | â€¦
1243 | â€¦
     |

E501 Line too long (151 > 100)
    --> src\scrapers\executor\workflow_executor.py:1244:101
     |
1242 | â€¦
1243 | â€¦
1244 | â€¦or '{selector}'. Found '{actual_value}', expected '{expected_value}' (mode: {match_mode})."
     |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1245 | â€¦
1246 | â€¦
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1246:27
     |
1244 | â€¦     error_msg = f"Verification failed for selector '{selector}'. Found '{actual_value}', expected '{expected_value}' (mode: {matchâ€¦
1245 | â€¦     if on_failure == "fail_workflow":
1246 | â€¦         raise WorkflowExecutionError(error_msg)
     |                 ^^^^^^^^^^^^^^^^^^^^^^
1247 | â€¦     else:
1248 | â€¦         logger.warning(error_msg)
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1248:21
     |
1246 |                     raise WorkflowExecutionError(error_msg)
1247 |                 else:
1248 |                     logger.warning(error_msg)
     |                     ^^^^^^
1249 |
1250 |         except (NoSuchElementException, ValueError) as e:
     |

E501 Line too long (119 > 100)
    --> src\scrapers\executor\workflow_executor.py:1251:101
     |
1250 |         except (NoSuchElementException, ValueError) as e:
1251 |             error_msg = f"Verification failed: could not find or extract value from selector '{selector}'. Reason: {e}"
     |                                                                                                     ^^^^^^^^^^^^^^^^^^^
1252 |             if on_failure == "fail_workflow":
1253 |                 raise WorkflowExecutionError(error_msg)
     |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    --> src\scrapers\executor\workflow_executor.py:1253:17
     |
1251 |             error_msg = f"Verification failed: could not find or extract value from selector '{selector}'. Reason: {e}"
1252 |             if on_failure == "fail_workflow":
1253 |                 raise WorkflowExecutionError(error_msg)
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1254 |             else:
1255 |                 logger.warning(error_msg)
     |

F821 Undefined name `WorkflowExecutionError`
    --> src\scrapers\executor\workflow_executor.py:1253:23
     |
1251 |             error_msg = f"Verification failed: could not find or extract value from selector '{selector}'. Reason: {e}"
1252 |             if on_failure == "fail_workflow":
1253 |                 raise WorkflowExecutionError(error_msg)
     |                       ^^^^^^^^^^^^^^^^^^^^^^
1254 |             else:
1255 |                 logger.warning(error_msg)
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1255:17
     |
1253 |                 raise WorkflowExecutionError(error_msg)
1254 |             else:
1255 |                 logger.warning(error_msg)
     |                 ^^^^^^
1256 |
1257 |     def _extract_value_from_element(self, element, attribute: str | None) -> str | None:
     |

F821 Undefined name `logger`
    --> src\scrapers\executor\workflow_executor.py:1276:13
     |
1274 |                 return element.get_attribute(attribute)
1275 |         except Exception as e:
1276 |             logger.warning(f"Failed to extract value from element: {e}")
     |             ^^^^^^
1277 |             return None
     |

E402 Module level import not at top of file
  --> src\scrapers\main.py:17:1
   |
15 |     sys.path.insert(0, project_root)
16 |
17 | import os
   | ^^^^^^^^^
18 |
19 | from src.core.database.refresh import refresh_database_from_xml
   |

E402 Module level import not at top of file
  --> src\scrapers\main.py:19:1
   |
17 | import os
18 |
19 | from src.core.database.refresh import refresh_database_from_xml
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLC0415 `import` should be at the top-level of a file
  --> src\scrapers\main.py:94:13
   |
92 |     if os.path.exists(passing_file):
93 |         try:
94 |             import json
   |             ^^^^^^^^^^^
95 |
96 |             with open(passing_file) as f:
   |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
   --> src\scrapers\selector_storage.py:202:54
    |
200 |             if selector != existing.selector:
201 |                 # New selector, add as fallback and promote if more successful
202 |                 if success and existing.confidence < 0.8:
    |                                                      ^^^
203 |                     # Promote new selector to primary
204 |                     existing.fallbacks.insert(0, existing.selector)
    |

B017 Do not assert blind exception: `Exception`
  --> src\tests\verify_actions.py:95:14
   |
94 |         params["expected"] = "67890"
95 |         with self.assertRaises(Exception):  # Should raise WorkflowExecutionError
   |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
96 |             action.execute(params)
   |

E501 Line too long (101 > 100)
  --> src\ui\__init__.py:14:101
   |
12 | Editor Functions (UI Only - NO Classification):
13 | - product_editor_interactive: Edit single product with UI (accepts SKU string or product data dict)
14 | - edit_products_in_batch: Edit multiple products with UI (accepts list of SKUs or product data dicts)
   |                                                                                                     ^
15 |
16 | Usage in master.py:
   |

PLR0913 Too many arguments in function definition (7 > 5)
  --> src\ui\main_window.py:67:9
   |
65 |         from src.scrapers.main import run_scraping
66 |
67 |     def run_scraper_tests(
   |         ^^^^^^^^^^^^^^^^^
68 |         run_integration=False,
69 |         log_callback=None,
   |

PLR0912 Too many branches (13 > 12)
  --> src\ui\main_window.py:67:9
   |
65 |         from src.scrapers.main import run_scraping
66 |
67 |     def run_scraper_tests(
   |         ^^^^^^^^^^^^^^^^^
68 |         run_integration=False,
69 |         log_callback=None,
   |

PLC0415 `import` should be at the top-level of a file
  --> src\ui\main_window.py:89:13
   |
87 |         # Correctly find project root from the current file's location
88 |         try:
89 |             from src.utils.run_scraper import find_project_root
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
90 |
91 |             PROJECT_ROOT = find_project_root()
   |

N806 Variable `PROJECT_ROOT` in function should be lowercase
  --> src\ui\main_window.py:91:13
   |
89 |             from src.utils.run_scraper import find_project_root
90 |
91 |             PROJECT_ROOT = find_project_root()
   |             ^^^^^^^^^^^^
92 |         except (ImportError, FileNotFoundError):
93 |             # Fallback if run_scraper is removed
   |

N806 Variable `PROJECT_ROOT` in function should be lowercase
  --> src\ui\main_window.py:94:13
   |
92 |         except (ImportError, FileNotFoundError):
93 |             # Fallback if run_scraper is removed
94 |             PROJECT_ROOT = os.path.dirname(
   |             ^^^^^^^^^^^^
95 |                 os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
96 |             )
   |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:118:13
    |
117 |             # Use Popen to stream output
118 |             import subprocess
    |             ^^^^^^^^^^^^^^^^^
119 |
120 |             process = subprocess.Popen(
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:282:9
    |
280 |     def _request_confirmation_sync(self, title, text):
281 |         """Request a confirmation dialog on the main thread and wait for the result."""
282 |         from PyQt6.QtCore import QEventLoop
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
283 |
284 |         result_container = {"result": None, "done": False}
    |

E501 Line too long (103 > 100)
   --> src\ui\main_window.py:297:101
    |
296 |     def _request_editor_sync(self, products_list, editor_type="product"):
297 |         """Request editor on main thread and wait for result (synchronous from worker's perspective)"""
    |                                                                                                     ^^^
298 |         from PyQt6.QtCore import QEventLoop
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:298:9
    |
296 |     def _request_editor_sync(self, products_list, editor_type="product"):
297 |         """Request editor on main thread and wait for result (synchronous from worker's perspective)"""
298 |         from PyQt6.QtCore import QEventLoop
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
299 |
300 |         # Create container for result
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:310:9
    |
309 |         # Poll until done
310 |         from PyQt6.QtCore import QTimer
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
311 |
312 |         def check_done():
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:334:9
    |
332 |         once the execution is complete.
333 |         """
334 |         import asyncio
    |         ^^^^^^^^^^^^^^
335 |         import inspect
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:335:9
    |
333 |         """
334 |         import asyncio
335 |         import inspect
    |         ^^^^^^^^^^^^^^
336 |
337 |         try:
    |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src\ui\main_window.py:364:18
    |
362 |       """Professional log viewer with color-coded messages and filtering"""
363 |
364 |       LOG_COLORS = {
    |  __________________^
365 | |         "DEBUG": "#888888",
366 | |         "INFO": "#2196F3",
367 | |         "SUCCESS": "#4CAF50",
368 | |         "WARNING": "#FF9800",
369 | |         "ERROR": "#F44336",
370 | |     }
    | |_____^
371 |
372 |       LOG_ICONS = {
    |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src\ui\main_window.py:372:17
    |
370 |       }
371 |
372 |       LOG_ICONS = {
    |  _________________^
373 | |         "DEBUG": "ðŸ”§",
374 | |         "INFO": "â„¹ï¸",
375 | |         "SUCCESS": "âœ…",
376 | |         "WARNING": "âš ï¸",
377 | |         "ERROR": "âŒ",
378 | |     }
    | |_____^
379 |
380 |       def __init__(self):
    |

RUF001 String contains ambiguous `â„¹` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
   --> src\ui\main_window.py:374:18
    |
372 |     LOG_ICONS = {
373 |         "DEBUG": "ðŸ”§",
374 |         "INFO": "â„¹ï¸",
    |                  ^
375 |         "SUCCESS": "âœ…",
376 |         "WARNING": "âš ï¸",
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:510:13
    |
508 |         # Apply the global dark theme.
509 |         try:
510 |             from src.ui.styling import STYLESHEET
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
511 |
512 |             self.setStyleSheet(STYLESHEET)
    |

PLR0911 Too many return statements (7 > 6)
   --> src\ui\main_window.py:522:9
    |
520 |         self.update_database_stats()
521 |
522 |     def create_menu_bar(self):
    |         ^^^^^^^^^^^^^^^
523 |         """Create the menu bar with all application menus"""
524 |         menubar = self.menuBar()
    |

PLR0915 Too many statements (57 > 50)
   --> src\ui\main_window.py:522:9
    |
520 |         self.update_database_stats()
521 |
522 |     def create_menu_bar(self):
    |         ^^^^^^^^^^^^^^^
523 |         """Create the menu bar with all application menus"""
524 |         menubar = self.menuBar()
    |

RUF001 String contains ambiguous `â„¹` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
   --> src\ui\main_window.py:611:33
    |
609 |             return
610 |
611 |         about_action = QAction("â„¹ï¸ About", self)
    |                                 ^
612 |         about_action.triggered.connect(self.show_about_dialog)
613 |         help_menu.addAction(about_action)
    |

RUF001 String contains ambiguous `âž•` (HEAVY PLUS SIGN). Did you mean `+` (PLUS SIGN)?
   --> src\ui\main_window.py:727:14
    |
725 |             self.add_new_scraper,
726 |             "Create a new scraper configuration",
727 |             "âž•",
    |              ^^
728 |         )
729 |         self.manage_scrapers_btn = tools_card.add_button(
    |

PLR0915 Too many statements (64 > 50)
   --> src\ui\main_window.py:774:9
    |
772 |             self.log_message("No active scraping operation to cancel", "INFO")
773 |
774 |     def create_right_panel(self):
    |         ^^^^^^^^^^^^^^^^^^
775 |         """Create the right panel with status and logs"""
776 |         container = QWidget()
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:983:13
    |
981 |         """Open a specified editor on the main GUI thread (synchronous)."""
982 |         if editor_type == "product":
983 |             from src.ui.product_editor import edit_products_in_batch as editor_func
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
984 |
985 |             log_msg = "product editor"
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\main_window.py:987:13
    |
985 |             log_msg = "product editor"
986 |         elif editor_type == "classification":
987 |             from src.core.classification.ui import edit_classification_in_batch as editor_func
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
988 |
989 |             log_msg = "classification editor"
    |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1011:13
     |
1009 |         except Exception as e:
1010 |             self.log_message(f"âŒ Error opening {log_msg}: {e}", "ERROR")
1011 |             import traceback
     |             ^^^^^^^^^^^^^^^^
1012 |
1013 |             traceback.print_exc()
     |

E501 Line too long (110 > 100)
    --> src\ui\main_window.py:1037:101
     |
1035 |             self.last_operation = "Scraping"
1036 |             self.log_message(
1037 |                 f"Starting scraping for: {os.path.basename(file_path)} on sites: {', '.join(selected_sites)}",
     |                                                                                                     ^^^^^^^^^^
1038 |                 "INFO",
1039 |             )
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1069:13
     |
1067 |         try:
1068 |             self.log_message("Opening product viewer...", "INFO")
1069 |             import subprocess
     |             ^^^^^^^^^^^^^^^^^
1070 |
1071 |             # Construct path relative to this file's location
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1086:13
     |
1084 |         """Open the settings dialog"""
1085 |         try:
1086 |             from src.ui.settings_dialog import SettingsDialog
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1087 |
1088 |             dialog = SettingsDialog(self)
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1100:13
     |
1098 |         """Show database statistics dialog"""
1099 |         try:
1100 |             from src.core.database.queries import ProductDatabase
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1101 |
1102 |             db = ProductDatabase()
     |

PLR0913 Too many arguments in function definition (6 > 5)
    --> src\ui\main_window.py:1131:9
     |
1129 |             self._run_worker(self.run_classification_worker, file_path)
1130 |
1131 |     def run_classification_worker(
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^
1132 |         self,
1133 |         file_path,
     |

PLR0912 Too many branches (16 > 12)
    --> src\ui\main_window.py:1131:9
     |
1129 |             self._run_worker(self.run_classification_worker, file_path)
1130 |
1131 |     def run_classification_worker(
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^
1132 |         self,
1133 |         file_path,
     |

PLR0915 Too many statements (70 > 50)
    --> src\ui\main_window.py:1131:9
     |
1129 |             self._run_worker(self.run_classification_worker, file_path)
1130 |
1131 |     def run_classification_worker(
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^
1132 |         self,
1133 |         file_path,
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1141:9
     |
1139 |     ):
1140 |         """Worker function to run classification"""
1141 |         import pandas as pd
     |         ^^^^^^^^^^^^^^^^^^^
1142 |
1143 |         from src.core.classification.manager import classify_products_batch
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1143:9
     |
1141 |         import pandas as pd
1142 |
1143 |         from src.core.classification.manager import classify_products_batch
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1144 |
1145 |         # Determine log function
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1192:13
     |
1191 |             # --- Classification Process ---
1192 |             from src.core.settings_manager import SettingsManager
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1193 |
1194 |             settings = SettingsManager()
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1239:13
     |
1237 |             df.update(results_to_update)
1238 |
1239 |             from datetime import datetime
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1240 |
1241 |             timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1260:13
     |
1258 |         except Exception as e:
1259 |             log(f"Error during classification: {e}")
1260 |             import traceback
     |             ^^^^^^^^^^^^^^^^
1261 |
1262 |             log(traceback.format_exc())
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1267:9
     |
1265 |     def get_available_sites(self):
1266 |         """Get list of available scraping sites"""
1267 |         from src.core.settings_manager import settings
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1268 |
1269 |         scraper_system = settings.get("scraper_system", "new")
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1274:17
     |
1272 |             if scraper_system == "legacy":
1273 |                 # DEPRECATION WARNING: Using legacy system
1274 |                 import warnings
     |                 ^^^^^^^^^^^^^^^
1275 |
1276 |                 from src.scrapers.main import get_available_scrapers
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1276:17
     |
1274 |                 import warnings
1275 |
1276 |                 from src.scrapers.main import get_available_scrapers
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1277 |
1278 |                 warnings.warn(
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1287:17
     |
1285 |                 return get_available_scrapers()
1286 |             else:
1287 |                 from src.scrapers.main import get_available_scrapers
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1288 |
1289 |                 return get_available_scrapers()
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1296:9
     |
1294 |       def select_sites_dialog(self, available_sites):
1295 |           """Show dialog to select which sites to scrape"""
1296 | /         from PyQt6.QtWidgets import (
1297 | |             QDialog,
1298 | |             QHBoxLayout,
1299 | |             QLabel,
1300 | |             QListWidget,
1301 | |             QListWidgetItem,
1302 | |             QPushButton,
1303 | |             QVBoxLayout,
1304 | |         )
     | |_________^
1305 |
1306 |           dialog = QDialog(self)
     |

E501 Line too long (101 > 100)
    --> src\ui\main_window.py:1412:101
     |
1411 |     def start_scraper_tests(self):
1412 |         """Start scraper integration test process - tests all scrapers with known working products"""
     |                                                                                                     ^
1413 |         self.last_operation = "Scraper Tests"
1414 |         self.log_message(
     |

E501 Line too long (103 > 100)
    --> src\ui\main_window.py:1415:101
     |
1413 |         self.last_operation = "Scraper Tests"
1414 |         self.log_message(
1415 |             "Starting scraper integration tests (testing all scrapers with known working products)...",
     |                                                                                                     ^^^
1416 |             "INFO",
1417 |         )
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1423:13
     |
1421 |         """Open dialog to add a new scraper configuration"""
1422 |         try:
1423 |             from src.ui.scraper_management_dialog import AddScraperDialog
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1424 |
1425 |             dialog = AddScraperDialog(self)
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1434:13
     |
1432 |         """Open dialog to manage existing scraper configurations"""
1433 |         try:
1434 |             from src.ui.scraper_management_dialog import ScraperManagementDialog
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1435 |
1436 |             dialog = ScraperManagementDialog(self)
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1445:13
     |
1443 |         """Open the scraper builder dialog"""
1444 |         try:
1445 |             from src.ui.scraper_builder_dialog import ScraperBuilderDialog
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1446 |
1447 |             dialog = ScraperBuilderDialog(self)
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\main_window.py:1507:13
     |
1505 |         """Update database statistics in the UI"""
1506 |         try:
1507 |             from src.core.database.queries import ProductDatabase
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1508 |
1509 |             db = ProductDatabase()
     |

RUF059 Unpacked variable `err_type` is never used
    --> src\ui\main_window.py:1564:9
     |
1562 |     def handle_error(self, error_tuple):
1563 |         """Handle errors emitted from the worker thread"""
1564 |         err_type, err_val, err_tb = error_tuple
     |         ^^^^^^^^
1565 |         self.log_message(f"An error occurred: {err_val}", "ERROR")
1566 |         self.log_message(f"Error details: {err_tb}", "DEBUG")
     |
help: Prefix it with an underscore or any other dummy variable pattern

E501 Line too long (101 > 100)
  --> src\ui\product_creator_ui.py:8:101
   |
 6 | Usage:
 7 |     from src.ui.product_creator import create_and_save_products
 8 |     products = [ { 'SKU': '123', 'Name': 'Foo', 'Brand': 'Bar', 'Image URLs': ['http://...'], ... } ]
   |                                                                                                     ^
 9 |     create_and_save_products(products, site='MySite', output_dir='./output')
10 | """
   |

E501 Line too long (101 > 100)
  --> src\ui\product_creator_ui.py:21:101
   |
20 | def _map_product_to_shopsite_row(product, date_string):
21 |     """Map friendly product dict to ShopSite column names used in master.save_incremental_results."""
   |                                                                                                     ^
22 |     brand = product.get("Brand", "")
23 |     name = product.get("Name", "")
   |

E501 Line too long (111 > 100)
  --> src\ui\product_creator_ui.py:92:101
   |
91 | def append_row_to_site_file(row: dict, site: str, output_dir=None):
92 |     """Append a single mapped ShopSite row to the site's spreadsheet (like master.save_incremental_results)."""
   |                                                                                                     ^^^^^^^^^^^
93 |     base_dir = Path(output_dir) if output_dir else (Path(__file__).parent / "output")
94 |     base_dir.mkdir(parents=True, exist_ok=True)
   |

RUF005 Consider iterable unpacking instead of concatenation
   --> src\ui\product_creator_ui.py:100:9
    |
 98 |       more_info_cols = [f"More Information Image {i}" for i in range(1, 6)]
 99 |       columns = (
100 | /         [
101 | |             "SKU",
102 | |             "Name",
103 | |             "Product Description",
104 | |             "Price",
105 | |             "Weight",
106 | |             "Product Field 16",
107 | |             "File name",
108 | |             "Graphic",
109 | |             "More Information Graphic",
110 | |             "Product Field 1",
111 | |             "Product Field 11",
112 | |         ]
113 | |         + more_info_cols
114 | |         + [
115 | |             "Product Field 24",
116 | |             "Product Field 25",
117 | |             "Product On Pages",
118 | |             "ProductDisabled",
119 | |         ]
    | |_________^
120 |       )
    |
help: Replace with iterable unpacking

E501 Line too long (135 > 100)
   --> src\ui\product_creator_ui.py:141:101
    |
140 | â€¦
141 | â€¦mpty product, then prompt for site and append the result to the site's spreadsheet.
    |                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
142 | â€¦
143 | â€¦ed.
    |

PLC0415 `import` should be at the top-level of a file
  --> src\ui\product_editor.py:86:13
   |
84 |         # Apply the global dark theme.
85 |         try:
86 |             from src.ui.styling import STYLESHEET
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
87 |
88 |             self.setStyleSheet(STYLESHEET)
   |

PLR0912 Too many branches (15 > 12)
   --> src\ui\product_editor.py:285:9
    |
283 |         return footer
284 |
285 |     def load_product_into_ui(self, index):
    |         ^^^^^^^^^^^^^^^^^^^^
286 |         """Load product data into the UI."""
287 |         if not (0 <= index < len(self.products_list)):
    |

PLR0915 Too many statements (71 > 50)
   --> src\ui\product_editor.py:285:9
    |
283 |         return footer
284 |
285 |     def load_product_into_ui(self, index):
    |         ^^^^^^^^^^^^^^^^^^^^
286 |         """Load product data into the UI."""
287 |         if not (0 <= index < len(self.products_list)):
    |

RUF015 Prefer `next(iter(image_sets.keys()))` over single element slice
   --> src\ui\product_editor.py:415:26
    |
413 |         # Select first source
414 |         if image_sets:
415 |             first_site = list(image_sets.keys())[0]
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
416 |             self._select_image_source(first_site)
    |
help: Replace with `next(iter(image_sets.keys()))`

PLC0415 `import` should be at the top-level of a file
   --> src\ui\product_editor.py:472:13
    |
470 |         """Load image from URL."""
471 |         try:
472 |             from PyQt6.QtCore import QEventLoop, QUrl
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
473 |             from PyQt6.QtNetwork import QNetworkAccessManager, QNetworkReply, QNetworkRequest
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\product_editor.py:473:13
    |
471 |         try:
472 |             from PyQt6.QtCore import QEventLoop, QUrl
473 |             from PyQt6.QtNetwork import QNetworkAccessManager, QNetworkReply, QNetworkRequest
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
474 |
475 |             manager = QNetworkAccessManager()
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\product_editor.py:696:5
    |
695 |     # Event loop
696 |     from PyQt6.QtCore import QEventLoop
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
697 |
698 |     loop = QEventLoop()
    |

E402 Module level import not at top of file
  --> src\ui\product_viewer.py:12:1
   |
10 |       sys.path.insert(0, project_root)
11 |
12 | / from PyQt6.QtWidgets import (
13 | |     QAbstractItemView,
14 | |     QApplication,
15 | |     QCheckBox,
16 | |     QComboBox,
17 | |     QGroupBox,
18 | |     QHBoxLayout,
19 | |     QHeaderView,
20 | |     QLabel,
21 | |     QLineEdit,
22 | |     QMainWindow,
23 | |     QMessageBox,
24 | |     QPushButton,
25 | |     QTableWidget,
26 | |     QTableWidgetItem,
27 | |     QVBoxLayout,
28 | |     QWidget,
29 | | )
   | |_^
30 |
31 |   try:
   |

E402 Module level import not at top of file
  --> src\ui\product_viewer.py:43:1
   |
42 | # Database path - find it relative to project root
43 | import os
   | ^^^^^^^^^
44 |
45 | PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
   |

PLC0415 `import` should be at the top-level of a file
  --> src\ui\product_viewer.py:57:13
   |
55 |         # Apply the global dark theme.
56 |         try:
57 |             from src.ui.styling import STYLESHEET
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
58 |
59 |             self.setStyleSheet(STYLESHEET)
   |

PLR0915 Too many statements (123 > 50)
  --> src\ui\product_viewer.py:94:9
   |
92 |         self.conn.text_factory = str
93 |
94 |     def create_widgets(self):
   |         ^^^^^^^^^^^^^^
95 |         """Create the main UI components."""
96 |         # Central widget and layout
   |

PLR0915 Too many statements (66 > 50)
   --> src\ui\product_viewer.py:411:9
    |
409 |         self.table.verticalScrollBar().setValue(0)
410 |
411 |     def load_products(self):
    |         ^^^^^^^^^^^^^
412 |         """Load products from database with current filters."""
413 |         if self.conn is None:
    |

E501 Line too long (119 > 100)
   --> src\ui\product_viewer.py:459:101
    |
457 |             # Add product type filter
458 |             if self.product_type_filter:
459 |                 query += " AND (Product_Type LIKE ? OR Product_Type LIKE ? OR Product_Type LIKE ? OR Product_Type = ?)"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^
460 |                 # Match: "|Type|", "Type|", "|Type", "Type"
461 |                 type_param = self.product_type_filter
    |

E501 Line too long (102 > 100)
   --> src\ui\product_viewer.py:571:101
    |
569 |             # Get distinct categories - split by "|" and collect unique values
570 |             cursor.execute(
571 |                 "SELECT DISTINCT Category FROM products WHERE Category IS NOT NULL AND Category != ''"
    |                                                                                                     ^^
572 |             )
573 |             categories = set()
    |

E501 Line too long (114 > 100)
   --> src\ui\product_viewer.py:584:101
    |
582 |             # Get distinct product types - split by "|" and collect unique values
583 |             cursor.execute(
584 |                 "SELECT DISTINCT Product_Type FROM products WHERE Product_Type IS NOT NULL AND Product_Type != ''"
    |                                                                                                     ^^^^^^^^^^^^^^
585 |             )
586 |             product_types = set()
    |

E501 Line too long (128 > 100)
   --> src\ui\product_viewer.py:704:101
    |
703 |         if self.search_term or filter_parts:
704 |             status = f"Found {self.total_products} products{filter_desc} | Showing {visible_count} | Selected: {selected_count}"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
705 |         else:
706 |             status = f"Total: {self.total_products} products | Showing {visible_count} | Selected: {selected_count}"
    |

E501 Line too long (116 > 100)
   --> src\ui\product_viewer.py:706:101
    |
704 |             status = f"Found {self.total_products} products{filter_desc} | Showing {visible_count} | Selected: {selected_count}"
705 |         else:
706 |             status = f"Total: {self.total_products} products | Showing {visible_count} | Selected: {selected_count}"
    |                                                                                                     ^^^^^^^^^^^^^^^^
707 |
708 |         self.status_label.setText(status)
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\product_viewer.py:768:13
    |
766 |         except Exception as e:
767 |             QMessageBox.critical(self, "Error", f"Failed to edit products: {e}")
768 |             import traceback
    |             ^^^^^^^^^^^^^^^^
769 |
770 |             traceback.print_exc()
    |

E501 Line too long (136 > 100)
   --> src\ui\product_viewer.py:787:101
    |
785 | â€¦
786 | â€¦
787 | â€¦ht, Category, Product_Type, Product_On_Pages, Special_Order, Images, ProductDisabled
    |                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
788 | â€¦
789 | â€¦
    |

PLR2004 Magic value used in comparison, consider replacing `2000` with a constant variable
   --> src\ui\scraper_builder_dialog.py:150:27
    |
148 |         # Show preview (first 2000 chars)
149 |         preview = content[:2000]
150 |         if len(content) > 2000:
    |                           ^^^^
151 |             preview += "\n\n[... content truncated ...]"
152 |         self.content_preview.setPlainText(preview)
    |

N802 Function name `isComplete` should be lowercase
   --> src\ui\scraper_builder_dialog.py:163:9
    |
161 |         QMessageBox.critical(self, "Error", f"Failed to load page: {error_msg}")
162 |
163 |     def isComplete(self):
    |         ^^^^^^^^^^
164 |         """Check if page is complete."""
165 |         return (
    |

RUF001 String contains ambiguous `âž•` (HEAVY PLUS SIGN). Did you mean `+` (PLUS SIGN)?
   --> src\ui\scraper_builder_dialog.py:250:46
    |
248 |         manual_layout.addWidget(self.attr_combo)
249 |
250 |         self.add_selector_btn = QPushButton("âž• Add")
    |                                              ^^
251 |         self.add_selector_btn.clicked.connect(self.add_manual_selector)
252 |         manual_layout.addWidget(self.add_selector_btn)
    |

E722 Do not use bare `except`
   --> src\ui\scraper_builder_dialog.py:288:9
    |
286 |             if url:
287 |                 self.visual_picker.set_url(url)
288 |         except:
    |         ^^^^^^
289 |             pass
    |

PLW2901 `for` loop variable `selector_info` overwritten by assignment target
   --> src\ui\scraper_builder_dialog.py:325:17
    |
323 |             if not isinstance(selector_info, dict):
324 |                 selectors[field_name] = {}
325 |                 selector_info = selectors[field_name]
    |                 ^^^^^^^^^^^^^
326 |             selector_info["source"] = "ai"
327 |         self.typed_wizard.set_wizard_data("suggested_selectors", selectors)
    |

N802 Function name `isComplete` should be lowercase
   --> src\ui\scraper_builder_dialog.py:471:9
    |
469 |         self.completeChanged.emit()
470 |
471 |     def isComplete(self):
    |         ^^^^^^^^^^
472 |         """Check if page is complete."""
473 |         suggested_selectors = self.typed_wizard.get_wizard_data("suggested_selectors", {}) or {}
    |

N802 Function name `initializePage` should be lowercase
   --> src\ui\scraper_builder_dialog.py:524:9
    |
522 |         layout.addWidget(self.summary_label)
523 |
524 |     def initializePage(self):
    |         ^^^^^^^^^^^^^^
525 |         """Initialize page with selectors from previous page."""
526 |         prev_page = self.typed_wizard.page(1)  # Selector generation page
    |

N802 Function name `isComplete` should be lowercase
   --> src\ui\scraper_builder_dialog.py:631:9
    |
629 |         self.completeChanged.emit()
630 |
631 |     def isComplete(self):
    |         ^^^^^^^^^^
632 |         """Check if page is complete."""
633 |         return super().isComplete() and hasattr(self.typed_wizard, "test_results")
    |

N802 Function name `initializePage` should be lowercase
   --> src\ui\scraper_builder_dialog.py:694:9
    |
692 |         self.registerField("scraper_name*", self.name_input)
693 |
694 |     def initializePage(self):
    |         ^^^^^^^^^^^^^^
695 |         """Initialize page with data from previous pages."""
696 |         # Generate YAML preview
    |

PLR0912 Too many branches (14 > 12)
   --> src\ui\scraper_builder_dialog.py:699:9
    |
697 |         self.generate_yaml_preview()
698 |
699 |     def generate_yaml_preview(self):
    |         ^^^^^^^^^^^^^^^^^^^^^
700 |         """Generate YAML preview from collected data."""
701 |         try:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\scraper_builder_dialog.py:831:13
    |
830 |             # Convert to YAML
831 |             import yaml
    |             ^^^^^^^^^^^
832 |
833 |             yaml_content = yaml.safe_dump(
    |

N802 Function name `isComplete` should be lowercase
   --> src\ui\scraper_builder_dialog.py:906:9
    |
904 |             print(f"Warning: Failed to save selectors to storage: {e}")
905 |
906 |     def isComplete(self):
    |         ^^^^^^^^^^
907 |         """Check if page is complete."""
908 |         return super().isComplete() and self.typed_wizard.config_saved
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\scraper_builder_dialog.py:970:13
    |
968 |         try:
969 |             # Use simple HTTP request to get page content
970 |             import requests
    |             ^^^^^^^^^^^^^^^
971 |             from bs4 import BeautifulSoup
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\scraper_builder_dialog.py:971:13
    |
969 |             # Use simple HTTP request to get page content
970 |             import requests
971 |             from bs4 import BeautifulSoup
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
972 |
973 |             headers = {
    |

E501 Line too long (147 > 100)
   --> src\ui\scraper_builder_dialog.py:974:101
    |
973 | â€¦
974 | â€¦0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
975 | â€¦
    |

E501 Line too long (119 > 100)
    --> src\ui\scraper_builder_dialog.py:1020:101
     |
1018 |             # Create prompt for selector generation
1019 |             prompt = f"""
1020 | Analyze this HTML content from a product page and suggest CSS selectors for the following specific product fields only.
     |                                                                                                     ^^^^^^^^^^^^^^^^^^^
1021 | Return a JSON object with field names as keys and selector objects as values.
     |

E501 Line too long (137 > 100)
    --> src\ui\scraper_builder_dialog.py:1036:101
     |
1034 | â€¦ef, etc.)
1035 | â€¦ post-processing
1036 | â€¦gex" (to extract part of text), "weight" (to parse weight), "price" (to clean price)
     |                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1037 | â€¦
1038 | â€¦ring group
     |

E501 Line too long (170 > 100)
    --> src\ui\scraper_builder_dialog.py:1042:101
     |
1041 | â€¦
1042 | â€¦lector for the script tag and attribute="text", then set processing.type="json" and processing.path.
     |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1043 | â€¦ype="weight".
1044 | â€¦
     |

E501 Line too long (121 > 100)
    --> src\ui\scraper_builder_dialog.py:1046:101
     |
1044 | - For price, if found like "$10.00", use processing.type="price".
1045 | - Return only valid JSON with no null values.
1046 | - When using contains selectors, use the proper CSS pseudo-class ':-soup-contains' instead of the deprecated ':contains'.
     |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^
1047 |
1048 | HTML Content:
     |

PLC0415 `import` should be at the top-level of a file
    --> src\ui\scraper_builder_dialog.py:1120:13
     |
1119 |         try:
1120 |             from bs4 import BeautifulSoup
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1121 |
1122 |             soup = BeautifulSoup(self.page_content, "html.parser")
     |

RUF001 String contains ambiguous `âž•` (HEAVY PLUS SIGN). Did you mean `+` (PLUS SIGN)?
  --> src\ui\scraper_management_dialog.py:71:37
   |
69 |         buttons_layout = QHBoxLayout()
70 |
71 |         self.add_btn = QPushButton("âž• Add New Scraper")
   |                                     ^^
72 |         self.add_btn.clicked.connect(self.add_scraper)
73 |         buttons_layout.addWidget(self.add_btn)
   |

E501 Line too long (109 > 100)
   --> src\ui\scraper_management_dialog.py:171:101
    |
169 |                     item = QListWidgetItem(f"ðŸ“„ {config.name}")
170 |                     item.setToolTip(
171 |                         f"Base URL: {config.base_url}\nTimeout: {config.timeout}s\nRetries: {config.retries}"
    |                                                                                                     ^^^^^^^^^
172 |                     )
173 |                     self.scraper_list.addItem(item)
    |

E501 Line too long (110 > 100)
   --> src\ui\scraper_management_dialog.py:288:101
    |
286 |             self,
287 |             "Confirm Delete",
288 |             f"Are you sure you want to delete the scraper '{scraper_name}'?\n\nThis action cannot be undone.",
    |                                                                                                     ^^^^^^^^^^
289 |             QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
290 |             QMessageBox.StandardButton.No,
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\scraper_management_dialog.py:487:13
    |
485 |         # Load current config as YAML
486 |         try:
487 |             import yaml
    |             ^^^^^^^^^^^
488 |
489 |             yaml_content = yaml.safe_dump(
    |

E501 Line too long (173 > 100)
   --> src\ui\scraper_management_dialog.py:526:100
    |
524 | â€¦
525 | â€¦
526 | â€¦Base URL: {config.base_url}\nSelectors: {len(config.selectors)}\nWorkflows: {len(config.workflows)}",
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
527 | â€¦
528 | â€¦
    |

PLC0415 `import` should be at the top-level of a file
  --> src\ui\settings_dialog.py:42:13
   |
40 |         # Apply the global dark theme.
41 |         try:
42 |             from src.ui.styling import STYLESHEET
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 |
44 |             self.setStyleSheet(
   |

PLR0915 Too many statements (55 > 50)
   --> src\ui\settings_dialog.py:209:9
    |
207 |         self.tab_widget.addTab(tab, "ðŸª ShopSite API")
208 |
209 |     def create_application_tab(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^
210 |         """Create the application settings tab."""
211 |         tab = QWidget()
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\settings_dialog.py:274:9
    |
273 |         # Classification method dropdown
274 |         from PyQt6.QtWidgets import QComboBox
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
275 |
276 |         self.classification_method = QComboBox()
    |

E501 Line too long (104 > 100)
   --> src\ui\settings_dialog.py:279:101
    |
277 |         self.classification_method.addItems(["llm", "local_llm", "fuzzy"])
278 |         self.classification_method.setToolTip(
279 |             "llm: OpenRouter API only\nlocal_llm: Local Ollama (no API key)\nfuzzy: fuzzy matching only"
    |                                                                                                     ^^^^
280 |         )
281 |         ai_layout.addRow("Classification Method:", self.classification_method)
    |

E501 Line too long (123 > 100)
   --> src\ui\settings_dialog.py:371:101
    |
369 |             self,
370 |             "Reset Settings",
371 |             "Are you sure you want to reset all settings to defaults?\n\nThis will clear all your configured credentials.",
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^
372 |             QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
373 |             QMessageBox.StandardButton.No,
    |

E501 Line too long (327 > 100)
  --> src\ui\styling.py:80:101
   |
78 | â€¦
79 | â€¦
80 | â€¦AwIDEwIDciIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PHBhdGggZD0iTTEgMy41TDQuMDggNi41TDkgMSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiLz48L3N2Zz4=);
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
81 | â€¦
82 | â€¦
   |

E501 Line too long (187 > 100)
   --> src\ui\styling.py:170:101
    |
168 | â€¦
169 | â€¦
170 | â€¦y5vcmcvMjAwMC9zdmciIHdpZHRoPSI4IiBoZWlnaHQ9IjQiPjxwYXRoIGQ9Ik00IDAgTDAgNEg4WiIgZmlsbD0iI2ZmZiIvPjwvc3ZnPg==);
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
171 | â€¦
172 | â€¦
    |

E501 Line too long (183 > 100)
   --> src\ui\styling.py:175:101
    |
173 | â€¦
174 | â€¦
175 | â€¦3My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4IiBoZWlnaHQ9IjQiPjxwYXRoIGQ9Ik00IDRMMCAwSDhaIiBmaWxsPSIjZmZmIi8+PC9zdmc+);
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
176 | â€¦
177 | â€¦
    |

E501 Line too long (327 > 100)
   --> src\ui\styling.py:241:101
    |
239 | â€¦
240 | â€¦
241 | â€¦AwIDEwIDciIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PHBhdGggZD0iTTEgMy41TDQuMDggNi41TDkgMSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiLz48L3N2Zz4=);
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
242 | â€¦
243 | â€¦
    |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src\ui\styling.py:254:18
    |
252 |       """Professional log viewer with color-coded messages and filtering"""
253 |
254 |       LOG_COLORS = {
    |  __________________^
255 | |         "DEBUG": MUTED_TEXT_COLOR,
256 | |         "INFO": ACCENT_COLOR,
257 | |         "SUCCESS": SUCCESS_COLOR,
258 | |         "WARNING": WARNING_COLOR,
259 | |         "ERROR": ERROR_COLOR,
260 | |     }
    | |_____^
261 |
262 |       LOG_ICONS = {
    |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src\ui\styling.py:262:17
    |
260 |       }
261 |
262 |       LOG_ICONS = {
    |  _________________^
263 | |         "DEBUG": "ðŸ”§",
264 | |         "INFO": "â„¹ï¸",
265 | |         "SUCCESS": "âœ…",
266 | |         "WARNING": "âš ï¸",
267 | |         "ERROR": "âŒ",
268 | |     }
    | |_____^
269 |
270 |       def __init__(self):
    |

RUF001 String contains ambiguous `â„¹` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
   --> src\ui\styling.py:264:18
    |
262 |     LOG_ICONS = {
263 |         "DEBUG": "ðŸ”§",
264 |         "INFO": "â„¹ï¸",
    |                  ^
265 |         "SUCCESS": "âœ…",
266 |         "WARNING": "âš ï¸",
    |

E501 Line too long (103 > 100)
   --> src\ui\styling.py:418:101
    |
417 |     def _request_editor_sync(self, products_list):
418 |         """Request editor on main thread and wait for result (synchronous from worker's perspective)"""
    |                                                                                                     ^^^
419 |
420 |         # Create container for result
    |

PLR0912 Too many branches (17 > 12)
  --> src\ui\utils.py:38:5
   |
38 | def select_excel_file_text():
   |     ^^^^^^^^^^^^^^^^^^^^^^
39 |     """Text-based file selection fallback when GUI is not available."""
40 |     input_dir = os.path.join(PROJECT_ROOT, "src", "data", "spreadsheets")
   |

PLR0915 Too many statements (86 > 50)
  --> src\ui\visual_selector_picker.py:51:9
   |
49 |         self.setup_ui()
50 |
51 |     def setup_ui(self):
   |         ^^^^^^^^
52 |         """Setup the user interface."""
53 |         layout = QVBoxLayout(self)
   |

RUF001 String contains ambiguous `âž•` (HEAVY PLUS SIGN). Did you mean `+` (PLUS SIGN)?
   --> src\ui\visual_selector_picker.py:181:46
    |
179 |         buttons_layout.addWidget(self.validate_btn)
180 |
181 |         self.add_selector_btn = QPushButton("âž• Add Selector")
    |                                              ^^
182 |         self.add_selector_btn.clicked.connect(self.add_selector)
183 |         buttons_layout.addWidget(self.add_selector_btn)
    |

N802 Function name `javaScriptConsoleMessage` should be lowercase
   --> src\ui\visual_selector_picker.py:517:9
    |
515 |         super().__init__(parent)
516 |
517 |     def javaScriptConsoleMessage(self, level, message, lineNumber, sourceID):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
518 |         """Handle JavaScript console messages."""
519 |         if QWebEnginePage is not None:
    |

N803 Argument name `lineNumber` should be lowercase
   --> src\ui\visual_selector_picker.py:517:56
    |
515 |         super().__init__(parent)
516 |
517 |     def javaScriptConsoleMessage(self, level, message, lineNumber, sourceID):
    |                                                        ^^^^^^^^^^
518 |         """Handle JavaScript console messages."""
519 |         if QWebEnginePage is not None:
    |

N803 Argument name `sourceID` should be lowercase
   --> src\ui\visual_selector_picker.py:517:68
    |
515 |         super().__init__(parent)
516 |
517 |     def javaScriptConsoleMessage(self, level, message, lineNumber, sourceID):
    |                                                                    ^^^^^^^^
518 |         """Handle JavaScript console messages."""
519 |         if QWebEnginePage is not None:
    |

N802 Function name `qtSelectorSelected` should be lowercase
   --> src\ui\visual_selector_picker.py:523:9
    |
522 |     # This method will be called from JavaScript
523 |     def qtSelectorSelected(self, selector: str, element_info_json: str):
    |         ^^^^^^^^^^^^^^^^^^
524 |         """Handle selector selection from JavaScript."""
525 |         try:
    |

PLC0415 `import` should be at the top-level of a file
   --> src\ui\visual_selector_picker.py:555:9
    |
553 |     """Validate a selector against HTML content."""
554 |     try:
555 |         from bs4 import BeautifulSoup
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
556 |
557 |         soup = BeautifulSoup(html_content, "html.parser")
    |

E501 Line too long (105 > 100)
  --> src\utils\check_dataset.py:17:101
   |
15 |             SELECT
16 |                 COUNT(*) as total,
17 |                 SUM(CASE WHEN Category IS NOT NULL AND Category != "" THEN 1 ELSE 0 END) as has_category,
   |                                                                                                     ^^^^^
18 |                 SUM(CASE WHEN Product_Type IS NOT NULL AND Product_Type != "" THEN 1 ELSE 0 END) as has_type,
19 |                 SUM(CASE WHEN Product_On_Pages IS NOT NULL AND Product_On_Pages != "" THEN 1 ELSE 0 END) as has_pages
   |

E501 Line too long (109 > 100)
  --> src\utils\check_dataset.py:18:101
   |
16 |                 COUNT(*) as total,
17 |                 SUM(CASE WHEN Category IS NOT NULL AND Category != "" THEN 1 ELSE 0 END) as has_category,
18 |                 SUM(CASE WHEN Product_Type IS NOT NULL AND Product_Type != "" THEN 1 ELSE 0 END) as has_type,
   |                                                                                                     ^^^^^^^^^
19 |                 SUM(CASE WHEN Product_On_Pages IS NOT NULL AND Product_On_Pages != "" THEN 1 ELSE 0 END) as has_pages
20 |             FROM products
   |

E501 Line too long (117 > 100)
  --> src\utils\check_dataset.py:19:101
   |
17 |                 SUM(CASE WHEN Category IS NOT NULL AND Category != "" THEN 1 ELSE 0 END) as has_category,
18 |                 SUM(CASE WHEN Product_Type IS NOT NULL AND Product_Type != "" THEN 1 ELSE 0 END) as has_type,
19 |                 SUM(CASE WHEN Product_On_Pages IS NOT NULL AND Product_On_Pages != "" THEN 1 ELSE 0 END) as has_pages
   |                                                                                                     ^^^^^^^^^^^^^^^^^
20 |             FROM products
21 |         """
   |

E501 Line too long (101 > 100)
  --> src\utils\check_dataset.py:47:101
   |
46 |         cursor = conn.execute(
47 |             'SELECT Product_Type FROM products WHERE Product_Type IS NOT NULL AND Product_Type != ""'
   |                                                                                                     ^
48 |         )
49 |         types = set(row[0] for row in cursor.fetchall())
   |

E402 Module level import not at top of file
  --> src\utils\classify_excel.py:20:1
   |
18 |     sys.path.insert(0, PROJECT_ROOT)
19 |
20 | from src.core.classification.manager import classify_products_batch
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 |
22 | # Import classification functions
   |

E402 Module level import not at top of file
  --> src\utils\classify_excel.py:23:1
   |
22 | # Import classification functions
23 | from src.core.classification.ui import edit_classification_in_batch
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 | from src.core.settings_manager import SettingsManager
   |

E402 Module level import not at top of file
  --> src\utils\classify_excel.py:24:1
   |
22 | # Import classification functions
23 | from src.core.classification.ui import edit_classification_in_batch
24 | from src.core.settings_manager import SettingsManager
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLR0915 Too many statements (53 > 50)
  --> src\utils\classify_excel.py:27:5
   |
27 | def classify_excel_file():
   |     ^^^^^^^^^^^^^^^^^^^
28 |     """
29 |     Standalone classification tool for Excel files.
   |

PLC0415 `import` should be at the top-level of a file
   --> src\utils\classify_excel.py:126:9
    |
125 |         # Add/update the 'Last Edited' timestamp
126 |         from datetime import datetime
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
127 |
128 |         timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    |

PLC0415 `import` should be at the top-level of a file
   --> src\utils\classify_excel.py:148:9
    |
146 |     except Exception as e:
147 |         print(f"âŒ Error during classification: {e}")
148 |         import traceback
    |         ^^^^^^^^^^^^^^^^
149 |
150 |         traceback.print_exc()
    |

RUF001 String contains ambiguous `â„¹` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
  --> src\utils\file\excel.py:55:20
   |
54 |         if converted_count == 0:
55 |             print("â„¹ï¸ No .xlsx files found to convert")
   |                    ^
56 |         else:
57 |             print(f"âœ… Successfully converted {converted_count} files")
   |

PLR0912 Too many branches (16 > 12)
  --> src\utils\general\display.py:13:5
   |
13 | def display_product_result(
   |     ^^^^^^^^^^^^^^^^^^^^^^
14 |     product: dict[str, Any],
15 |     index: int | None = None,
   |

PLR2004 Magic value used in comparison, consider replacing `60` with a constant variable
  --> src\utils\general\display.py:51:20
   |
50 |     # Truncate long names for display
51 |     if len(name) > 60:
   |                    ^^
52 |         name = name[:57] + "..."
   |

E501 Line too long (101 > 100)
   --> src\utils\general\display.py:129:101
    |
127 |     eta = remaining / rate if rate > 0 else 0
128 |
129 |     # Show progress at start, every few items for small lists, every 10th for large lists, and at end
    |                                                                                                     ^
130 |     if current == 1:
131 |         progress_pct = (current / total) * 100
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> src\utils\general\display.py:136:19
    |
134 |             f"Rate: {rate:.1f}/sec | ETA: {eta:.0f}s"
135 |         )
136 |     elif total <= 10 or current % max(1, total // 10) == 0 or current == total:
    |                   ^^
137 |         progress_pct = (current / total) * 100
138 |         output(
    |

PLW0603 Using the global statement to update `_SUPPRESS_SUMMARY` is discouraged
   --> src\utils\general\display.py:153:12
    |
151 | def set_suppress_summary(suppress: bool):
152 |     """Set whether to suppress scraping summary output (used during testing)."""
153 |     global _SUPPRESS_SUMMARY
    |            ^^^^^^^^^^^^^^^^^
154 |     _SUPPRESS_SUMMARY = suppress
    |

RUF001 String contains ambiguous `â„¹` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
   --> src\utils\general\display.py:261:14
    |
259 |         # If it's already a callable (like emit method or function), use it directly
260 |         output = log_callback
261 |     output(f"â„¹ï¸  {message}")
    |              ^
    |

PLW2901 `with` statement variable `img` overwritten by assignment target
  --> src\utils\images\image_convert.py:19:13
   |
17 |     try:
18 |         with Image.open(path) as img:
19 |             img = img.convert("RGB")
   |             ^^^
20 |             width, height = img.size
   |

PLW2901 `with` statement variable `img` overwritten by assignment target
  --> src\utils\images\image_convert.py:30:13
   |
28 |                 new_width = int((width / height) * 1000)
29 |
30 |             img = img.resize((new_width, new_height), Image.LANCZOS)
   |             ^^^
31 |
32 |             # Create white background canvas
   |

PLR2004 Magic value used in comparison, consider replacing `255` with a constant variable
  --> src\utils\images\processing.py:71:35
   |
70 |     sanitized_file_name = sanitize_filename(file_name)
71 |     if len(sanitized_file_name) > 255:
   |                                   ^^^
72 |         sanitized_file_name = sanitized_file_name[:255]
   |

RUF059 Unpacked variable `ext` is never used
  --> src\utils\images\processing.py:77:15
   |
75 |         img_name = os.path.join(folder_path, sanitized_file_name)
76 |     else:
77 |         name, ext = os.path.splitext(sanitized_file_name)
   |               ^^^
78 |         img_name = os.path.join(folder_path, f"{name}-{idx}.jpg")
   |
help: Prefix it with an underscore or any other dummy variable pattern

E501 Line too long (136 > 100)
  --> src\utils\images\processing.py:81:101
   |
80 | â€¦
81 | â€¦ Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
   |                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
82 | â€¦ml,image/*,*/*;q=0.8",
83 | â€¦
   |

PLR0913 Too many arguments in function definition (6 > 5)
  --> src\utils\scraping\browser.py:18:9
   |
16 |     """Base browser class for scrapers with common functionality."""
17 |
18 |     def __init__(
   |         ^^^^^^^^
19 |         self,
20 |         site_name,
   |

E501 Line too long (152 > 100)
   --> src\utils\scraping\browser.py:99:101
    |
 97 | â€¦
 98 | â€¦
 99 | â€¦it_time:.2f}s (headless={headless}, devtools={enable_devtools}, CI={is_ci}, size=1920x1080)"
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
100 | â€¦
    |

PLR0913 Too many arguments in function definition (6 > 5)
   --> src\utils\scraping\browser.py:202:5
    |
202 | def create_browser(
    |     ^^^^^^^^^^^^^^
203 |     site_name,
204 |     headless=True,
    |

PLR0915 Too many statements (82 > 50)
 --> src\utils\scraping\scraping.py:7:5
  |
7 | def get_standard_chrome_options(
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
8 |     headless=True, profile_suffix="default", enable_devtools=False, devtools_port=9222
9 | ):
  |

E501 Line too long (132 > 100)
  --> src\utils\scraping\scraping.py:89:101
   |
87 |     # User agent
88 |     options.add_argument(
89 |         "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
   |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
90 |     )
   |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> src\utils\scraping\scraping.py:127:33
    |
125 | def clean_string(s):
126 |     s = s.strip()
127 |     if s.isupper() and len(s) > 3:
    |                                 ^
128 |         s = smart_title(s)
    |

RUF001 String contains ambiguous `â€“` (EN DASH). Did you mean `-` (HYPHEN-MINUS)?
   --> src\utils\scraping\scraping.py:134:28
    |
132 |     s = re.sub(r"[\|\u00AE\u2122\u00A9]", "", s)
133 |
134 |     s = re.sub(r"(\d+)\s*[-â€“â€”]\s*(\d+)", r"\1-\2", s)
    |                            ^
135 |     s = re.sub(r"(\d+)\"", r"\1 in.", s)
136 |     s = re.sub(r"(\d+)'", r"\1 ft.", s)
    |

E501 Line too long (116 > 100)
   --> src\utils\scraping\scraping.py:148:101
    |
147 | def smart_title(s):
148 |     """Title case that handles apostrophes correctly (e.g., "world's best" -> "World's Best", not "World'S Best")"""
    |                                                                                                     ^^^^^^^^^^^^^^^^
149 |     # First do regular title case
150 |     titled = s.title()
    |

PLC0415 `import` should be at the top-level of a file
   --> src\utils\scraping\scraping.py:154:5
    |
152 |     # Fix apostrophes - lowercase the letter after an apostrophe if it's not at the start of a word
153 |     # This handles cases like "World'S" -> "World's"
154 |     import re
    |     ^^^^^^^^^
155 |
156 |     titled = re.sub(r"'([A-Z])", lambda m: "'" + m.group(1).lower(), titled)
    |

E402 Module level import not at top of file
   --> src\utils\scraping\scraping.py:167:1
    |
167 | import hashlib
    | ^^^^^^^^^^^^^^
    |

N802 Function name `create_fileName` should be lowercase
   --> src\utils\scraping\scraping.py:170:5
    |
170 | def create_fileName(s):
    |     ^^^^^^^^^^^^^^^
171 |     base = re.sub(r"[^a-zA-Z0-9\s]", "", s)
172 |     base = re.sub(r"\s+", " ", base).strip().replace(" ", "-").lower()
    |

PLR2004 Magic value used in comparison, consider replacing `100` with a constant variable
   --> src\utils\scraping\scraping.py:174:20
    |
172 |     base = re.sub(r"\s+", " ", base).strip().replace(" ", "-").lower()
173 |
174 |     if len(base) > 100:
    |                    ^^^
175 |         hash_suffix = hashlib.md5(base.encode()).hexdigest()[:8]
176 |         base = base[:90] + "-" + hash_suffix
    |

PLR2004 Magic value used in comparison, consider replacing `100` with a constant variable
   --> src\utils\scraping\scraping.py:184:20
    |
182 |     base = re.sub(r"\s+", " ", base).strip().replace(" ", "-").lower()
183 |
184 |     if len(base) > 100:
    |                    ^^^
185 |         hash_suffix = hashlib.md5(base.encode()).hexdigest()[:8]
186 |         base = base[:90] + "-" + hash_suffix
    |

RUF059 Unpacked variable `stdout` is never used
  --> src\utils\setup_ollama.py:63:14
   |
61 |     print("ðŸ§ Installing Ollama on Linux...")
62 |
63 |     success, stdout, stderr = run_command(
   |              ^^^^^^
64 |         "curl -fsSL https://ollama.com/install.sh | sh", shell=True
65 |     )
   |
help: Prefix it with an underscore or any other dummy variable pattern

RUF059 Unpacked variable `stderr` is never used
   --> src\utils\setup_ollama.py:99:22
    |
 97 |     print("ðŸ” Checking Ollama installation...")
 98 |
 99 |     success, stdout, stderr = run_command(["ollama", "--version"])
    |                      ^^^^^^
100 |     if not success:
101 |         print("âŒ Ollama is not installed or not in PATH")
    |
help: Prefix it with an underscore or any other dummy variable pattern

PLC0415 `import` should be at the top-level of a file
   --> src\utils\setup_ollama.py:108:9
    |
106 |     # Check if Ollama is running
107 |     try:
108 |         import ollama
    |         ^^^^^^^^^^^^^
109 |
110 |         ollama.list()
    |

RUF059 Unpacked variable `stdout` is never used
   --> src\utils\setup_ollama.py:123:14
    |
121 |     print("ðŸ“¥ Pulling default model (llama3.2)...")
122 |
123 |     success, stdout, stderr = run_command(["ollama", "pull", "llama3.2"])
    |              ^^^^^^
124 |     if success:
125 |         print("âœ… Model llama3.2 downloaded successfully!")
    |
help: Prefix it with an underscore or any other dummy variable pattern

PLC0415 `import` should be at the top-level of a file
  --> tests\conftest.py:92:5
   |
90 | def memory_monitor():
91 |     """Fixture to monitor memory usage during tests."""
92 |     import os
   |     ^^^^^^^^^
93 |
94 |     import psutil
   |

PLC0415 `import` should be at the top-level of a file
  --> tests\conftest.py:94:5
   |
92 |     import os
93 |
94 |     import psutil
   |     ^^^^^^^^^^^^^
95 |
96 |     process = psutil.Process(os.getpid())
   |

PLC0415 `import` should be at the top-level of a file
   --> tests\conftest.py:112:5
    |
110 | def time_monitor():
111 |     """Fixture to monitor execution time."""
112 |     import time
    |     ^^^^^^^^^^^
113 |
114 |     class TimeMonitor:
    |

E402 Module level import not at top of file
  --> tests\e2e\test_scrapers.py:18:1
   |
16 |     sys.path.insert(0, str(PROJECT_ROOT))
17 |
18 | from src.scrapers.executor.workflow_executor import WorkflowExecutor
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 | from src.scrapers.parser.yaml_parser import ScraperConfigParser
20 | from tests.fixtures.scraper_validator import ScraperValidator
   |

E402 Module level import not at top of file
  --> tests\e2e\test_scrapers.py:19:1
   |
18 | from src.scrapers.executor.workflow_executor import WorkflowExecutor
19 | from src.scrapers.parser.yaml_parser import ScraperConfigParser
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20 | from tests.fixtures.scraper_validator import ScraperValidator
   |

E402 Module level import not at top of file
  --> tests\e2e\test_scrapers.py:20:1
   |
18 | from src.scrapers.executor.workflow_executor import WorkflowExecutor
19 | from src.scrapers.parser.yaml_parser import ScraperConfigParser
20 | from tests.fixtures.scraper_validator import ScraperValidator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

E501 Line too long (105 > 100)
  --> tests\e2e\test_scrapers.py:75:101
   |
74 |         print(
75 |             f"DEBUG: Starting scraper execution for {scraper_name} with SKUs {skus}, headless={headless}"
   |                                                                                                     ^^^^^
76 |         )
   |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:105:21
    |
103 |                 try:
104 |                     # Clone config and replace {sku} placeholders
105 |                     import copy
    |                     ^^^^^^^^^^^
106 |
107 |                     sku_config = copy.deepcopy(config)
    |

E501 Line too long (125 > 100)
   --> tests\e2e\test_scrapers.py:117:101
    |
115 |                     workflow_result = executor.execute_workflow()
116 |                     print(
117 |                         f"DEBUG: Workflow execution completed for SKU {sku}, success={workflow_result.get('success', False)}"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
118 |                     )
    |

E501 Line too long (104 > 100)
   --> tests\e2e\test_scrapers.py:136:101
    |
134 |             results["execution_time"] = time.time() - start_time
135 |             print(
136 |                 f"DEBUG: Scraper {scraper_name} execution completed in {results['execution_time']:.2f}s"
    |                                                                                                     ^^^^
137 |             )
    |

E501 Line too long (116 > 100)
   --> tests\e2e\test_scrapers.py:226:101
    |
224 |             if skipped_count > 0:
225 |                 print(
226 |                     f"SKIP: Skipping {skipped_count} login-requiring scrapers: {', '.join(login_required_scrapers)}"
    |                                                                                                     ^^^^^^^^^^^^^^^^
227 |                 )
    |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
   --> tests\e2e\test_scrapers.py:320:52
    |
318 |                 print("   Field Coverage:")
319 |                 for field, coverage in field_coverage.items():
320 |                     status = "PASS" if coverage == 100.0 else "WARN" if coverage > 0 else "FAIL"
    |                                                    ^^^^^
321 |                     print(f"     {status} {field}: {coverage:.1f}%")
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:431:9
    |
429 |         """Test running individual scrapers with parametrization."""
430 |         # Skip login-requiring scrapers in CI
431 |         import os
    |         ^^^^^^^^^
432 |
433 |         if os.getenv("CI") == "true" and scraper_name in {"orgill", "petfoodex", "phillips"}:
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:449:9
    |
447 |         """Test running a single scraper with timeout handling."""
448 |         print("DEBUG: Starting test_single_scraper_with_timeout")
449 |         import threading
    |         ^^^^^^^^^^^^^^^^
450 |         from typing import Any
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:450:9
    |
448 |         print("DEBUG: Starting test_single_scraper_with_timeout")
449 |         import threading
450 |         from typing import Any
    |         ^^^^^^^^^^^^^^^^^^^^^^
451 |
452 |         result: dict[str, Any] = {"completed": False, "data": None, "error": None}
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:491:9
    |
489 |         print("DEBUG: Starting test_all_scrapers_integration")
490 |         # For CI/CD, skip login-requiring scrapers; locally, test all
491 |         import os
    |         ^^^^^^^^^
492 |
493 |         skip_login = os.getenv("CI") == "true"  # Skip in CI environment
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:496:9
    |
494 |         print(f"DEBUG: skip_login_required={skip_login}")
495 |
496 |         import threading
    |         ^^^^^^^^^^^^^^^^
497 |         from typing import Any
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:497:9
    |
496 |         import threading
497 |         from typing import Any
    |         ^^^^^^^^^^^^^^^^^^^^^^
498 |
499 |         result: dict[str, Any] = {"completed": False, "data": None, "error": None}
    |

E501 Line too long (112 > 100)
   --> tests\e2e\test_scrapers.py:535:101
    |
533 |             # Print summary
534 |             print(
535 |                 f"Integration test results: {results['successful_scrapers']}/{results['total_scrapers']} passed"
    |                                                                                                     ^^^^^^^^^^^^
536 |             )
537 |             print("DEBUG: test_all_scrapers_integration completed successfully")
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:545:9
    |
543 |         print(f"DEBUG: Starting test_scraper_headless_modes with headless={headless}")
544 |         # Only test amazon for mode testing
545 |         import os
    |         ^^^^^^^^^
546 |
547 |         if not headless and os.getenv("CI") == "true":
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:551:9
    |
549 |             pytest.skip("Skipping non-headless test in CI environment")
550 |
551 |         import threading
    |         ^^^^^^^^^^^^^^^^
552 |         from typing import Any
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:552:9
    |
551 |         import threading
552 |         from typing import Any
    |         ^^^^^^^^^^^^^^^^^^^^^^
553 |
554 |         result: dict[str, Any] = {"completed": False, "data": None, "error": None}
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:667:9
    |
665 |     def test_no_results_integration_with_config_validation(self, tester):
666 |         """Test integration with scraper configuration validation sections for no results."""
667 |         from src.scrapers.parser.yaml_parser import ScraperConfigParser
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
668 |
669 |         # Test with amazon config which has no_results validation
    |

E501 Line too long (108 > 100)
   --> tests\e2e\test_scrapers.py:675:101
    |
673 |         )
674 |
675 |         # Verify config has validation section (may be stored as extra field due to arbitrary_types_allowed)
    |                                                                                                     ^^^^^^^^
676 |         assert hasattr(config, "validation") or hasattr(config, "__dict__")
677 |         validation_data = getattr(config, "validation", None) or config.__dict__.get("validation")
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\e2e\test_scrapers.py:696:13
    |
694 |         else:
695 |             # If validation section is not loaded, at least verify the YAML file contains it
696 |             import yaml
    |             ^^^^^^^^^^^
697 |
698 |             with open(tester.project_root / "src" / "scrapers" / "configs" / "amazon.yaml") as f:
    |

RUF013 PEP 484 prohibits implicit `Optional`
  --> tests\fixtures\scraper_validator.py:14:40
   |
12 |     """Validates scraper output data format and content."""
13 |
14 |     def __init__(self, test_data_path: str = None):
   |                                        ^^^
15 |         """Initialize validator with test data configuration."""
16 |         # Define common validation rules internally
   |
help: Convert to `T | None`

PLR0912 Too many branches (16 > 12)
  --> tests\fixtures\scraper_validator.py:37:9
   |
35 |         }
36 |
37 |     def validate_product_data(self, products: list[dict], scraper_name: str) -> dict[str, Any]:
   |         ^^^^^^^^^^^^^^^^^^^^^
38 |         """
39 |         Validate a list of product dictionaries from a scraper.
   |

PLR2004 Magic value used in comparison, consider replacing `50` with a constant variable
   --> tests\fixtures\scraper_validator.py:195:37
    |
193 |         sku_str = str(sku).strip()
194 |         # Basic SKU validation - not empty and reasonable length
195 |         return 1 <= len(sku_str) <= 50
    |                                     ^^
196 |
197 |     def _validate_price(self, price: Any) -> bool:
    |

PLR2004 Magic value used in comparison, consider replacing `0.01` with a constant variable
   --> tests\fixtures\scraper_validator.py:244:16
    |
242 |         weight_value = float(weight_match.group(1))
243 |         # Reasonable weight range for pet products
244 |         return 0.01 <= weight_value <= 1000.0
    |                ^^^^
245 |
246 |     def print_validation_report(self, results: dict[str, Any]) -> None:
    |

PLR2004 Magic value used in comparison, consider replacing `1000.0` with a constant variable
   --> tests\fixtures\scraper_validator.py:244:40
    |
242 |         weight_value = float(weight_match.group(1))
243 |         # Reasonable weight range for pet products
244 |         return 0.01 <= weight_value <= 1000.0
    |                                        ^^^^^^
245 |
246 |     def print_validation_report(self, results: dict[str, Any]) -> None:
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> tests\fixtures\scraper_validator.py:269:41
    |
267 |             for error in results["errors"][:10]:  # Show first 10 errors
268 |                 print(f"  â€¢ {error}")
269 |             if len(results["errors"]) > 10:
    |                                         ^^
270 |                 print(f"  ... and {len(results['errors']) - 10} more errors")
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> tests\fixtures\scraper_validator.py:276:43
    |
274 |             for warning in results["warnings"][:10]:  # Show first 10 warnings
275 |                 print(f"  â€¢ {warning}")
276 |             if len(results["warnings"]) > 10:
    |                                           ^^
277 |                 print(f"  ... and {len(results['warnings']) - 10} more warnings")
    |

E402 Module level import not at top of file
  --> tests\integration\classification_e2e.py:9:1
   |
 7 |     sys.path.insert(0, PROJECT_ROOT)
 8 |
 9 | from src.core.classification.manager import classify_products_batch
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
10 | from src.core.classification.ui import edit_classification_in_batch
   |

E402 Module level import not at top of file
  --> tests\integration\classification_e2e.py:10:1
   |
 9 | from src.core.classification.manager import classify_products_batch
10 | from src.core.classification.ui import edit_classification_in_batch
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

E402 Module level import not at top of file
  --> tests\integration\test_data_quality.py:9:1
   |
 7 |     sys.path.insert(0, str(PROJECT_ROOT))
 8 |
 9 | from src.core.data_quality_scorer import DataQualityScorer, is_product_high_quality
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
10 | from src.scrapers.parser.yaml_parser import ScraperConfigParser
   |

E402 Module level import not at top of file
  --> tests\integration\test_data_quality.py:10:1
   |
 9 | from src.core.data_quality_scorer import DataQualityScorer, is_product_high_quality
10 | from src.scrapers.parser.yaml_parser import ScraperConfigParser
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

RUF059 Unpacked variable `score` is never used
  --> tests\integration\test_data_quality.py:59:13
   |
57 |                 "Product_Field_25": "Test Product Type",
58 |             }
59 |             score, _ = scorer.score_record(record)
   |             ^^^^^
60 |             total_records += 1
61 |             if is_product_high_quality(record):
   |
help: Prefix it with an underscore or any other dummy variable pattern

E501 Line too long (116 > 100)
  --> tests\integration\test_data_quality.py:66:101
   |
64 |     quality_rate = high_quality_records / total_records if total_records > 0 else 0
65 |     print(
66 |         f"Quality validation: {high_quality_records}/{total_records} records pass quality gate ({quality_rate:.1%})"
   |                                                                                                     ^^^^^^^^^^^^^^^^
67 |     )
   |

PLR2004 Magic value used in comparison, consider replacing `0.6` with a constant variable
  --> tests\integration\test_data_quality.py:70:28
   |
69 |     # Quality gate: at least 60% of test records should pass (allowing for incomplete mock data)
70 |     assert quality_rate >= 0.6, (
   |                            ^^^
71 |         f"Quality gate failed: only {quality_rate:.1%} records pass validation"
72 |     )
   |

PLR0913 Too many arguments in function definition (6 > 5)
  --> tests\integration\test_local_llm_integration.py:60:9
   |
58 |     @patch("src.core.classification.local_llm_classifier.LocalLLMProductClassifier._load_cache")
59 |     @patch("src.core.classification.local_llm_classifier.LocalLLMProductClassifier._save_cache")
60 |     def test_local_llm_method_integration(
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
61 |         self,
62 |         mock_save_cache,
   |

PLR0913 Too many arguments in function definition (6 > 5)
  --> tests\integration\test_local_llm_integration.py:94:9
   |
92 |     @patch("src.core.classification.local_llm_classifier.LocalLLMProductClassifier._load_cache")
93 |     @patch("src.core.classification.local_llm_classifier.LocalLLMProductClassifier._save_cache")
94 |     def test_batch_classification_integration(
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
95 |         self,
96 |         mock_save_cache,
   |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\integration\test_local_llm_integration.py:142:32
    |
140 |         results = classify_products_batch(sample_products, method="local_llm")
141 |
142 |         assert len(results) == 2
    |                                ^
143 |         assert results[0]["Category"] == "Dog Food"
144 |         assert results[1]["Category"] == "Cat Supplies"
    |

PLR0913 Too many arguments in function definition (6 > 5)
   --> tests\integration\test_local_llm_integration.py:150:9
    |
148 |     @patch("src.core.classification.local_llm_classifier.LocalLLMProductClassifier._load_cache")
149 |     @patch("src.core.classification.local_llm_classifier.LocalLLMProductClassifier._save_cache")
150 |     def test_caching_integration(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
151 |         self,
152 |         mock_save_cache,
    |

PLR2004 Magic value used in comparison, consider replacing `10` with a constant variable
   --> tests\integration\test_local_llm_integration.py:299:32
    |
298 |         results = classify_products_batch(large_batch, method="local_llm")
299 |         assert len(results) == 10
    |                                ^^
300 |
301 |     @patch("ollama.list")
    |

PLR0913 Too many arguments in function definition (7 > 5)
  --> tests\integration\test_scraper_validation.py:22:9
   |
20 |         ],
21 |     )
22 |     def test_record_quality_validation_parametrized(
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
23 |         self,
24 |         data_quality_scorer,
   |

RUF059 Unpacked variable `details` is never used
  --> tests\integration\test_scraper_validation.py:41:16
   |
39 |             record = sample_low_quality_record
40 |
41 |         score, details = data_quality_scorer.score_record(record)
   |                ^^^^^^^
42 |
43 |         assert score >= expected_score_min, (
   |
help: Prefix it with an underscore or any other dummy variable pattern

PLR2004 Magic value used in comparison, consider replacing `85.0` with a constant variable
  --> tests\integration\test_scraper_validation.py:54:25
   |
52 |         score, details = data_quality_scorer.score_record(sample_high_quality_record)
53 |
54 |         assert score >= 85.0, f"High-quality record scored too low: {score}"
   |                         ^^^^
55 |         assert is_product_high_quality(sample_high_quality_record), (
56 |             "High-quality record not recognized"
   |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
  --> tests\integration\test_scraper_validation.py:60:52
   |
59 |         # Check all components are high
60 |         assert details["completeness"]["score"] == 100.0
   |                                                    ^^^^^
61 |         assert details["accuracy"]["score"] >= 80.0
62 |         assert details["consistency"]["score"] == 100.0
   |

PLR2004 Magic value used in comparison, consider replacing `80.0` with a constant variable
  --> tests\integration\test_scraper_validation.py:61:48
   |
59 |         # Check all components are high
60 |         assert details["completeness"]["score"] == 100.0
61 |         assert details["accuracy"]["score"] >= 80.0
   |                                                ^^^^
62 |         assert details["consistency"]["score"] == 100.0
   |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
  --> tests\integration\test_scraper_validation.py:62:51
   |
60 |         assert details["completeness"]["score"] == 100.0
61 |         assert details["accuracy"]["score"] >= 80.0
62 |         assert details["consistency"]["score"] == 100.0
   |                                                   ^^^^^
63 |
64 |     def test_low_quality_record_validation(self, data_quality_scorer, sample_low_quality_record):
   |

RUF059 Unpacked variable `details` is never used
  --> tests\integration\test_scraper_validation.py:66:16
   |
64 |     def test_low_quality_record_validation(self, data_quality_scorer, sample_low_quality_record):
65 |         """Test that low-quality records fail validation."""
66 |         score, details = data_quality_scorer.score_record(sample_low_quality_record)
   |                ^^^^^^^
67 |
68 |         assert score < 85.0, f"Low-quality record scored too high: {score}"
   |
help: Prefix it with an underscore or any other dummy variable pattern

PLR2004 Magic value used in comparison, consider replacing `85.0` with a constant variable
  --> tests\integration\test_scraper_validation.py:68:24
   |
66 |         score, details = data_quality_scorer.score_record(sample_low_quality_record)
67 |
68 |         assert score < 85.0, f"Low-quality record scored too high: {score}"
   |                        ^^^^
69 |         assert not is_product_high_quality(sample_low_quality_record), (
70 |             "Low-quality record incorrectly recognized as high quality"
   |

RUF059 Unpacked variable `details` is never used
  --> tests\integration\test_scraper_validation.py:79:20
   |
77 |         results = []
78 |         for record in sample_mixed_quality_records:
79 |             score, details = data_quality_scorer.score_record(record)
   |                    ^^^^^^^
80 |             results.append((score, is_product_high_quality(record)))
   |
help: Prefix it with an underscore or any other dummy variable pattern

RUF059 Unpacked variable `score` is never used
  --> tests\integration\test_scraper_validation.py:97:13
   |
95 |         for weight_str, expected_lb in test_cases:
96 |             record = {"Weight": weight_str}
97 |             score, details = data_quality_scorer._score_accuracy(record)
   |             ^^^^^
98 |             assert details["weight"]["normalized"] == f"{expected_lb:.2f} lb"
   |
help: Prefix it with an underscore or any other dummy variable pattern

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\integration\test_scraper_validation.py:107:51
    |
105 |         }
106 |         score, details = data_quality_scorer._score_accuracy(record)
107 |         assert details["images"]["valid_urls"] == 3
    |                                                   ^
108 |         assert details["images"]["percentage"] == 100.0
    |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
   --> tests\integration\test_scraper_validation.py:108:51
    |
106 |         score, details = data_quality_scorer._score_accuracy(record)
107 |         assert details["images"]["valid_urls"] == 3
108 |         assert details["images"]["percentage"] == 100.0
    |                                                   ^^^^^
109 |
110 |         # Mixed valid/invalid
    |

RUF059 Unpacked variable `score` is never used
   --> tests\integration\test_scraper_validation.py:112:9
    |
110 |         # Mixed valid/invalid
111 |         record = {"Images": "https://valid.com/img.jpg,invalid-url,ftp://invalid.com/img.jpg"}
112 |         score, details = data_quality_scorer._score_accuracy(record)
    |         ^^^^^
113 |         assert details["images"]["valid_urls"] == 1
114 |         assert details["images"]["percentage"] == pytest.approx(
    |
help: Prefix it with an underscore or any other dummy variable pattern

PLR2004 Magic value used in comparison, consider replacing `85.0` with a constant variable
   --> tests\integration\test_scraper_validation.py:136:25
    |
134 |             score, _ = data_quality_scorer.score_record(record)
135 |             total_score += score
136 |             if score >= 85.0:
    |                         ^^^^
137 |                 high_quality_count += 1
    |

PLR2004 Magic value used in comparison, consider replacing `300.0` with a constant variable
   --> tests\integration\test_scraper_validation.py:143:34
    |
142 |         # Performance assertions
143 |         assert elapsed_seconds < 300.0, f"Processing took too long: {elapsed_seconds}s (>5 min)"
    |                                  ^^^^^
144 |         assert memory_delta_mb < 500.0, f"Memory usage too high: {memory_delta_mb}MB (>500MB)"
    |

PLR2004 Magic value used in comparison, consider replacing `500.0` with a constant variable
   --> tests\integration\test_scraper_validation.py:144:34
    |
142 |         # Performance assertions
143 |         assert elapsed_seconds < 300.0, f"Processing took too long: {elapsed_seconds}s (>5 min)"
144 |         assert memory_delta_mb < 500.0, f"Memory usage too high: {memory_delta_mb}MB (>500MB)"
    |                                  ^^^^^
145 |
146 |         # Quality assertions
    |

PLR2004 Magic value used in comparison, consider replacing `85.0` with a constant variable
   --> tests\integration\test_scraper_validation.py:148:29
    |
146 |         # Quality assertions
147 |         avg_score = total_score / len(performance_test_data)
148 |         assert avg_score >= 85.0, f"Average score too low: {avg_score}"
    |                             ^^^^
149 |         assert high_quality_count == len(performance_test_data), (
150 |             "Not all records recognized as high quality"
    |

E501 Line too long (101 > 100)
   --> tests\integration\test_scraper_validation.py:154:101
    |
153 |         print(
154 |             f"Performance test results: {elapsed_seconds:.2f}s, {memory_delta_mb:.2f}MB memory delta"
    |                                                                                                     ^
155 |         )
    |

PLR2004 Magic value used in comparison, consider replacing `10.0` with a constant variable
   --> tests\integration\test_scraper_validation.py:172:30
    |
171 |         # Should be very fast (< 10ms average)
172 |         assert avg_time_ms < 10.0, f"Average scoring time too slow: {avg_time_ms}ms"
    |                              ^^^^
173 |         assert max_time_ms < 50.0, f"Max scoring time too slow: {max_time_ms}ms"
    |

PLR2004 Magic value used in comparison, consider replacing `50.0` with a constant variable
   --> tests\integration\test_scraper_validation.py:173:30
    |
171 |         # Should be very fast (< 10ms average)
172 |         assert avg_time_ms < 10.0, f"Average scoring time too slow: {avg_time_ms}ms"
173 |         assert max_time_ms < 50.0, f"Max scoring time too slow: {max_time_ms}ms"
    |                              ^^^^
174 |
175 |         print(
    |

E402 Module level import not at top of file
  --> tests\unit\test_classification.py:13:1
   |
12 |   # Import classification module
13 | / from src.core.classification.ui import (
14 | |     assign_classification_batch,
15 | |     assign_classification_single,
16 | |     clear_facet_cache,
17 | |     edit_classification_in_batch,
18 | |     get_facet_options_from_db,
19 | | )
   | |_^
   |

E402 Module level import not at top of file
  --> tests\unit\test_config_models.py:10:1
   |
 8 | sys.path.insert(0, PROJECT_ROOT)
 9 |
10 | from src.scrapers.models.config import LoginConfig, ScraperConfig, SelectorConfig, WorkflowStep
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLR2004 Magic value used in comparison, consider replacing `30` with a constant variable
   --> tests\unit\test_config_models.py:247:34
    |
245 |         assert config.name == "Test Scraper"
246 |         assert config.base_url == "https://example.com"
247 |         assert config.timeout == 30
    |                                  ^^
248 |         assert config.retries == 3
249 |         assert config.selectors == []
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_config_models.py:248:34
    |
246 |         assert config.base_url == "https://example.com"
247 |         assert config.timeout == 30
248 |         assert config.retries == 3
    |                                  ^
249 |         assert config.selectors == []
250 |         assert config.workflows == []
    |

PLR2004 Magic value used in comparison, consider replacing `60` with a constant variable
   --> tests\unit\test_config_models.py:286:34
    |
285 |         assert config.name == "Full Test Scraper"
286 |         assert config.timeout == 60
    |                                  ^^
287 |         assert config.retries == 5
288 |         assert len(config.selectors) == 2
    |

PLR2004 Magic value used in comparison, consider replacing `5` with a constant variable
   --> tests\unit\test_config_models.py:287:34
    |
285 |         assert config.name == "Full Test Scraper"
286 |         assert config.timeout == 60
287 |         assert config.retries == 5
    |                                  ^
288 |         assert len(config.selectors) == 2
289 |         assert len(config.workflows) == 2
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_config_models.py:288:41
    |
286 |         assert config.timeout == 60
287 |         assert config.retries == 5
288 |         assert len(config.selectors) == 2
    |                                         ^
289 |         assert len(config.workflows) == 2
290 |         assert config.login is not None
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_config_models.py:289:41
    |
287 |         assert config.retries == 5
288 |         assert len(config.selectors) == 2
289 |         assert len(config.workflows) == 2
    |                                         ^
290 |         assert config.login is not None
291 |         assert config.test_skus == test_skus
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_config_models.py:314:41
    |
312 |         )
313 |
314 |         assert len(config.selectors) == 2
    |                                         ^
315 |         assert len(config.workflows) == 3
316 |         assert config.selectors[0].name == "product_name"
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_config_models.py:315:41
    |
314 |         assert len(config.selectors) == 2
315 |         assert len(config.workflows) == 3
    |                                         ^
316 |         assert config.selectors[0].name == "product_name"
317 |         assert config.workflows[0].action == "navigate"
    |

PLR2004 Magic value used in comparison, consider replacing `45` with a constant variable
   --> tests\unit\test_config_models.py:347:35
    |
345 |         assert data["name"] == "Test Scraper"
346 |         assert data["base_url"] == "https://example.com"
347 |         assert data["timeout"] == 45
    |                                   ^^
348 |         assert data["retries"] == 2
349 |         assert len(data["selectors"]) == 1
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_config_models.py:348:35
    |
346 |         assert data["base_url"] == "https://example.com"
347 |         assert data["timeout"] == 45
348 |         assert data["retries"] == 2
    |                                   ^
349 |         assert len(data["selectors"]) == 1
350 |         assert len(data["workflows"]) == 1
    |

PLR2004 Magic value used in comparison, consider replacing `45` with a constant variable
   --> tests\unit\test_config_models.py:368:34
    |
367 |         assert config.name == "Test Scraper"
368 |         assert config.timeout == 45
    |                                  ^^
369 |         assert len(config.selectors) == 1
370 |         assert len(config.workflows) == 1
    |

B017 Do not assert blind exception: `Exception`
   --> tests\unit\test_config_models.py:376:14
    |
374 |         """Test that required fields are validated."""
375 |         # Missing name
376 |         with pytest.raises(Exception):
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
377 |             ScraperConfig(base_url="https://example.com")
    |

B017 Do not assert blind exception: `Exception`
   --> tests\unit\test_config_models.py:380:14
    |
379 |         # Missing base_url
380 |         with pytest.raises(Exception):
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
381 |             ScraperConfig(name="Test Scraper")
    |

B017 Do not assert blind exception: `Exception`
   --> tests\unit\test_config_models.py:386:14
    |
384 |         """Test field type validation."""
385 |         # Invalid timeout type
386 |         with pytest.raises(Exception):
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
387 |             ScraperConfig(name="Test", base_url="https://example.com", timeout="not_a_number")
    |

B017 Do not assert blind exception: `Exception`
   --> tests\unit\test_config_models.py:390:14
    |
389 |         # Invalid retries type
390 |         with pytest.raises(Exception):
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
391 |             ScraperConfig(name="Test", base_url="https://example.com", retries="not_a_number")
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_config_models.py:403:41
    |
401 |         config = ScraperConfig(name="Test", base_url="https://example.com", selectors=selectors)
402 |
403 |         assert len(config.selectors) == 2
    |                                         ^
404 |
405 |     def test_workflows_validation(self):
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_config_models.py:415:41
    |
413 |         config = ScraperConfig(name="Test", base_url="https://example.com", workflows=workflows)
414 |
415 |         assert len(config.workflows) == 3
    |                                         ^
416 |
417 |     def test_login_config_validation(self):
    |

E402 Module level import not at top of file
  --> tests\unit\test_core_logic.py:11:1
   |
 9 | sys.path.insert(0, PROJECT_ROOT)
10 |
11 | from src.scrapers.main import run_db_refresh
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
12 |
13 | # --- Test Fixtures ---
   |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
  --> tests\unit\test_core_logic.py:74:49
   |
72 |     mock_db_refresh_func.assert_called_once()
73 |     log_callback.emit.assert_any_call("ðŸ’¡ Database updated successfully.")
74 |     assert progress_callback.emit.call_count == 3  # 10, 30, 90
   |                                                 ^
   |

PLR2004 Magic value used in comparison, consider replacing `100` with a constant variable
  --> tests\unit\test_data_quality_scorer.py:55:30
   |
54 |         assert isinstance(score, float)
55 |         assert 0 <= score <= 100
   |                              ^^^
56 |         assert score >= 85  # Should be high quality
57 |         assert "completeness" in details
   |

PLR2004 Magic value used in comparison, consider replacing `85` with a constant variable
  --> tests\unit\test_data_quality_scorer.py:56:25
   |
54 |         assert isinstance(score, float)
55 |         assert 0 <= score <= 100
56 |         assert score >= 85  # Should be high quality
   |                         ^^
57 |         assert "completeness" in details
58 |         assert "accuracy" in details
   |

RUF059 Unpacked variable `details` is never used
  --> tests\unit\test_data_quality_scorer.py:64:16
   |
62 |     def test_score_record_invalid(self, scorer, invalid_record):
63 |         """Test scoring an invalid record."""
64 |         score, details = scorer.score_record(invalid_record)
   |                ^^^^^^^
65 |
66 |         assert isinstance(score, float)
   |
help: Prefix it with an underscore or any other dummy variable pattern

PLR2004 Magic value used in comparison, consider replacing `100` with a constant variable
  --> tests\unit\test_data_quality_scorer.py:67:30
   |
66 |         assert isinstance(score, float)
67 |         assert 0 <= score <= 100
   |                              ^^^
68 |         assert score < 85  # Should be low quality
   |

PLR2004 Magic value used in comparison, consider replacing `85` with a constant variable
  --> tests\unit\test_data_quality_scorer.py:68:24
   |
66 |         assert isinstance(score, float)
67 |         assert 0 <= score <= 100
68 |         assert score < 85  # Should be low quality
   |                        ^^
69 |
70 |     def test_completeness_scoring(self, scorer, valid_record, invalid_record):
   |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
  --> tests\unit\test_data_quality_scorer.py:75:58
   |
73 |         _, invalid_details = scorer.score_record(invalid_record)
74 |
75 |         assert valid_details["completeness"]["score"] == 100.0
   |                                                          ^^^^^
76 |         assert invalid_details["completeness"]["score"] == 0.0
   |

RUF059 Unpacked variable `score` is never used
  --> tests\unit\test_data_quality_scorer.py:87:9
   |
85 |         # Test image URLs
86 |         record = {"Images": "https://valid.com/img.jpg,invalid-url"}
87 |         score, details = scorer._score_accuracy(record)
   |         ^^^^^
88 |         assert details["images"]["valid_urls"] == 1
89 |         assert details["images"]["total_urls"] == 2
   |
help: Prefix it with an underscore or any other dummy variable pattern

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
  --> tests\unit\test_data_quality_scorer.py:89:51
   |
87 |         score, details = scorer._score_accuracy(record)
88 |         assert details["images"]["valid_urls"] == 1
89 |         assert details["images"]["total_urls"] == 2
   |                                                   ^
90 |
91 |     def test_consistency_scoring(self, scorer):
   |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
   --> tests\unit\test_data_quality_scorer.py:102:25
    |
100 |         }
101 |         score, details = scorer._score_consistency(record)
102 |         assert score == 100.0
    |                         ^^^^^
103 |
104 |         # Invalid formats
    |

RUF059 Unpacked variable `details` is never used
   --> tests\unit\test_data_quality_scorer.py:112:16
    |
110 |             "Product_Field_25": None,
111 |         }
112 |         score, details = scorer._score_consistency(record)
    |                ^^^^^^^
113 |         assert score == 0.0
    |
help: Prefix it with an underscore or any other dummy variable pattern

PLR2004 Magic value used in comparison, consider replacing `5.0` with a constant variable
   --> tests\unit\test_data_quality_scorer.py:123:58
    |
121 |     def test_weight_normalization(self, scorer):
122 |         """Test weight normalization to LB."""
123 |         assert scorer._normalize_weight_to_lb("5 lb") == 5.0
    |                                                          ^^^
124 |         assert scorer._normalize_weight_to_lb("16 oz") == 1.0
125 |         assert scorer._normalize_weight_to_lb("2.2 kg") == pytest.approx(4.8508, rel=1e-3)
    |

PLR2004 Magic value used in comparison, consider replacing `2.20462` with a constant variable
   --> tests\unit\test_data_quality_scorer.py:126:60
    |
124 |         assert scorer._normalize_weight_to_lb("16 oz") == 1.0
125 |         assert scorer._normalize_weight_to_lb("2.2 kg") == pytest.approx(4.8508, rel=1e-3)
126 |         assert scorer._normalize_weight_to_lb("1000 g") == 2.20462
    |                                                            ^^^^^^^
127 |         assert scorer._normalize_weight_to_lb("invalid") is None
128 |         assert scorer._normalize_weight_to_lb("") is None
    |

PLR2004 Magic value used in comparison, consider replacing `100` with a constant variable
   --> tests\unit\test_data_quality_scorer.py:141:25
    |
139 |         """Test price parsing."""
140 |         score, details = scorer._score_price_accuracy("$29.99")
141 |         assert score == 100
    |                         ^^^
142 |         assert details["value"] == 29.99
    |

PLR2004 Magic value used in comparison, consider replacing `29.99` with a constant variable
   --> tests\unit\test_data_quality_scorer.py:142:36
    |
140 |         score, details = scorer._score_price_accuracy("$29.99")
141 |         assert score == 100
142 |         assert details["value"] == 29.99
    |                                    ^^^^^
143 |
144 |         score, details = scorer._score_price_accuracy("invalid price")
    |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
  --> tests\unit\test_failure_classifier.py:43:37
   |
42 |         assert result.failure_type == FailureType.NO_RESULTS
43 |         assert result.confidence == 0.8  # High confidence for selector match
   |                                     ^^^
44 |         assert result.recovery_strategy == "fail_and_continue_to_next_sku"
   |

E501 Line too long (140 > 100)
  --> tests\unit\test_failure_classifier.py:49:101
   |
47 | â€¦rns."""
48 | â€¦o exceed 0.3 confidence threshold
49 | â€¦lts found. Your search returned no results. No matching products found.</body></html>"
   |                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
50 | â€¦
   |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
  --> tests\unit\test_failure_classifier.py:55:36
   |
54 |         assert result.failure_type == FailureType.NO_RESULTS
55 |         assert result.confidence > 0.3  # Should exceed threshold with multiple matches
   |                                    ^^^
56 |         assert result.details["text_match"] is True
   |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
  --> tests\unit\test_failure_classifier.py:68:34
   |
66 |         assert result.failure_type == FailureType.NO_RESULTS
67 |         assert (
68 |             result.confidence >= 0.5
   |                                  ^^^
69 |         )  # Title match with reduced weight but multiple patterns, and now better classification
70 |         assert result.details["title_match"] is True
   |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
  --> tests\unit\test_failure_classifier.py:87:37
   |
86 |         assert result.failure_type == FailureType.NO_RESULTS
87 |         assert result.confidence >= 0.8  # High confidence from multiple matches
   |                                     ^^^
88 |
89 |     def test_no_results_partial_text_match(self, classifier, mock_driver):
   |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
  --> tests\unit\test_failure_classifier.py:98:34
   |
96 |         assert result.failure_type == FailureType.NO_RESULTS
97 |         assert (
98 |             result.confidence >= 0.5
   |                                  ^^^
99 |         )  # Should exceed threshold with multiple matches and now better classification
   |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
   --> tests\unit\test_failure_classifier.py:109:37
    |
107 |         result = classifier.classify_page_content(mock_driver, {})
108 |         assert result.failure_type == FailureType.NO_RESULTS
109 |         assert result.confidence >= 0.5  # Should exceed threshold and now better classification
    |                                     ^^^
110 |
111 |     def test_no_results_false_positive_avoidance(self, classifier, mock_driver):
    |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> tests\unit\test_failure_classifier.py:119:85
    |
118 |         # Should not classify as NO_RESULTS due to low confidence
119 |         assert result.failure_type != FailureType.NO_RESULTS or result.confidence < 0.3
    |                                                                                     ^^^
120 |
121 |     def test_no_results_vs_other_failure_types(self, classifier, mock_driver):
    |

E501 Line too long (124 > 100)
   --> tests\unit\test_failure_classifier.py:124:101
    |
122 |         """Test differentiation between NO_RESULTS and other failure types."""
123 |         # Test CAPTCHA content that should clearly match CAPTCHA patterns
124 |         mock_driver.page_source = "<html><body>Please verify you are human. Complete the captcha to continue.</body></html>"
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^
125 |
126 |         result = classifier.classify_page_content(mock_driver, {})
    |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> tests\unit\test_failure_classifier.py:149:36
    |
148 |         # Should not classify as NO_RESULTS with high confidence
149 |         assert result.confidence < 0.3
    |                                    ^^^
150 |
151 |     def test_no_results_selector_exception_handling(self, classifier, mock_driver):
    |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
   --> tests\unit\test_failure_classifier.py:164:34
    |
162 |         assert result.failure_type == FailureType.NO_RESULTS
163 |         assert (
164 |             result.confidence >= 0.5
    |                                  ^^^
165 |         )  # Should still work via text patterns despite selector exception, with better confidence
    |

PLR2004 Magic value used in comparison, consider replacing `0.7` with a constant variable
   --> tests\unit\test_failure_classifier.py:177:30
    |
175 |         # Test single match
176 |         confidence = classifier._calculate_text_match_confidence("no results found", patterns)
177 |         assert confidence == 0.7  # Fixed confidence for any match
    |                              ^^^
178 |
179 |         # Test multiple matches still returns the fixed confidence
    |

PLR2004 Magic value used in comparison, consider replacing `0.7` with a constant variable
   --> tests\unit\test_failure_classifier.py:183:30
    |
181 |             "no results found - your search returned no results", patterns
182 |         )
183 |         assert confidence == 0.7  # Should still be the fixed confidence
    |                              ^^^
184 |
185 |         # Test no matches
    |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
   --> tests\unit\test_failure_classifier.py:214:37
    |
213 |         assert result.failure_type == FailureType.NO_RESULTS
214 |         assert result.confidence >= 0.8  # High confidence from multiple indicators and new logic
    |                                     ^^^
215 |         assert result.details["selector_match"] is True
216 |         assert result.details["text_match"] is True
    |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> tests\unit\test_failure_classifier.py:228:36
    |
227 |         # Should not classify as NO_RESULTS with high confidence
228 |         assert result.confidence < 0.3
    |                                    ^^^
229 |
230 |     def test_no_results_edge_case_similar_text(self, classifier, mock_driver):
    |

E501 Line too long (103 > 100)
   --> tests\unit\test_failure_classifier.py:231:101
    |
230 |     def test_no_results_edge_case_similar_text(self, classifier, mock_driver):
231 |         """Test edge case with text that contains NO_RESULTS keywords but isn't actually no results."""
    |                                                                                                     ^^^
232 |         mock_driver.page_source = """
233 |         <html><body>
    |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
   --> tests\unit\test_failure_classifier.py:243:36
    |
242 |         # Should have low confidence due to partial matches not forming complete patterns
243 |         assert result.confidence < 0.5
    |                                    ^^^
244 |
245 |     def test_no_results_with_status_code_context(self, classifier, mock_driver):
    |

PLR2004 Magic value used in comparison, consider replacing `0.95` with a constant variable
   --> tests\unit\test_failure_classifier.py:257:37
    |
255 |         # 404 status code gives very high confidence to PAGE_NOT_FOUND
256 |         assert result.failure_type == FailureType.PAGE_NOT_FOUND
257 |         assert result.confidence == 0.95
    |                                     ^^^^
258 |         assert result.details["status_code_match"] == 404
    |

PLR2004 Magic value used in comparison, consider replacing `404` with a constant variable
   --> tests\unit\test_failure_classifier.py:258:55
    |
256 |         assert result.failure_type == FailureType.PAGE_NOT_FOUND
257 |         assert result.confidence == 0.95
258 |         assert result.details["status_code_match"] == 404
    |                                                       ^^^
259 |
260 |     def test_no_results_confidence_threshold(self, classifier, mock_driver):
    |

PLR2004 Magic value used in comparison, consider replacing `0.3` with a constant variable
   --> tests\unit\test_failure_classifier.py:268:85
    |
267 |         # Should not classify as NO_RESULTS due to low confidence
268 |         assert result.failure_type != FailureType.NO_RESULTS or result.confidence < 0.3
    |                                                                                     ^^^
    |

E402 Module level import not at top of file
  --> tests\unit\test_local_llm_classifier.py:14:1
   |
13 |   # Import the local LLM classifier
14 | / from src.core.classification.local_llm_classifier import (
15 | |     LocalLLMProductClassifier,
16 | |     classify_product_local_llm,
17 | |     get_local_llm_classifier,
18 | | )
   | |_^
19 |   from src.core.classification.manager import GENERAL_PRODUCT_TAXONOMY, PRODUCT_PAGES
   |

E402 Module level import not at top of file
  --> tests\unit\test_local_llm_classifier.py:19:1
   |
17 |     get_local_llm_classifier,
18 | )
19 | from src.core.classification.manager import GENERAL_PRODUCT_TAXONOMY, PRODUCT_PAGES
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

E501 Line too long (126 > 100)
  --> tests\unit\test_local_llm_classifier.py:48:101
   |
46 |         return {
47 |             "message": {
48 |                 "content": '{"category": "Dog Food", "product_type": "Dry Dog Food", "product_on_pages": "Dog Food Shop All"}'
   |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
49 |             }
50 |         }
   |

PLC0415 `import` should be at the top-level of a file
  --> tests\unit\test_local_llm_classifier.py:62:9
   |
60 |     def unique_cache_file(self, tmp_path):
61 |         """Create a unique cache file for each test."""
62 |         import uuid
   |         ^^^^^^^^^^^
63 |
64 |         cache_file = tmp_path / f"test_cache_{uuid.uuid4().hex}.json"
   |

B007 Loop control variable `category` not used within loop body
  --> tests\unit\test_local_llm_classifier.py:80:13
   |
79 |         # Check that categories have product types
80 |         for category, product_types in GENERAL_PRODUCT_TAXONOMY.items():
   |             ^^^^^^^^
81 |             assert isinstance(product_types, list)
82 |             assert len(product_types) > 0
   |
help: Rename unused `category` to `_category`

E501 Line too long (144 > 100)
   --> tests\unit\test_local_llm_classifier.py:255:101
    |
253 | â€¦
254 | â€¦
255 | â€¦ct_index": 1, "category": "Test", "product_type": "Test", "product_on_pages": "Test"}]}'
    |                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
256 | â€¦
257 | â€¦
    |

E501 Line too long (171 > 100)
   --> tests\unit\test_local_llm_classifier.py:372:101
    |
370 | â€¦
371 | â€¦
372 | â€¦Dog Food", "product_type": "Dry Dog Food", "product_on_pages": "Dog Food Shop All"} Hope this helps!'
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
373 | â€¦
374 | â€¦
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_local_llm_classifier.py:413:9
    |
412 |         # Reset global instance
413 |         import src.core.classification.local_llm_classifier as llm_module
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
414 |
415 |         llm_module._local_llm_classifier = None
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_local_llm_classifier.py:431:9
    |
430 |         # Reset global instance
431 |         import src.core.classification.local_llm_classifier as llm_module
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
432 |
433 |         llm_module._local_llm_classifier = None
    |

PLR0913 Too many arguments in function definition (6 > 5)
   --> tests\unit\test_local_llm_classifier.py:678:9
    |
676 |     @patch("ollama.list")
677 |     @patch("ollama.chat")
678 |     def test_comprehensive_product_classification(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
679 |         self,
680 |         mock_chat,
    |

B905 `zip()` without an explicit `strict=` parameter
   --> tests\unit\test_local_llm_classifier.py:833:48
    |
832 |         # Results should be consistent
833 |         for batch_result, individual_result in zip(batch_results, individual_results):
    |                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
834 |             assert batch_result["category"] == individual_result["category"]
835 |             assert batch_result["product_type"] == individual_result["product_type"]
    |
help: Add explicit value for parameter `strict=`

E501 Line too long (151 > 100)
   --> tests\unit\test_local_llm_classifier.py:848:101
    |
846 | â€¦og Food"',
847 | â€¦
848 | â€¦"product_type": "Wet Cat Food", "product_on_pages": "Cat Food Shop All"} Hope this helps!',
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
849 | â€¦
850 | â€¦Bird Food", "product_on_pages": "Bird Supplies Shop All", "confidence": 0.95, "notes": "Good match"}',
    |

E501 Line too long (162 > 100)
   --> tests\unit\test_local_llm_classifier.py:850:101
    |
848 | â€¦uct_type": "Wet Cat Food", "product_on_pages": "Cat Food Shop All"} Hope this helps!',
849 | â€¦
850 | â€¦Food", "product_on_pages": "Bird Supplies Shop All", "confidence": 0.95, "notes": "Good match"}',
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
851 | â€¦
852 | â€¦: "Dry Dog Food", "product_on_pages": "Dog Food Shop All"}}',
    |

E501 Line too long (126 > 100)
   --> tests\unit\test_local_llm_classifier.py:852:101
    |
850 | â€¦     '{"category": "Bird Supplies", "product_type": "Bird Food", "product_on_pages": "Bird Supplies Shop All", "confidence": 0.95, "â€¦
851 | â€¦     # Nested JSON (should extract inner)
852 | â€¦     '{"response": {"category": "Dog Food", "product_type": "Dry Dog Food", "product_on_pages": "Dog Food Shop All"}}',
    |                                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^
853 | â€¦     # Array response (should handle gracefully)
854 | â€¦     '[{"category": "Cat Food", "product_type": "Dry Cat Food", "product_on_pages": "Cat Food Shop All"}]',
    |

E501 Line too long (114 > 100)
   --> tests\unit\test_local_llm_classifier.py:854:101
    |
852 |             '{"response": {"category": "Dog Food", "product_type": "Dry Dog Food", "product_on_pages": "Dog Food Shop All"}}',
853 |             # Array response (should handle gracefully)
854 |             '[{"category": "Cat Food", "product_type": "Dry Cat Food", "product_on_pages": "Cat Food Shop All"}]',
    |                                                                                                     ^^^^^^^^^^^^^^
855 |         ]
    |

E501 Line too long (130 > 100)
   --> tests\unit\test_local_llm_classifier.py:882:101
    |
880 |             {
881 |                 "message": {
882 |                     "content": '{"category": "Dog Food", "product_type": "Dry Dog Food", "product_on_pages": "Dog Food Shop All"}'
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
883 |                 }
884 |             },
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_local_llm_classifier.py:892:40
    |
890 |         # Should eventually succeed after retries
891 |         assert result["category"] == "Dog Food"
892 |         assert mock_chat.call_count == 3  # Should have tried 3 times
    |                                        ^
893 |
894 |     @patch("ollama.list")
    |

E501 Line too long (126 > 100)
   --> tests\unit\test_local_llm_classifier.py:956:101
    |
954 |         mock_chat.return_value = {
955 |             "message": {
956 |                 "content": '{"category": "Dog Food", "product_type": "Dry Dog Food", "product_on_pages": "Dog Food Shop All"}'
    |                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
957 |             }
958 |         }
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
  --> tests\unit\test_local_storage.py:55:37
   |
53 |         self.dataset.push_data(data_list)
54 |
55 |         assert len(self.dataset) == 2
   |                                     ^
56 |         assert self.dataset._cache == data_list
   |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
  --> tests\unit\test_local_storage.py:60:30
   |
58 |         # Check files were created
59 |         files = list(self.dataset.storage_dir.glob("*.json"))
60 |         assert len(files) == 2
   |                              ^
61 |
62 |     def test_get_data(self):
   |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
  --> tests\unit\test_local_storage.py:86:37
   |
84 |         info = self.dataset.get_info()
85 |         assert info["id"] == "test_dataset"
86 |         assert info["itemCount"] == 2
   |                                     ^
87 |         assert str(self.temp_dir / "test_dataset") in info["storageDir"]
   |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_local_storage.py:137:29
    |
136 |         keys = self.store.list_keys()
137 |         assert len(keys) == 2
    |                             ^
138 |         assert "key1" in keys
139 |         assert "key2" in keys
    |

PLR2004 Magic value used in comparison, consider replacing `300.0` with a constant variable
  --> tests\unit\test_performance.py:64:31
   |
63 |         # Performance assertions
64 |         assert elapsed_time < 300.0, f"Processing 5000 records took {elapsed_time:.2f}s (>5 min)"
   |                               ^^^^^
65 |         assert memory_delta < 500.0, f"Memory usage increased by {memory_delta:.2f}MB (>500MB)"
   |

PLR2004 Magic value used in comparison, consider replacing `500.0` with a constant variable
  --> tests\unit\test_performance.py:65:31
   |
63 |         # Performance assertions
64 |         assert elapsed_time < 300.0, f"Processing 5000 records took {elapsed_time:.2f}s (>5 min)"
65 |         assert memory_delta < 500.0, f"Memory usage increased by {memory_delta:.2f}MB (>500MB)"
   |                               ^^^^^
66 |
67 |         # Quality assertions
   |

PLR2004 Magic value used in comparison, consider replacing `85.0` with a constant variable
  --> tests\unit\test_performance.py:69:69
   |
67 |         # Quality assertions
68 |         avg_score = sum(results) / len(results)
69 |         high_quality_count = sum(1 for score in results if score >= 85.0)
   |                                                                     ^^^^
70 |
71 |         assert avg_score >= 85.0, f"Average quality score too low: {avg_score:.2f}"
   |

PLR2004 Magic value used in comparison, consider replacing `85.0` with a constant variable
  --> tests\unit\test_performance.py:71:29
   |
69 |         high_quality_count = sum(1 for score in results if score >= 85.0)
70 |
71 |         assert avg_score >= 85.0, f"Average quality score too low: {avg_score:.2f}"
   |                             ^^^^
72 |         assert high_quality_count == len(results), (
73 |             f"Only {high_quality_count}/{len(results)} records are high quality"
   |

E501 Line too long (112 > 100)
  --> tests\unit\test_performance.py:77:101
   |
76 |         print(
77 |             f"Performance results: {elapsed_time:.2f}s, {memory_delta:.2f}MB memory, avg score: {avg_score:.2f}"
   |                                                                                                     ^^^^^^^^^^^^
78 |         )
   |

PLR2004 Magic value used in comparison, consider replacing `50.0` with a constant variable
   --> tests\unit\test_performance.py:122:32
    |
120 |         peak_growth = max_memory - initial_memory
121 |
122 |         assert memory_growth < 50.0, f"Memory grew by {memory_growth:.2f}MB during test (>50MB)"
    |                                ^^^^
123 |         assert peak_growth < 100.0, f"Peak memory growth {peak_growth:.2f}MB (>100MB)"
    |

PLR2004 Magic value used in comparison, consider replacing `100.0` with a constant variable
   --> tests\unit\test_performance.py:123:30
    |
122 |         assert memory_growth < 50.0, f"Memory grew by {memory_growth:.2f}MB during test (>50MB)"
123 |         assert peak_growth < 100.0, f"Peak memory growth {peak_growth:.2f}MB (>100MB)"
    |                              ^^^^^
124 |
125 |         print(f"Memory stability: growth {memory_growth:.2f}MB, peak {peak_growth:.2f}MB")
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_performance.py:129:9
    |
127 |     def test_concurrent_performance_simulation(self):
128 |         """Simulate concurrent validation scenarios."""
129 |         import threading
    |         ^^^^^^^^^^^^^^^^
130 |
131 |         scorer = DataQualityScorer()
    |

PLR2004 Magic value used in comparison, consider replacing `60.0` with a constant variable
   --> tests\unit\test_performance.py:186:31
    |
185 |         # Performance check
186 |         assert elapsed_time < 60.0, f"Concurrent processing took {elapsed_time:.2f}s (>1 min)"
    |                               ^^^^
187 |
188 |         print(f"Concurrent performance: {elapsed_time:.2f}s for {total_scores} records")
    |

PLR2004 Magic value used in comparison, consider replacing `5.0` with a constant variable
   --> tests\unit\test_performance.py:224:23
    |
223 |     # Performance thresholds
224 |     assert avg_time < 5.0, f"Average scoring time {avg_time:.2f}ms (>5ms)"
    |                       ^^^
225 |     assert max_time < 20.0, f"Max scoring time {max_time:.2f}ms (>20ms)"
226 |     assert p95_time < 10.0, f"95th percentile {p95_time:.2f}ms (>10ms)"
    |

PLR2004 Magic value used in comparison, consider replacing `20.0` with a constant variable
   --> tests\unit\test_performance.py:225:23
    |
223 |     # Performance thresholds
224 |     assert avg_time < 5.0, f"Average scoring time {avg_time:.2f}ms (>5ms)"
225 |     assert max_time < 20.0, f"Max scoring time {max_time:.2f}ms (>20ms)"
    |                       ^^^^
226 |     assert p95_time < 10.0, f"95th percentile {p95_time:.2f}ms (>10ms)"
    |

PLR2004 Magic value used in comparison, consider replacing `10.0` with a constant variable
   --> tests\unit\test_performance.py:226:23
    |
224 |     assert avg_time < 5.0, f"Average scoring time {avg_time:.2f}ms (>5ms)"
225 |     assert max_time < 20.0, f"Max scoring time {max_time:.2f}ms (>20ms)"
226 |     assert p95_time < 10.0, f"95th percentile {p95_time:.2f}ms (>10ms)"
    |                       ^^^^
227 |
228 |     print(f"Speed test: avg {avg_time:.2f}ms, max {max_time:.2f}ms, p95 {p95_time:.2f}ms")
    |

PLC0415 `import` should be at the top-level of a file
  --> tests\unit\test_scraper_fields.py:48:9
   |
46 |     def discover_scrapers(self) -> dict[str, Any]:
47 |         """Discover all scraper modules dynamically."""
48 |         import glob
   |         ^^^^^^^^^^^
49 |         import importlib.util
   |

PLC0415 `import` should be at the top-level of a file
  --> tests\unit\test_scraper_fields.py:49:9
   |
47 |         """Discover all scraper modules dynamically."""
48 |         import glob
49 |         import importlib.util
   |         ^^^^^^^^^^^^^^^^^^^^^
50 |
51 |         scrapers_dir = os.path.join(PROJECT_ROOT, "scrapers")
   |

PLR0911 Too many return statements (16 > 6)
  --> tests\unit\test_scraper_fields.py:85:9
   |
83 |         return None
84 |
85 |     def validate_field(
   |         ^^^^^^^^^^^^^^
86 |         self, product: dict, field_name: str, scrape_duration: float
87 |     ) -> FieldTestResult:
   |

PLR0912 Too many branches (16 > 12)
  --> tests\unit\test_scraper_fields.py:85:9
   |
83 |         return None
84 |
85 |     def validate_field(
   |         ^^^^^^^^^^^^^^
86 |         self, product: dict, field_name: str, scrape_duration: float
87 |     ) -> FieldTestResult:
   |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_scraper_fields.py:101:42
    |
 99 |                     scrape_duration,
100 |                 )
101 |             if len(str(value).strip()) < 3:
    |                                          ^
102 |                 return FieldTestResult(
103 |                     field_name,
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_scraper_fields.py:120:42
    |
118 |                     scrape_duration,
119 |                 )
120 |             if len(str(value).strip()) < 3:
    |                                          ^
121 |                 return FieldTestResult(
122 |                     field_name,
    |

E501 Line too long (101 > 100)
   --> tests\unit\test_scraper_fields.py:217:101
    |
216 |     def test_scraper(self, scraper_name: str, module: Any) -> ScraperTestResult:
217 |         """Test a scraper by scraping one product and checking if all required fields are present."""
    |                                                                                                     ^
218 |         start_time = time.time()
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_scraper_fields.py:241:13
    |
239 |         try:
240 |             # Temporarily suppress scraping summary output during testing
241 |             from src.utils.general.display import set_suppress_summary
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
242 |
243 |             set_suppress_summary(True)
    |

E722 Do not use bare `except`
   --> tests\unit\test_scraper_fields.py:303:13
    |
301 |             try:
302 |                 set_suppress_summary(False)
303 |             except:
    |             ^^^^^^
304 |                 pass
    |

PLR0912 Too many branches (13 > 12)
   --> tests\unit\test_scraper_fields.py:338:9
    |
336 |         return results
337 |
338 |     def print_summary(self, results: dict[str, ScraperTestResult]):
    |         ^^^^^^^^^^^^^
339 |         """Print a detailed summary of test results."""
340 |         print("\n" + "=" * 80)
    |

PLR2004 Magic value used in comparison, consider replacing `50` with a constant variable
   --> tests\unit\test_scraper_fields.py:356:78
    |
354 |                 value_display = (
355 |                     str(field_result.value)[:50] + "..."
356 |                     if field_result.value and len(str(field_result.value)) > 50
    |                                                                              ^^
357 |                     else str(field_result.value)
358 |                 )
    |

PLC0415 `import` should be at the top-level of a file
  --> tests\unit\test_scraper_fields_clean.py:49:9
   |
47 |     def discover_scrapers(self) -> dict[str, Any]:
48 |         """Discover all scraper modules dynamically."""
49 |         import glob
   |         ^^^^^^^^^^^
50 |         import importlib.util
   |

PLC0415 `import` should be at the top-level of a file
  --> tests\unit\test_scraper_fields_clean.py:50:9
   |
48 |         """Discover all scraper modules dynamically."""
49 |         import glob
50 |         import importlib.util
   |         ^^^^^^^^^^^^^^^^^^^^^
51 |
52 |         scrapers_dir = os.path.join(PROJECT_ROOT, "scrapers")
   |

PLR0911 Too many return statements (16 > 6)
   --> tests\unit\test_scraper_fields_clean.py:151:9
    |
149 |         return result
150 |
151 |     def validate_field(self, product: dict, field_name: str, duration: float) -> FieldTestResult:
    |         ^^^^^^^^^^^^^^
152 |         """Validate a specific field in the product data."""
153 |         value = product.get(field_name)
    |

PLR0912 Too many branches (16 > 12)
   --> tests\unit\test_scraper_fields_clean.py:151:9
    |
149 |         return result
150 |
151 |     def validate_field(self, product: dict, field_name: str, duration: float) -> FieldTestResult:
    |         ^^^^^^^^^^^^^^
152 |         """Validate a specific field in the product data."""
153 |         value = product.get(field_name)
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_scraper_fields_clean.py:161:42
    |
159 |                     field_name, FieldTestStatus.FAIL, value, "SKU is empty", duration
160 |                 )
161 |             if len(str(value).strip()) < 3:
    |                                          ^
162 |                 return FieldTestResult(
163 |                     field_name, FieldTestStatus.FAIL, value, "SKU too short", duration
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_scraper_fields_clean.py:176:42
    |
174 |                     duration,
175 |                 )
176 |             if len(str(value).strip()) < 3:
    |                                          ^
177 |                 return FieldTestResult(
178 |                     field_name, FieldTestStatus.FAIL, value, "Name too short", duration
    |

PLR0912 Too many branches (13 > 12)
   --> tests\unit\test_scraper_fields_clean.py:338:9
    |
336 |         return results
337 |
338 |     def print_summary(self, results: dict[str, ScraperTestResult]):
    |         ^^^^^^^^^^^^^
339 |         """Print a detailed summary of test results."""
340 |         print("\n" + "=" * 80)
    |

PLR2004 Magic value used in comparison, consider replacing `50` with a constant variable
   --> tests\unit\test_scraper_fields_clean.py:356:78
    |
354 |                 value_display = (
355 |                     str(field_result.value)[:50] + "..."
356 |                     if field_result.value and len(str(field_result.value)) > 50
    |                                                                              ^^
357 |                     else str(field_result.value)
358 |                 )
    |

E402 Module level import not at top of file
  --> tests\unit\test_selector_storage.py:9:1
   |
 7 | # Add project root to sys.path
 8 | PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
 9 | import sys
   | ^^^^^^^^^^
10 |
11 | sys.path.insert(0, PROJECT_ROOT)
   |

E402 Module level import not at top of file
  --> tests\unit\test_selector_storage.py:13:1
   |
11 | sys.path.insert(0, PROJECT_ROOT)
12 |
13 | from src.scrapers.selector_storage import SelectorData, SelectorManager, SelectorStorage
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
  --> tests\unit\test_selector_storage.py:46:35
   |
45 |         assert data.selector == ".test"
46 |         assert data.confidence == 0.5
   |                                   ^^^
47 |         assert data.fallbacks == []
48 |         assert data.last_updated is not None
   |

PLR2004 Magic value used in comparison, consider replacing `0.9` with a constant variable
  --> tests\unit\test_selector_storage.py:60:35
   |
59 |         assert data.selector == ".custom"
60 |         assert data.confidence == 0.9
   |                                   ^^^
61 |         assert data.last_updated == "2023-01-01T00:00:00Z"
62 |         assert data.fallbacks == [".alt1", ".alt2"]
   |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
  --> tests\unit\test_selector_storage.py:88:35
   |
87 |         assert data.selector == ".product-title"
88 |         assert data.confidence == 0.8
   |                                   ^^^
89 |         assert data.last_updated == "2023-01-01T00:00:00Z"
90 |         assert data.fallbacks == [".title", ".name"]
   |

PLR2004 Magic value used in comparison, consider replacing `0.5` with a constant variable
   --> tests\unit\test_selector_storage.py:99:35
    |
 98 |         assert data.selector == ".test"
 99 |         assert data.confidence == 0.5
    |                                   ^^^
100 |         assert data.fallbacks == []
    |

PLR2004 Magic value used in comparison, consider replacing `0.6` with a constant variable
   --> tests\unit\test_selector_storage.py:108:35
    |
106 |         data.update_confidence(success=True)
107 |
108 |         assert data.confidence == 0.6  # 0.5 + 0.1
    |                                   ^^^
109 |
110 |     def test_update_confidence_failure(self):
    |

PLR2004 Magic value used in comparison, consider replacing `0.4` with a constant variable
   --> tests\unit\test_selector_storage.py:116:35
    |
114 |         data.update_confidence(success=False)
115 |
116 |         assert data.confidence == 0.4  # 0.5 - 0.1
    |                                   ^^^
117 |
118 |     def test_update_confidence_max_min_bounds(self):
    |

PLR2004 Magic value used in comparison, consider replacing `0.7` with a constant variable
   --> tests\unit\test_selector_storage.py:136:35
    |
134 |         data.update_confidence(success=True, learning_rate=0.2)
135 |
136 |         assert data.confidence == 0.7  # 0.5 + 0.2
    |                                   ^^^
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_selector_storage.py:150:13
    |
148 |         # Ensure the directory doesn't exist
149 |         if test_dir.exists():
150 |             import shutil
    |             ^^^^^^^^^^^^^
151 |
152 |             shutil.rmtree(test_dir)
    |

F841 Local variable `storage` is assigned to but never used
   --> tests\unit\test_selector_storage.py:154:9
    |
152 |             shutil.rmtree(test_dir)
153 |
154 |         storage = SelectorStorage(str(storage_file))
    |         ^^^^^^^
155 |
156 |         assert test_dir.exists()
    |
help: Remove assignment to unused variable `storage`

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
   --> tests\unit\test_selector_storage.py:194:44
    |
192 |         selector_data = storage.data["example.com"]["product_name"]
193 |         assert selector_data.selector == ".product-title"
194 |         assert selector_data.confidence == 0.8
    |                                            ^^^
195 |
196 |     def test_load_corrupted_file(self, temp_storage_path):
    |

PLR2004 Magic value used in comparison, consider replacing `0.9` with a constant variable
   --> tests\unit\test_selector_storage.py:220:44
    |
218 |         assert selector_data is not None
219 |         assert selector_data.selector == ".price"
220 |         assert selector_data.confidence == 0.9
    |                                            ^^^
221 |         assert selector_data.fallbacks == [".cost"]
    |

PLR2004 Magic value used in comparison, consider replacing `0.7` with a constant variable
   --> tests\unit\test_selector_storage.py:250:44
    |
248 |         assert selector_data is not None
249 |         assert selector_data.selector == ".name"
250 |         assert selector_data.confidence == 0.7
    |                                            ^^^
251 |         assert selector_data.fallbacks == [".title"]
    |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
   --> tests\unit\test_selector_storage.py:263:44
    |
261 |         assert selector_data is not None
262 |         assert selector_data.selector == ".new-name"
263 |         assert selector_data.confidence == 0.8
    |                                            ^^^
264 |         assert selector_data.fallbacks == [".alt"]
    |

PLR2004 Magic value used in comparison, consider replacing `0.6` with a constant variable
   --> tests\unit\test_selector_storage.py:275:44
    |
273 |         selector_data = storage.get_selector("example.com", "price")
274 |         assert selector_data is not None
275 |         assert selector_data.confidence == 0.6
    |                                            ^^^
276 |
277 |     def test_get_fallback_chain(self, temp_storage_path):
    |

PLR2004 Magic value used in comparison, consider replacing `0.6` with a constant variable
   --> tests\unit\test_selector_storage.py:390:44
    |
388 |         selector_data = manager.storage.get_selector("example.com", "title")
389 |         assert selector_data is not None
390 |         assert selector_data.confidence == 0.6  # 0.5 + 0.1
    |                                            ^^^
391 |
392 |     def test_learn_selector_promote_new(self, temp_storage_path):
    |

PLR2004 Magic value used in comparison, consider replacing `0.8` with a constant variable
   --> tests\unit\test_selector_storage.py:455:39
    |
453 |         assert stats is not None
454 |         assert stats["selector"] == ".title"
455 |         assert stats["confidence"] == 0.8
    |                                       ^^^
456 |         assert stats["fallback_count"] == 2
457 |         assert stats["total_selectors"] == 3
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_selector_storage.py:456:43
    |
454 |         assert stats["selector"] == ".title"
455 |         assert stats["confidence"] == 0.8
456 |         assert stats["fallback_count"] == 2
    |                                           ^
457 |         assert stats["total_selectors"] == 3
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_selector_storage.py:457:44
    |
455 |         assert stats["confidence"] == 0.8
456 |         assert stats["fallback_count"] == 2
457 |         assert stats["total_selectors"] == 3
    |                                            ^
458 |
459 |     def test_get_selector_stats_none(self, temp_storage_path):
    |

E402 Module level import not at top of file
  --> tests\unit\test_workflow_executor.py:11:1
   |
 9 | sys.path.insert(0, PROJECT_ROOT)
10 |
11 | from selenium.webdriver.common.by import By
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
12 |
13 | from src.scrapers.executor.workflow_executor import WorkflowExecutionError, WorkflowExecutor
   |

E402 Module level import not at top of file
  --> tests\unit\test_workflow_executor.py:13:1
   |
11 | from selenium.webdriver.common.by import By
12 |
13 | from src.scrapers.executor.workflow_executor import WorkflowExecutionError, WorkflowExecutor
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
14 | from src.scrapers.models.config import LoginConfig, ScraperConfig, SelectorConfig, WorkflowStep
   |

E402 Module level import not at top of file
  --> tests\unit\test_workflow_executor.py:14:1
   |
13 | from src.scrapers.executor.workflow_executor import WorkflowExecutionError, WorkflowExecutor
14 | from src.scrapers.models.config import LoginConfig, ScraperConfig, SelectorConfig, WorkflowStep
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
  --> tests\unit\test_workflow_executor.py:90:43
   |
88 |         assert executor.timeout == expected_timeout
89 |         assert executor.results == {}
90 |         assert len(executor.selectors) == 3
   |                                           ^
91 |         mock_create_browser.assert_called_once()
92 |         call_args = mock_create_browser.call_args
   |

PLR2004 Magic value used in comparison, consider replacing `60` with a constant variable
   --> tests\unit\test_workflow_executor.py:101:36
    |
 99 |         executor = WorkflowExecutor(sample_config, headless=True, timeout=60)
100 |
101 |         assert executor.timeout == 60
    |                                    ^^
102 |
103 |     def test_init_browser_failure(self, sample_config):
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_workflow_executor.py:132:44
    |
130 |         assert result["success"] is True
131 |         assert result["config_name"] == "Test Scraper"
132 |         assert result["steps_executed"] == 3
    |                                            ^
133 |         assert "results" in result
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:182:9
    |
180 |     def test_action_wait_for_timeout(self, sample_config, mock_create_browser, mock_browser):
181 |         """Test wait_for action that times out."""
182 |         from selenium.common.exceptions import TimeoutException
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
183 |
184 |         executor = WorkflowExecutor(sample_config, headless=True)
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:225:9
    |
223 |     ):
224 |         """Test extract_single when element is not found."""
225 |         from selenium.common.exceptions import NoSuchElementException
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
226 |
227 |         executor = WorkflowExecutor(sample_config, headless=True)
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_workflow_executor.py:362:44
    |
361 |         assert result["success"] is True
362 |         assert result["steps_executed"] == 2
    |                                            ^
363 |         assert "product_name" in executor.results
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:604:9
    |
602 |     def test_anti_detection_pre_action_hook_failure(self, sample_config, mock_create_browser):
603 |         """Test pre-action anti-detection hook failure."""
604 |         from unittest.mock import Mock
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
605 |
606 |         mock_anti_detection = Mock()
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_workflow_executor.py:638:47
    |
636 |         # Should have called handle_error and retried
637 |         mock_anti_detection.handle_error.assert_called_once()
638 |         assert mock_browser.get.call_count == 2
    |                                               ^
639 |
640 |     def test_get_locator_type_xpath(self, sample_config, mock_create_browser):
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:699:9
    |
697 |     def test_no_results_failure_no_retry(self, sample_config, mock_create_browser, mock_browser):
698 |         """Test that NO_RESULTS failures are properly classified and handled without retries."""
699 |         from src.core.failure_classifier import FailureType
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
700 |
701 |         # Mock the failure classifier to return NO_RESULTS
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:742:9
    |
740 |     ):
741 |         """Test that failure context is correctly stored in workflow results for NO_RESULTS."""
742 |         from src.core.failure_classifier import FailureType
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
743 |
744 |         # Mock the failure classifier to return NO_RESULTS
    |

PLR2004 Magic value used in comparison, consider replacing `0.9` with a constant variable
   --> tests\unit\test_workflow_executor.py:778:57
    |
776 |                 failure_context = executor.results["failure_context"]
777 |                 assert failure_context["type"] == "no_results"
778 |                 assert failure_context["confidence"] == 0.9
    |                                                         ^^^
779 |                 assert failure_context["details"]["selector_match"] is True
780 |                 assert failure_context["recovery_strategy"] == "retry_with_different_query"
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:785:9
    |
783 |     def test_no_results_analytics_recording(self, sample_config, mock_create_browser, mock_browser):
784 |         """Test that NO_RESULTS failures trigger appropriate analytics recording."""
785 |         from src.core.failure_classifier import FailureType
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
786 |
787 |         # Mock the failure classifier to return NO_RESULTS
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:834:9
    |
832 |     ):
833 |         """Test differentiation between NO_RESULTS and other failure types in retry logic."""
834 |         from src.core.failure_classifier import FailureType
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
835 |
836 |         executor = WorkflowExecutor(sample_config, headless=True)
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_workflow_executor.py:902:75
    |
901 |                     # Verify it was called twice (initial + 1 retry)
902 |                     assert mock_browser.driver.find_element.call_count == 2
    |                                                                           ^
903 |
904 |     def test_no_results_detection_integration(
    |

E501 Line too long (106 > 100)
   --> tests\unit\test_workflow_executor.py:907:101
    |
905 |         self, sample_config, mock_create_browser, mock_browser
906 |     ):
907 |         """Test integration with failure classifier for NO_RESULTS detection during extraction actions."""
    |                                                                                                     ^^^^^^
908 |         from src.core.failure_classifier import FailureType
    |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_workflow_executor.py:908:9
    |
906 |     ):
907 |         """Test integration with failure classifier for NO_RESULTS detection during extraction actions."""
908 |         from src.core.failure_classifier import FailureType
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
909 |
910 |         executor = WorkflowExecutor(sample_config, headless=True)
    |

E501 Line too long (104 > 100)
   --> tests\unit\test_workflow_executor.py:930:101
    |
928 |                     return_value=mock_config,
929 |                 ):
930 |                     # Make extract_single fail with an exception that should be classified as NO_RESULTS
    |                                                                                                     ^^^^
931 |                     mock_browser.driver.find_element.side_effect = Exception(
932 |                         "No products found matching your search criteria"
    |

E402 Module level import not at top of file
  --> tests\unit\test_yaml_parser.py:11:1
   |
 9 | sys.path.insert(0, PROJECT_ROOT)
10 |
11 | from src.scrapers.models.config import ScraperConfig
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
12 | from src.scrapers.parser.yaml_parser import ScraperConfigParser
   |

E402 Module level import not at top of file
  --> tests\unit\test_yaml_parser.py:12:1
   |
11 | from src.scrapers.models.config import ScraperConfig
12 | from src.scrapers.parser.yaml_parser import ScraperConfigParser
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLC0415 `import` should be at the top-level of a file
   --> tests\unit\test_yaml_parser.py:104:9
    |
102 |     def test_preprocess_config_dict_with_anti_detection(self, config_with_anti_detection):
103 |         """Test preprocessing config dict with anti-detection."""
104 |         from src.core.anti_detection_manager import AntiDetectionConfig
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
105 |
106 |         parser = ScraperConfigParser()
    |

PLR2004 Magic value used in comparison, consider replacing `30` with a constant variable
   --> tests\unit\test_yaml_parser.py:128:34
    |
126 |         assert config.name == "Test Scraper"
127 |         assert config.base_url == "https://example.com"
128 |         assert config.timeout == 30
    |                                  ^^
129 |         assert config.retries == 3
130 |         assert len(config.selectors) == 2
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_yaml_parser.py:129:34
    |
127 |         assert config.base_url == "https://example.com"
128 |         assert config.timeout == 30
129 |         assert config.retries == 3
    |                                  ^
130 |         assert len(config.selectors) == 2
131 |         assert len(config.workflows) == 2
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_yaml_parser.py:130:41
    |
128 |         assert config.timeout == 30
129 |         assert config.retries == 3
130 |         assert len(config.selectors) == 2
    |                                         ^
131 |         assert len(config.workflows) == 2
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_yaml_parser.py:131:41
    |
129 |         assert config.retries == 3
130 |         assert len(config.selectors) == 2
131 |         assert len(config.workflows) == 2
    |                                         ^
132 |
133 |     def test_load_from_file_not_found(self):
    |

B017 Do not assert blind exception: `Exception`
   --> tests\unit\test_yaml_parser.py:164:14
    |
163 |         # Should raise validation error
164 |         with pytest.raises(Exception):  # Pydantic validation error
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
165 |             parser.load_from_file(str(yaml_file))
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_yaml_parser.py:176:41
    |
174 |         assert config.name == "Test Scraper"
175 |         assert config.base_url == "https://example.com"
176 |         assert len(config.selectors) == 2
    |                                         ^
177 |         assert len(config.workflows) == 2
    |

PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
   --> tests\unit\test_yaml_parser.py:177:41
    |
175 |         assert config.base_url == "https://example.com"
176 |         assert len(config.selectors) == 2
177 |         assert len(config.workflows) == 2
    |                                         ^
178 |
179 |     def test_load_from_string_invalid_yaml(self):
    |

PLR2004 Magic value used in comparison, consider replacing `30` with a constant variable
   --> tests\unit\test_yaml_parser.py:332:34
    |
330 |         assert config.name == "Minimal Scraper"
331 |         assert config.base_url == "https://example.com"
332 |         assert config.timeout == 30  # default
    |                                  ^^
333 |         assert config.retries == 3  # default
334 |         assert config.selectors == []  # default
    |

PLR2004 Magic value used in comparison, consider replacing `3` with a constant variable
   --> tests\unit\test_yaml_parser.py:333:34
    |
331 |         assert config.base_url == "https://example.com"
332 |         assert config.timeout == 30  # default
333 |         assert config.retries == 3  # default
    |                                  ^
334 |         assert config.selectors == []  # default
335 |         assert config.workflows == []  # default
    |

Found 845 errors.
No fixes available (50 hidden fixes can be enabled with the `--unsafe-fixes` option).
